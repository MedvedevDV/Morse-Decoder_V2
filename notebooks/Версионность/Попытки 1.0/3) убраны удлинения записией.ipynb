{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d761d8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path as pt\n",
    "import torch\n",
    "import torchaudio\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchaudio import transforms\n",
    "from torchvision.transforms import v2\n",
    "# from Moduls.MosreDataset import MosreDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "DEVICE = torch.device(\"cuda\")\n",
    "\n",
    "MAIN = pt(os.getcwd())\n",
    "DATASET_PATCH = MAIN / 'morse_dataset'\n",
    "AUDIO_FILES = DATASET_PATCH / 'morse_dataset'\n",
    "\n",
    "# Поятоянные значения выявленные в процессе анализа\n",
    "MORSEALP = \"АБВГДЕЁЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯ 1234567890#\"\n",
    "MAX_TIME = 48\n",
    "SAMPLE_RATE = 8000\n",
    "N_MELS = 128\n",
    "N_FFT = 400\n",
    "HOP_LENGTH = 180\n",
    "TOP_DB = 80\n",
    "FREQ_MASK = 30\n",
    "TIME_MASK = 40\n",
    "\n",
    "# Гиперпараметы обучения\n",
    "SEED = 42\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 0.002 #2e-4\n",
    "WEIGHT_DECAY = 0.00001\n",
    "# int_to_alph = dict(enumerate(MORSEALP))\n",
    "# alph_to_int = {char:enum for enum, char in int_to_alph.items()}\n",
    "\n",
    "#===== Import data =====\n",
    "train_data = pd.read_csv(pt.joinpath(DATASET_PATCH,'train.csv'))\n",
    "test_data = pd.read_csv(pt.joinpath(DATASET_PATCH,'test.csv'))\n",
    "sample_data = pd.read_csv(pt.joinpath(DATASET_PATCH,'sample_submission.csv'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26dc5684",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MosreDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Класс для обработки \n",
    "    \"\"\"\n",
    "    def __init__(self, df, data_patch, train=True, transforms=None, prev_chars = 1):\n",
    "        self.df = df\n",
    "        self.is_train = train\n",
    "\n",
    "        self.data_path = data_patch\n",
    "        self.audio_paths = self.data_path / 'morse_dataset'\n",
    "\n",
    "        self.transforms = transforms\n",
    "\n",
    "        self.morse_alp = \"АБВГДЕЁЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯ 1234567890#\"\n",
    "        self.int_to_alph = dict(enumerate(MORSEALP, start=1)) # 0 - Выводим под пустое\n",
    "        self.alph_to_int = {char:enum+1 for enum, char in self.int_to_alph.items()}\n",
    "        self.prev_chars = prev_chars\n",
    "\n",
    "        if self.is_train:\n",
    "            self.messeges = self.df.message.values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        #Получение аугментрованых спектрограмм\n",
    "        try:\n",
    "            audio_file = self.audio_paths / self.df.id.values[index]\n",
    "            waveform, sample_rate = torchaudio.load(audio_file)\n",
    "            augmented_spectrogram = self.transforms(waveform)\n",
    "\n",
    "            if self.is_train:\n",
    "                message = self.messeges[index]\n",
    "                #Получение списка индексов секта - как требует CTC los\n",
    "                '''\n",
    "                При обработке dataloader labels будут выравниваться по макс длине для выравнивания батча\n",
    "                Т.е. будет padding 0. что в будующем будет пустым значением для ctc loss\n",
    "                '''\n",
    "                label = torch.LongTensor([self.morse_alp.find(c) + 1 for c in message])\n",
    "                label_len = torch.LongTensor([len(label)])\n",
    "                return augmented_spectrogram, label, label_len\n",
    "            else:\n",
    "                return augmented_spectrogram\n",
    "        except Exception as ex:\n",
    "            print(str(ex))\n",
    "        \n",
    "    def change_time(self, audio_file, max_len = 384000):\n",
    "        waveform, sample_rate = torchaudio.load(audio_file)\n",
    "        cahanal, sig_len = waveform.shape\n",
    "\n",
    "        if sig_len < max_len:\n",
    "            pad_len = torch.zeros(max_len - sig_len).unsqueeze(0)\n",
    "            waveform = torch.cat([waveform, pad_len], dim=1)\n",
    "\n",
    "        return waveform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de5e48a",
   "metadata": {},
   "source": [
    "# Загрузка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40609f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1, 128, 320])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_audio_transforms = nn.Sequential(\n",
    "    transforms.MelSpectrogram(sample_rate=SAMPLE_RATE, n_fft=N_FFT, n_mels=N_MELS),\n",
    "    transforms.AmplitudeToDB(top_db=TOP_DB),\n",
    "    transforms.FrequencyMasking(freq_mask_param=FREQ_MASK),\n",
    "    transforms.TimeMasking(time_mask_param=TIME_MASK),\n",
    "    v2.RandomCrop((N_MELS, 320)) # Обрезает последний кадр спектрограммы, в идеале надобы считать а не прописывать число\n",
    "    ) # заметка - Данные трансформации не создают довых обучаемых параметров. Но есть и те что создают. В будущем это стоит учитывать\n",
    "\n",
    "valid_audio_transforms = nn.Sequential(\n",
    "    transforms.MelSpectrogram(sample_rate=SAMPLE_RATE, n_fft=N_FFT, n_mels=N_MELS),\n",
    "    transforms.AmplitudeToDB(top_db=TOP_DB),\n",
    "    v2.RandomCrop((N_MELS, 320)) \n",
    "    )\n",
    "\n",
    "train_dataframe, val_dataframe = train_test_split(train_data, test_size=0.15, random_state=SEED)\n",
    "\n",
    "train_ds = MosreDataset(df=train_dataframe,\n",
    "                        data_patch=DATASET_PATCH,\n",
    "                        train=True,\n",
    "                        transforms=train_audio_transforms)\n",
    "\n",
    "val_ds = MosreDataset(df=val_dataframe,\n",
    "                        data_patch=DATASET_PATCH,\n",
    "                        train=True,\n",
    "                        transforms=valid_audio_transforms)\n",
    "\n",
    "def my_collate(batch):\n",
    "    data = torch.stack([item[0] for item in batch])\n",
    "    target = torch.nn.utils.rnn.pad_sequence(\n",
    "                                            [item[1] for item in batch], \n",
    "                                            batch_first=True, \n",
    "                                            padding_value=0) # выравнивает последовательность до макс \n",
    "                                                            # длины в датче заполняя пропуски нулем\n",
    "    label_len = torch.stack([item[2] for item in batch])\n",
    "    return [data, target, label_len]\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=my_collate)\n",
    "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, collate_fn=my_collate)\n",
    "test = next(iter(train_dl))[0].to(DEVICE)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495949e0",
   "metadata": {},
   "source": [
    "Вывод - torch.Size([32, 1, 128, 1921]) => нужно обрезать посдлелний кадр в спектрограмме 1921 -> 1920(torchvision.transformes.RandomCrop). Или подобрать Гиперпараметры(не вышло)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbaf999d",
   "metadata": {},
   "source": [
    "# Класс модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9608d23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "FIRST_FE_COUNT = 16\n",
    "SECOND_FE_COUNT = 32\n",
    "THIRD_FE_COUNT = 32\n",
    "QAD_FE_COUNT = 32\n",
    "PADDING = 'same'\n",
    "MAXPOOL_KERNEL = 2\n",
    "KERTNEL_SIZE = 3\n",
    "NERON_COUNT = 128\n",
    "GRU_HIDEN = 256\n",
    "# Start with 4 transforms\n",
    "class MorseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, \n",
    "                      out_channels=FIRST_FE_COUNT, \n",
    "                      kernel_size=KERTNEL_SIZE , stride=1, padding=PADDING),\n",
    "            nn.BatchNorm2d(FIRST_FE_COUNT),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=MAXPOOL_KERNEL), # [batch, FIRST_FE_COUNT = 16, 64, 960]\n",
    "\n",
    "            nn.Conv2d(in_channels=FIRST_FE_COUNT, \n",
    "                      out_channels=SECOND_FE_COUNT, \n",
    "                      kernel_size=KERTNEL_SIZE , stride=1, padding=PADDING),\n",
    "            nn.BatchNorm2d(SECOND_FE_COUNT),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=MAXPOOL_KERNEL), # [batch, SECOND_FE_COUNT = 32, 32, 480]\n",
    "\n",
    "            nn.Conv2d(in_channels=SECOND_FE_COUNT, \n",
    "                      out_channels=THIRD_FE_COUNT, \n",
    "                      kernel_size=KERTNEL_SIZE , stride=1, padding=PADDING),\n",
    "            nn.BatchNorm2d(THIRD_FE_COUNT),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=MAXPOOL_KERNEL), # [batch, THIRD_FE_COUNT = 32, 16, 240]\n",
    "\n",
    "            nn.Conv2d(in_channels=THIRD_FE_COUNT, \n",
    "                      out_channels=QAD_FE_COUNT, \n",
    "                      kernel_size=KERTNEL_SIZE , stride=1, padding=PADDING),\n",
    "            nn.BatchNorm2d(QAD_FE_COUNT),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2,3)), # [batch=32, QAD_FE_COUNT = 32, 8, 80](что юы сохраниить большще признаков по горизонтали)\n",
    "        )\n",
    "\n",
    "        self.rnn1 = nn.GRU(input_size=N_MELS*2,hidden_size=GRU_HIDEN, num_layers=3, bidirectional=True)\n",
    "\n",
    "        # self.faltten = nn.Flatten() # [32, 81920]\n",
    "        # self.layer1 = nn.Linear(81920, N_MELS, bias=False)         \n",
    "        # self.layer2 = nn.Linear(N_MELS, len(MORSEALP), bias=False)         \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net_conv(x)\n",
    "\n",
    "        batch, channels, reduced_mels, reduced_time = x.shape\n",
    "        x = x.permute(0, 3, 1, 2)  # [batch, time, channels, mels]\n",
    "        # В частности, каждый вектор признаков в последовательности признаков генерируется \n",
    "        # слева направо на картах признаков. Это означает, что i-й вектор признаков представляет \n",
    "        # собой объединение столбцов всех карт. \n",
    "        # Таким образом, форма тензора может быть изменена, например, на (размер_пакета, 80, 256)\n",
    "        x = x.reshape(batch, reduced_time, -1)  # to GRU [batch=32, seq_len=80, features=256]\n",
    "\n",
    "        x = self.rnn1(x)\n",
    "        x, _ = x # берем информацию со всез состояний\n",
    "        x = x.log_softmax(dim=2) \n",
    "        # x = self.faltten(x)\n",
    "\n",
    "        # x = self.layer1(x)\n",
    "        # x = self.layer2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66eee39",
   "metadata": {},
   "source": [
    "Переменные для обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b432159",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MorseNet().to(DEVICE)\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "loss_func = nn.CTCLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1155b008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 13, 512])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(test).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa7f726",
   "metadata": {},
   "source": [
    "# Обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb5f703",
   "metadata": {},
   "source": [
    "0) Сохдать отдельный трансформер на валинацию => Изменить class Dataset \n",
    "1) Обучить на 1-м батче\n",
    "2) изменить LEARNING_RATE и WEIGHT_DECAY \n",
    "\n",
    "3) попробовать убрать выравнивание по длинне аудио - появляется много пустого места => модет плохо сказываться на обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "422ea6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Эпоха 1/20\n",
      "Train Loss: nan\n",
      "Val Loss: nan\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m total_train = \u001b[32m0\u001b[39m\n\u001b[32m     10\u001b[39m train_tqdm = tqdm(train_dl, desc=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mЭпоха \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m [Обучение]\u001b[39m\u001b[33m\"\u001b[39m, leave=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmel_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_lens\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_tqdm\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmel_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_lens\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmel_spec\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_lens\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#===== считатем длинну mel_spec для передачи в CTC loss =====\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\homer\\OneDrive\\Desktop\\Morse_Decoder_V2\\Morse_decoder_V2\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\homer\\OneDrive\\Desktop\\Morse_Decoder_V2\\Morse_decoder_V2\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\homer\\OneDrive\\Desktop\\Morse_Decoder_V2\\Morse_decoder_V2\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:789\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    788\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    790\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    791\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\homer\\OneDrive\\Desktop\\Morse_Decoder_V2\\Morse_decoder_V2\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36mMosreDataset.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     28\u001b[39m     audio_file = \u001b[38;5;28mself\u001b[39m.audio_paths / \u001b[38;5;28mself\u001b[39m.df.id.values[index]\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     waveform, sample_rate = \u001b[43mtorchaudio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m     augmented_spectrogram = \u001b[38;5;28mself\u001b[39m.transforms(waveform)\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_train:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\homer\\OneDrive\\Desktop\\Morse_Decoder_V2\\Morse_decoder_V2\\Lib\\site-packages\\torchaudio\\_backend\\utils.py:205\u001b[39m, in \u001b[36mget_load_func.<locals>.load\u001b[39m\u001b[34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size, backend)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Load audio data from source.\u001b[39;00m\n\u001b[32m    129\u001b[39m \n\u001b[32m    130\u001b[39m \u001b[33;03mBy default (``normalize=True``, ``channels_first=True``), this function returns Tensor with\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    202\u001b[39m \u001b[33;03m        `[channel, time]` else `[time, channel]`.\u001b[39;00m\n\u001b[32m    203\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    204\u001b[39m backend = dispatcher(uri, \u001b[38;5;28mformat\u001b[39m, backend)\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\homer\\OneDrive\\Desktop\\Morse_Decoder_V2\\Morse_decoder_V2\\Lib\\site-packages\\torchaudio\\_backend\\soundfile.py:27\u001b[39m, in \u001b[36mSoundfileBackend.load\u001b[39m\u001b[34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\n\u001b[32m     19\u001b[39m     uri: Union[BinaryIO, \u001b[38;5;28mstr\u001b[39m, os.PathLike],\n\u001b[32m   (...)\u001b[39m\u001b[32m     25\u001b[39m     buffer_size: \u001b[38;5;28mint\u001b[39m = \u001b[32m4096\u001b[39m,\n\u001b[32m     26\u001b[39m ) -> Tuple[torch.Tensor, \u001b[38;5;28mint\u001b[39m]:\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msoundfile_backend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\homer\\OneDrive\\Desktop\\Morse_Decoder_V2\\Morse_decoder_V2\\Lib\\site-packages\\torchaudio\\_backend\\soundfile_backend.py:230\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(filepath, frame_offset, num_frames, normalize, channels_first, format)\u001b[39m\n\u001b[32m    227\u001b[39m         dtype = _SUBTYPE2DTYPE[file_.subtype]\n\u001b[32m    229\u001b[39m     frames = file_._prepare_read(frame_offset, \u001b[38;5;28;01mNone\u001b[39;00m, num_frames)\n\u001b[32m--> \u001b[39m\u001b[32m230\u001b[39m     waveform = \u001b[43mfile_\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malways_2d\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    231\u001b[39m     sample_rate = file_.samplerate\n\u001b[32m    233\u001b[39m waveform = torch.from_numpy(waveform)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\homer\\OneDrive\\Desktop\\Morse_Decoder_V2\\Morse_decoder_V2\\Lib\\site-packages\\soundfile.py:942\u001b[39m, in \u001b[36mSoundFile.read\u001b[39m\u001b[34m(self, frames, dtype, always_2d, fill_value, out)\u001b[39m\n\u001b[32m    940\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m frames < \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m frames > \u001b[38;5;28mlen\u001b[39m(out):\n\u001b[32m    941\u001b[39m         frames = \u001b[38;5;28mlen\u001b[39m(out)\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m frames = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_array_io\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mread\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) > frames:\n\u001b[32m    944\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m fill_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\homer\\OneDrive\\Desktop\\Morse_Decoder_V2\\Morse_decoder_V2\\Lib\\site-packages\\soundfile.py:1394\u001b[39m, in \u001b[36mSoundFile._array_io\u001b[39m\u001b[34m(self, action, array, frames)\u001b[39m\n\u001b[32m   1392\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m array.dtype.itemsize == _ffi.sizeof(ctype)\n\u001b[32m   1393\u001b[39m cdata = _ffi.cast(ctype + \u001b[33m'\u001b[39m\u001b[33m*\u001b[39m\u001b[33m'\u001b[39m, array.__array_interface__[\u001b[33m'\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m'\u001b[39m][\u001b[32m0\u001b[39m])\n\u001b[32m-> \u001b[39m\u001b[32m1394\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cdata_io\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\homer\\OneDrive\\Desktop\\Morse_Decoder_V2\\Morse_decoder_V2\\Lib\\site-packages\\soundfile.py:1403\u001b[39m, in \u001b[36mSoundFile._cdata_io\u001b[39m\u001b[34m(self, action, data, ctype, frames)\u001b[39m\n\u001b[32m   1401\u001b[39m     curr = \u001b[38;5;28mself\u001b[39m.tell()\n\u001b[32m   1402\u001b[39m func = \u001b[38;5;28mgetattr\u001b[39m(_snd, \u001b[33m'\u001b[39m\u001b[33msf_\u001b[39m\u001b[33m'\u001b[39m + action + \u001b[33m'\u001b[39m\u001b[33mf_\u001b[39m\u001b[33m'\u001b[39m + ctype)\n\u001b[32m-> \u001b[39m\u001b[32m1403\u001b[39m frames = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1404\u001b[39m _error_check(\u001b[38;5;28mself\u001b[39m._errorcode)\n\u001b[32m   1405\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.seekable():\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "lst_loss_train = []\n",
    "lst_loss_val = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    epoch_train_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    train_tqdm = tqdm(train_dl, desc=f\"Эпоха {epoch+1}/{EPOCHS} [Обучение]\", leave=False)\n",
    "    for mel_spec, labels, label_lens in train_tqdm:\n",
    "        mel_spec, labels, label_lens = mel_spec.to(DEVICE), labels.to(DEVICE), label_lens.to(DEVICE)\n",
    "\n",
    "        #===== считатем длинну mel_spec для передачи в CTC loss =====\n",
    "        \n",
    "        predict = model(mel_spec) # (N=batch,T,C)\n",
    "        permuted_predict = predict.permute(1, 0, 2)\n",
    "        N = predict.shape[0]\n",
    "        T = predict.shape[1]\n",
    "        predict_lengths = torch.full(size=(N,), fill_value=T, dtype=torch.long)\n",
    "\n",
    "        # print(permuted_predict.shape, labels.shape, predict_lengths.shape, label_lens.shape)\n",
    "        # break\n",
    "        loss = loss_func(permuted_predict, labels, predict_lengths, label_lens)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_train_loss += loss.item()\n",
    "        train_loss = epoch_train_loss / len(train_data)\n",
    "\n",
    "\n",
    "    # ======== Валидация ========\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    all_targets = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for val_mel_spec, val_labels, val_label_lensin in tqdm(\n",
    "                                                        val_dl, \n",
    "                                                        desc=f\"Эпоха {epoch+1}/{EPOCHS} [Валидация]\", \n",
    "                                                        leave=False):\n",
    "            val_mel_spec, val_labels, val_label_lensin = val_mel_spec.to(DEVICE), val_labels.to(DEVICE), val_label_lensin.to(DEVICE)\n",
    "            val_predict = model(val_mel_spec)\n",
    "\n",
    "            permuted_val_predict = val_predict.permute(1, 0, 2)\n",
    "            val_N = val_predict.shape[0]\n",
    "            val_T = val_predict.shape[1]\n",
    "            predict_val_lengths = torch.full(size=(val_N,), fill_value=val_T, dtype=torch.long)\n",
    "            val_loss += loss_func(permuted_val_predict, val_labels, predict_val_lengths, val_label_lensin).item()\n",
    "\n",
    "\n",
    "\n",
    "    lst_loss_train.append(train_loss)\n",
    "    lst_loss_val.append(val_loss)\n",
    "\n",
    "            \n",
    "    print(f\"\\nЭпоха {epoch+1}/{EPOCHS}\")\n",
    "    # print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1547a2ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lst_loss_train)\n",
    "plt.plot(lst_loss_val)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Morse_decoder_V2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

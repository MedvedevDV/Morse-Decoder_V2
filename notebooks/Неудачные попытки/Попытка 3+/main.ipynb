{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d761d8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN размерность выхода: torch.Size([1, 32, 16, 89])\n",
      "CNN число фичей: 512\n",
      "Проекция из 512 в 1024\n",
      "\n",
      "MorseNet - инициалицация модели. Число обучаемых параметров: 12,017,933\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path as pt\n",
    "import torch\n",
    "import torchaudio\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchaudio import transforms\n",
    "from torchvision.transforms import v2\n",
    "# from Moduls.MosreDataset import MosreDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch.nn.parallel import DataParallel\n",
    "from collections import Counter\n",
    "\n",
    "DEVICE = torch.device(\"cuda\")\n",
    "\n",
    "MAIN = pt(os.getcwd())\n",
    "DATASET_PATCH = MAIN / 'morse_dataset'\n",
    "AUDIO_FILES = DATASET_PATCH / 'morse_dataset'\n",
    "\n",
    "# Поятоянные значения выявленные в процессе анализа\n",
    "MORSEALP = \"АБВГДЕЁЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯ 1234567890#\"\n",
    "MAX_TIME = 48\n",
    "SAMPLE_RATE = 8000\n",
    "N_MELS = 128\n",
    "N_FFT = 400\n",
    "HOP_LENGTH = 180\n",
    "TOP_DB = 80\n",
    "FREQ_MASK = 30\n",
    "TIME_MASK = 40\n",
    "\n",
    "# Гиперпараметы обучения\n",
    "SEED = 42\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 0.002 \n",
    "WEIGHT_DECAY = 0.00001\n",
    "\n",
    "#===== Import data =====\n",
    "train_data = pd.read_csv(pt.joinpath(DATASET_PATCH,'train.csv'))\n",
    "test_data = pd.read_csv(pt.joinpath(DATASET_PATCH,'test.csv'))\n",
    "sample_data = pd.read_csv(pt.joinpath(DATASET_PATCH,'sample_submission.csv'))\n",
    "\n",
    "all_chars = Counter(\"\".join(train_data['message']))\n",
    "BLANK_CHAR = \"_\"\n",
    "vocab_list = sorted(all_chars.keys()) + [BLANK_CHAR]\n",
    "num_classes = len(vocab_list)\n",
    "char_to_int = {char: i for i, char in enumerate(vocab_list)}\n",
    "int_to_char = {i: char for i, char in enumerate(vocab_list)}\n",
    "BLANK_IDX = char_to_int[BLANK_CHAR]\n",
    "\n",
    "class MosreDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Класс для обработки \n",
    "    \"\"\"\n",
    "    def __init__(self, df, data_patch,char_to_int, train=True, transforms=None, prev_chars = 1):\n",
    "        self.df = df\n",
    "        self.is_train = train\n",
    "\n",
    "        self.data_path = data_patch\n",
    "        self.audio_paths = self.data_path / 'morse_dataset'\n",
    "\n",
    "        self.transforms = transforms\n",
    "\n",
    "        self.char_to_int = char_to_int\n",
    "        self.prev_chars = prev_chars\n",
    "\n",
    "        if self.is_train:\n",
    "            self.messeges = self.df.message.values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        #Получение аугментрованых спектрограмм\n",
    "        try:\n",
    "            audio_file = self.audio_paths / self.df.id.values[index]\n",
    "            waveform, sample_rate = torchaudio.load(audio_file)\n",
    "            augmented_spectrogram = self.transforms(waveform)\n",
    "\n",
    "            if self.is_train:\n",
    "                message = self.messeges[index]\n",
    "                #Получение списка индексов секта - как требует CTC los\n",
    "                '''\n",
    "                При обработке dataloader labels будут выравниваться по макс длине для выравнивания батча\n",
    "                Т.е. будет padding 0. что в будующем будет пустым значением для ctc loss\n",
    "                '''\n",
    "                target = torch.tensor([self.char_to_int[char] for char in message], dtype=torch.long); \n",
    "                target_len = torch.tensor(len(target), dtype=torch.long)\n",
    "                return augmented_spectrogram, target, target_len, message\n",
    "            else:\n",
    "                return augmented_spectrogram, None, None, None\n",
    "        except Exception as ex:\n",
    "            print(str(ex))\n",
    "        \n",
    "    def change_time(self, audio_file, max_len = 384000):\n",
    "        waveform, sample_rate = torchaudio.load(audio_file)\n",
    "        cahanal, sig_len = waveform.shape\n",
    "\n",
    "        if sig_len < max_len:\n",
    "            pad_len = torch.zeros(max_len - sig_len).unsqueeze(0)\n",
    "            waveform = torch.cat([waveform, pad_len], dim=1)\n",
    "\n",
    "        return waveform\n",
    "    \n",
    "FIRST_FE_COUNT = 16\n",
    "SECOND_FE_COUNT = 32\n",
    "THIRD_FE_COUNT = 32\n",
    "QAD_FE_COUNT = 32\n",
    "PADDING = 'same'\n",
    "MAXPOOL_KERNEL = 2\n",
    "KERTNEL_SIZE = 3\n",
    "NERON_COUNT = 128\n",
    "GRU_HIDEN = 512\n",
    "# Start with 4 transforms\n",
    "class MorseNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.net_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, \n",
    "                      out_channels=FIRST_FE_COUNT, \n",
    "                      kernel_size=KERTNEL_SIZE , stride=1, padding=PADDING),\n",
    "            nn.BatchNorm2d(FIRST_FE_COUNT),\n",
    "            nn.GELU(),\n",
    "            nn.MaxPool2d((1, 2), (1, 2)), # [batch, FIRST_FE_COUNT = 16, 64, 960]\n",
    "\n",
    "            nn.Conv2d(in_channels=FIRST_FE_COUNT, \n",
    "                      out_channels=SECOND_FE_COUNT, \n",
    "                      kernel_size=KERTNEL_SIZE , stride=1, padding=PADDING),\n",
    "            nn.BatchNorm2d(SECOND_FE_COUNT),\n",
    "            nn.GELU(),\n",
    "            nn.MaxPool2d((2, 1), (2, 1)), # [batch, SECOND_FE_COUNT = 32, 32, 480]\n",
    "\n",
    "            nn.Conv2d(in_channels=SECOND_FE_COUNT, \n",
    "                      out_channels=THIRD_FE_COUNT, \n",
    "                      kernel_size=KERTNEL_SIZE , stride=1, padding=PADDING),\n",
    "            nn.BatchNorm2d(THIRD_FE_COUNT),\n",
    "            nn.GELU(),\n",
    "            nn.MaxPool2d((2, 2), (2, 2)), # [batch, THIRD_FE_COUNT = 32, 16, 240]\n",
    "\n",
    "            nn.Conv2d(in_channels=THIRD_FE_COUNT, \n",
    "                      out_channels=QAD_FE_COUNT, \n",
    "                      kernel_size=KERTNEL_SIZE , stride=1, padding=PADDING),\n",
    "            nn.BatchNorm2d(QAD_FE_COUNT),\n",
    "            nn.GELU(),\n",
    "            nn.MaxPool2d((2, 1), (2, 1)) # [batch=32, QAD_FE_COUNT = 32, 8, 80](что юы сохраниить большще признаков по горизонтали)\n",
    "        )\n",
    "        with torch.no_grad(): \n",
    "            dummy_input = torch.randn(1, 1, N_MELS, 356); \n",
    "            cnn_out = self.net_conv(dummy_input); \n",
    "            self.cnn_output_features = cnn_out.shape[1] * cnn_out.shape[2]\n",
    "\n",
    "        print(f\"CNN размерность выхода: {cnn_out.shape}\"); \n",
    "        print(f\"CNN число фичей: {self.cnn_output_features}\")\n",
    "\n",
    "        # Добавлен лоейный слой и функция активации. Для чего? расписать потом \n",
    "        self.layer1 = nn.Linear(self.cnn_output_features, N_MELS*2); \n",
    "        self.gelu = nn.GELU()\n",
    "        print(f\"Проекция из {self.cnn_output_features} в {GRU_HIDEN*2}\")\n",
    "        self.rnn = nn.GRU(\n",
    "                input_size=N_MELS*2,\n",
    "                hidden_size=GRU_HIDEN,\n",
    "                num_layers=3,\n",
    "                bidirectional=True,\n",
    "                batch_first=True,\n",
    "            )\n",
    "\n",
    "        \n",
    "        self.embed_dim = GRU_HIDEN * 2\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm(self.embed_dim)   \n",
    "        # self.dropout = nn.Dropout(0.3)   \n",
    "        self.layer2 = nn.Linear(self.embed_dim, num_classes)       \n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net_conv(x)\n",
    "\n",
    "        batch, channels, reduced_mels, reduced_time = x.shape\n",
    "        x = x.permute(0, 3, 1, 2)  # [batch, time, channels, mels]\n",
    "\n",
    "        # В частности, каждый вектор признаков в последовательности признаков генерируется \n",
    "        # слева направо на картах признаков. Это означает, что i-й вектор признаков представляет \n",
    "        # собой объединение столбцов всех карт. \n",
    "        # Таким образом, форма тензора может быть изменена, например, на (размер_пакета, 80, 256)\n",
    "        \n",
    "        x = x.reshape(batch, reduced_time, -1)  # to GRU [batch=32, seq_len=89, features/hiden_dim=512]\n",
    "        x = self.layer1(x)\n",
    "        x = self.gelu(x)\n",
    "\n",
    "        self.rnn.flatten_parameters()\n",
    "\n",
    "        x = self.rnn(x) # [batch=32, seq_len=89, features/hiden_dim=256 * 2]\n",
    "        x, _ = x # берем информацию со всез состояний\n",
    "        x = self.layer_norm(x)\n",
    "        # x = self.dropout(x)\n",
    "        x = self.layer2(x) # logits - [batch, sequence, num_classes] \n",
    "        x = nn.functional.log_softmax(x.permute(1,0,2), dim=2) # pertime так как CTC loss требует на взод (sequence/T,batch/N,num_classes/C)\n",
    "        '''\n",
    "        по одному прогнозу для каждого из признаков в последовательности, \n",
    "        в итоге получается 89 прогнозов символов для каждой секунды звука.\n",
    "        '''\n",
    "        return x\n",
    "    \n",
    "\n",
    "train_audio_transforms = nn.Sequential(\n",
    "    transforms.MelSpectrogram(sample_rate=SAMPLE_RATE, n_fft=N_FFT, hop_length=HOP_LENGTH, n_mels=N_MELS),\n",
    "    transforms.AmplitudeToDB(top_db=TOP_DB),\n",
    "    transforms.FrequencyMasking(freq_mask_param=FREQ_MASK),\n",
    "    transforms.TimeMasking(time_mask_param=TIME_MASK),\n",
    "    ) \n",
    "# заметка - Данные трансформации не создают довых обучаемых параметров. Но есть и те что создают. В будущем это стоит учитывать\n",
    "\n",
    "valid_audio_transforms = nn.Sequential(\n",
    "    transforms.MelSpectrogram(sample_rate=SAMPLE_RATE, n_fft=N_FFT, hop_length=HOP_LENGTH, n_mels=N_MELS),\n",
    "    transforms.AmplitudeToDB(top_db=TOP_DB),\n",
    "\n",
    "    )\n",
    "\n",
    "train_dataframe, val_dataframe = train_test_split(train_data, test_size=0.15, random_state=SEED)\n",
    "\n",
    "train_ds = MosreDataset(df=train_dataframe,\n",
    "                        data_patch=DATASET_PATCH,\n",
    "                        char_to_int=char_to_int,\n",
    "                        train=True,\n",
    "                        transforms=train_audio_transforms)\n",
    "\n",
    "val_ds = MosreDataset(df=val_dataframe,\n",
    "                        data_patch=DATASET_PATCH,\n",
    "                        char_to_int=char_to_int,\n",
    "                        train=True,\n",
    "                        transforms=valid_audio_transforms)\n",
    "\n",
    "def my_collate(batch):\n",
    "    spectrograms = [item[0].squeeze(0) for item in batch]\n",
    "    # Падинг спектрограмм по максимальной длине\n",
    "    spectrograms_permuted = [s.permute(1, 0) for s in spectrograms]\n",
    "    spectrograms_padded = nn.utils.rnn.pad_sequence(spectrograms_permuted, batch_first=True, padding_value=0.0)\n",
    "    spectrograms_padded = spectrograms_padded.permute(0, 2, 1).unsqueeze(1)\n",
    "\n",
    "    if batch[0][3] is not None:\n",
    "        target = torch.nn.utils.rnn.pad_sequence(\n",
    "                                                [item[1] for item in batch], \n",
    "                                                batch_first=True, \n",
    "                                                padding_value=BLANK_IDX)# выравнивает последовательность до макс \n",
    "                                                                        # длины в батче заполняя пропуски нулем\n",
    "        label_len = torch.stack([item[2] for item in batch])\n",
    "        msg = [item[3] for item in batch]\n",
    "        \n",
    "        return [spectrograms_padded, target, label_len, msg]\n",
    "    else: \n",
    "        return spectrograms_padded\n",
    "\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=my_collate, drop_last=True)\n",
    "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=my_collate, drop_last=True)\n",
    "\n",
    "\n",
    "\n",
    "#===== начало обучения =====\n",
    "model = MorseNet(num_classes=num_classes).to(DEVICE)\n",
    "model = DataParallel(model)\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.2, patience=6)\n",
    "loss_func = nn.CTCLoss(blank=BLANK_IDX, reduction='mean', zero_infinity=True).to(DEVICE)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nMorseNet - инициалицация модели. Число обучаемых параметров: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be51c697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a= model(test)\n",
    "# a.shape, a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa77922d",
   "metadata": {},
   "source": [
    "Подсказка по ctc loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "222c0bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\homer\\AppData\\Local\\Temp\\ipykernel_20744\\2733710114.py:15: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\build\\aten\\src\\ATen/core/TensorBody.h:494.)\n",
      "  loss.grad\n"
     ]
    }
   ],
   "source": [
    "# Target are to be un-padded\n",
    "T = 50      # Input sequence length\n",
    "C = 20      # Number of classes (including blank)\n",
    "N = 16      # Batch size\n",
    "# Initialize random batch of input vectors, for *size = (T,N,C)\n",
    "input = torch.randn(T, N, C).log_softmax(2).detach().requires_grad_()\n",
    "input_lengths = torch.full(size=(N,), fill_value=T, dtype=torch.long)\n",
    "# Initialize random batch of targets (0 = blank, 1:C = classes)\n",
    "target_lengths = torch.randint(low=1, high=T, size=(N,), dtype=torch.long)\n",
    "target = torch.randint(low=1, high=C, size=(sum(target_lengths),), dtype=torch.long)\n",
    "ctc_loss = nn.CTCLoss()\n",
    "loss = ctc_loss(input, target, input_lengths, target_lengths)\n",
    "loss.backward()\n",
    "# input.detach().numpy().shape\n",
    "loss.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50953d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_loss_train = []\n",
    "lst_loss_val = []\n",
    "pr = []\n",
    "p_Val = []\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    epoch_train_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    pr = []\n",
    "\n",
    "    train_tqdm = tqdm(train_dl, desc=f\"Эпоха {epoch+1}/{EPOCHS} [Обучение]\", leave=False)\n",
    "    for batch_ind, batch in enumerate(train_tqdm):\n",
    "        mel_spec, targets, targets_lens, _ = batch\n",
    "        mel_spec, targets, targets_lens = mel_spec.to(DIVICE), targets.to(DIVICE), targets_lens.to(DIVICE)\n",
    "\n",
    "        #===== считатем длинну mel_spec для передачи в CTC loss =====\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predict = model(mel_spec) # (N=batch,T,C)\n",
    "        pr.append(predict)\n",
    "\n",
    "        N = predict.shape[1]\n",
    "        T = predict.shape[0]\n",
    "        predict_lengths = torch.full(size=(N,), fill_value=T, dtype=torch.long)\n",
    "\n",
    "    #     print(\"Predict shape:\", predict.shape) # [T, N, C]\n",
    "    #     print(\"Labels shape:\", targets.shape)   # [N, max_label_len]\n",
    "    #     print(\"Predict lengths:\", predict_lengths) # [N]\n",
    "    #     print(\"Target lengths:\", targets_lens.reshape(BATCH_SIZE))   # [N]\n",
    "    #     break\n",
    "    # break\n",
    "        try:\n",
    "            loss = loss_func(predict, targets, predict_lengths, targets_lens.reshape(BATCH_SIZE))\n",
    "        except RuntimeError:\n",
    "            print(predict.shape, targets.shape, predict_lengths, targets_lens.reshape(BATCH_SIZE))\n",
    "            continue\n",
    "        # print(loss)\n",
    "        if torch.isnan(loss) or torch.isinf(loss): \n",
    "            print(f\"\\nWarning: In batch-{batch_ind} loss train is NaN/Inf: {loss.item()}\"); \n",
    "            optimizer.zero_grad(); \n",
    "            continue\n",
    "\n",
    "        loss.backward()\n",
    "        # nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_train_loss += loss.item()\n",
    "        train_loss = epoch_train_loss / len(train_dl)\n",
    "\n",
    "    # ======== Валидация ========\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    all_targets = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for val_mel_spec, val_labels, val_label_lensin, _ in tqdm(\n",
    "                                                        val_dl, \n",
    "                                                        desc=f\"Эпоха {epoch+1}/{EPOCHS} [Валидация]\", \n",
    "                                                        leave=False):\n",
    "            val_mel_spec, val_labels, val_label_lensin = val_mel_spec.to(DIVICE), val_labels.to(DIVICE), val_label_lensin.to(DIVICE)\n",
    "            val_predict = model(val_mel_spec)\n",
    "\n",
    "            p_Val.append(val_predict)\n",
    "            val_N = val_predict.shape[1]\n",
    "            val_T = val_predict.shape[0]\n",
    "            predict_val_lengths = torch.full(size=(val_N,), fill_value=val_T, dtype=torch.long)\n",
    "            epoch_val_loss += loss_func(val_predict, val_labels, predict_val_lengths, val_label_lensin).item()\n",
    "            val_loss = epoch_val_loss / len(val_dl)\n",
    "\n",
    "    lst_loss_train.append(train_loss)\n",
    "    lst_loss_val.append(val_loss)\n",
    "\n",
    "    # scheduler.step(val_loss)\n",
    "\n",
    "\n",
    "            \n",
    "    print(f\"===== Эпоха {epoch+1}/{EPOCHS} =====\")\n",
    "    # print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "    grad_norms = [param.grad.norm().item() for param in model.parameters() if param.grad is not None]\n",
    "    if grad_norms:\n",
    "        print(f\"Mean grad norm: {np.mean(grad_norms):.6f}\")\n",
    "        print(f\"Max grad norm: {np.max(grad_norms):.6f}\")\n",
    "        print(f\"Min grad norm: {np.min(grad_norms):.6f}\")\n",
    "    else:\n",
    "        print(\"No gradients computed yet.\")\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}\")\n",
    "    print(f\"LR: {optimizer.param_groups[0][\"lr\"]:.2e}\")\n",
    "    print(\"\\n\"+\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa7f726",
   "metadata": {},
   "source": [
    "# Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422ea6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 1/20 =====\n",
      "Mean grad norm: 0.024823\n",
      "Max grad norm: 0.996818\n",
      "Min grad norm: 0.000000\n",
      "Train Loss: 4.2327\n",
      "Val Loss: 4.0945\n",
      "Current LR: 2.00e-03\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 2/20 =====\n",
      "Mean grad norm: 0.025902\n",
      "Max grad norm: 0.805216\n",
      "Min grad norm: 0.000000\n",
      "Train Loss: 4.0454\n",
      "Val Loss: 4.0270\n",
      "Current LR: 2.00e-03\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 3/20 =====\n",
      "Mean grad norm: 0.016852\n",
      "Max grad norm: 0.493174\n",
      "Min grad norm: 0.000000\n",
      "Train Loss: 4.0249\n",
      "Val Loss: 4.0181\n",
      "Current LR: 2.00e-03\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 4/20 =====\n",
      "Mean grad norm: 0.010962\n",
      "Max grad norm: 0.335793\n",
      "Min grad norm: 0.000000\n",
      "Train Loss: 4.0137\n",
      "Val Loss: 4.0105\n",
      "Current LR: 2.00e-03\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 5/20 [Обучение]:  39%|███▉      | 309/796 [01:20<02:15,  3.60it/s, train_loss=3.97]"
     ]
    }
   ],
   "source": [
    "lst_loss_train = []\n",
    "lst_loss_val = []\n",
    "pr = []\n",
    "p_Val = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # ======== Обучение ========\n",
    "    model.train()\n",
    "    epoch_train_loss = 0.0\n",
    "    \n",
    "    train_tqdm = tqdm(train_dl, desc=f\"Эпоха {epoch+1}/{EPOCHS} [Обучение]\", leave=False)\n",
    "    for batch_ind, batch in enumerate(train_tqdm):\n",
    "        mel_spec, targets, targets_lens, _ = batch\n",
    "        mel_spec = mel_spec.to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "        targets_lens = targets_lens.to(DEVICE)\n",
    "\n",
    "        #===== считатем длинну mel_spec для передачи в CTC loss =====\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        predict = model(mel_spec)  # (N=batch,T,C)\n",
    "        pr.append(predict)\n",
    "        \n",
    "        N = predict.shape[1]\n",
    "        T = predict.shape[0]\n",
    "        predict_lengths = torch.full(size=(N,), fill_value=T, dtype=torch.long)\n",
    "\n",
    "        try:\n",
    "            loss = loss_func(predict, targets, predict_lengths, targets_lens.reshape(BATCH_SIZE))\n",
    "        except RuntimeError:\n",
    "            print(predict.shape, targets.shape, predict_lengths, targets_lens.reshape(BATCH_SIZE))\n",
    "            continue\n",
    "\n",
    "        if torch.isnan(loss) or torch.isinf(loss): \n",
    "            print(f\"\\nWarning: In batch-{batch_ind} loss train is NaN/Inf: {loss.item()}\")\n",
    "            optimizer.zero_grad()\n",
    "            continue\n",
    "\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_train_loss += loss.item()\n",
    "        train_tqdm.set_postfix({'train_loss': loss.item()})\n",
    "\n",
    "    # Правильное усреднение после эпохи\n",
    "    train_loss = epoch_train_loss / len(train_dl)\n",
    "    lst_loss_train.append(train_loss)\n",
    "\n",
    "    # ======== Валидация ========\n",
    "    model.eval()\n",
    "    epoch_val_loss = 0.0  # Исправлено: инициализация перед циклом\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        val_tqdm = tqdm(val_dl, desc=f\"Эпоха {epoch+1}/{EPOCHS} [Валидация]\", leave=False)\n",
    "        for val_mel_spec, val_labels, val_label_lens, _ in val_tqdm:\n",
    "            val_mel_spec = val_mel_spec.to(DEVICE)\n",
    "            val_labels = val_labels.to(DEVICE)\n",
    "            val_label_lens = val_label_lens.to(DEVICE)\n",
    "            \n",
    "            val_predict = model(val_mel_spec)\n",
    "            p_Val.append(val_predict)\n",
    "            \n",
    "            val_N = val_predict.shape[1]\n",
    "            val_T = val_predict.shape[0]\n",
    "            predict_val_lengths = torch.full(size=(val_N,), fill_value=val_T, dtype=torch.long)\n",
    "            \n",
    "            loss = loss_func(val_predict, val_labels, predict_val_lengths, val_label_lens)\n",
    "            epoch_val_loss += loss.item()\n",
    "            # val_tqdm.set_postfix({'val_loss': loss.item()})\n",
    "\n",
    "    # Правильное усреднение после эпохи\n",
    "    val_loss = epoch_val_loss / len(val_dl)\n",
    "    lst_loss_val.append(val_loss)\n",
    "\n",
    "    # scheduler.step(val_loss)  \n",
    "\n",
    "    # ======== Вывод информации ========\n",
    "    print(f\"\\n===== Эпоха {epoch+1}/{EPOCHS} =====\")\n",
    "    grad_norms = [param.grad.norm().item() for param in model.parameters() if param.grad is not None]\n",
    "    if grad_norms:\n",
    "        print(f\"Mean grad norm: {np.mean(grad_norms):.6f}\")\n",
    "        print(f\"Max grad norm: {np.max(grad_norms):.6f}\")\n",
    "        print(f\"Min grad norm: {np.min(grad_norms):.6f}\")\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.4f}\")  # Средний лосс за эпоху\n",
    "    print(f\"Val Loss: {val_loss:.4f}\")     # Средний лосс за эпоху\n",
    "    print(f\"Current LR: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "    print(\"-\" * 50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca52e14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'MorseNet.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1547a2ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lst_loss_train)\n",
    "plt.plot(lst_loss_val)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58358780",
   "metadata": {},
   "source": [
    "# Проверка качества модели "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b4b4b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN размерность выхода: torch.Size([1, 32, 16, 89])\n",
      "CNN число фичей: 512\n",
      "Проекция из 512 в 1024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): MorseNet(\n",
       "    (net_conv): Sequential(\n",
       "      (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "      (4): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): GELU(approximate='none')\n",
       "      (7): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "      (8): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (9): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (10): GELU(approximate='none')\n",
       "      (11): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "      (12): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (13): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (14): GELU(approximate='none')\n",
       "      (15): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (layer1): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (gelu): GELU(approximate='none')\n",
       "    (rnn): GRU(256, 512, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "    (layer2): Linear(in_features=1024, out_features=45, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ctc_decoder(logits, int_char_map, blank_label_idx):\n",
    "    preds = []\n",
    "    logits_cpu = logits.cpu() \n",
    "    max_inds = torch.argmax(logits_cpu.detach(), dim=2).t().numpy() # арзмакс по лагитам и преобразование к словарю\n",
    "    \n",
    "    for ind in max_inds:\n",
    "        merged_inds = []\n",
    "        for idx in ind:\n",
    "            if idx != blank_label_idx: \n",
    "                merged_inds.append(idx)\n",
    "        text = \"\".join([int_char_map.get(i, '?') for i in merged_inds])\n",
    "        preds.append(text)\n",
    "\n",
    "    return preds\n",
    "\n",
    "model_load = nn.DataParallel(MorseNet(num_classes=num_classes))\n",
    "model_load.load_state_dict(torch.load('MorseNet.pth'))\n",
    "model_load.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45f65295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accurasu by The Levenshtein in train is : 0.8396696467581081\n",
      "Mean accurasu by The Levenshtein in validate is : 0.9091199388053927\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    train_mess = []\n",
    "    train_predicts = []\n",
    "    for loader in train_dl:\n",
    "        seq, test_target, _, mess = loader\n",
    "        train_mess.extend(mess)\n",
    "\n",
    "        logits = model_load(seq)\n",
    "        predicted_values = ctc_decoder(logits, int_to_char, BLANK_IDX)\n",
    "        train_predicts.extend(predicted_values)\n",
    "\n",
    "    val_mess = []\n",
    "    val_predicts = []\n",
    "    for loader in val_dl:\n",
    "        seq, test_target, _, mess = loader\n",
    "        val_mess.extend(mess)\n",
    "\n",
    "        logits= model_load(seq)\n",
    "        predicted_values = ctc_decoder(logits, int_to_char, BLANK_IDX)\n",
    "        val_predicts.extend(predicted_values)\n",
    "\n",
    "import Levenshtein\n",
    "\n",
    "mean_acc_test = np.mean([Levenshtein.ratio(test_pred, train_mess[ind]) for ind, test_pred in enumerate(train_predicts)])\n",
    "mean_acc_val = np.mean([Levenshtein.ratio(val_pred, val_mess[ind]) for ind, val_pred in enumerate(val_predicts)])\n",
    "\n",
    "\n",
    "print(f\"Mean accurasu by The Levenshtein in train is : {mean_acc_test}\")\n",
    "print(f\"Mean accurasu by The Levenshtein in validate is : {mean_acc_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07f45a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = MosreDataset(df=sample_data,\n",
    "                        data_patch=DATASET_PATCH,\n",
    "                        char_to_int=char_to_int,\n",
    "                        train=False,\n",
    "                        transforms=valid_audio_transforms)\n",
    "     \n",
    "test_dl = torch.utils.data.DataLoader(test_ds, batch_size=20, shuffle=False, collate_fn=my_collate)\n",
    "model_load.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_predicts = []\n",
    "    for loader in test_dl:\n",
    "        seq = loader\n",
    "        logits = model_load(seq)\n",
    "        predicted_values = ctc_decoder(logits, int_to_char, BLANK_IDX)\n",
    "        test_predicts.extend(predicted_values)\n",
    "\n",
    "sample_data.message = test_predicts\n",
    "sample_data.to_csv('sample_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Morse_decoder_V2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d761d8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN размерность выхода: torch.Size([1, 32, 32, 89])\n",
      "CNN число фичей: 1024\n",
      "\n",
      "MorseNet - инициалицация модели. Число обучаемых параметров: 2,939,778\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path as pt\n",
    "import torch\n",
    "import torchaudio\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchaudio import transforms\n",
    "from torchvision.transforms import v2\n",
    "# from Moduls.MosreDataset import MosreDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch.nn.parallel import DataParallel\n",
    "from collections import Counter\n",
    "\n",
    "DIVICE = torch.device('cuda')\n",
    "\n",
    "MAIN = pt(os.getcwd())\n",
    "DATASET_PATCH = MAIN / 'morse_dataset'\n",
    "AUDIO_FILES = DATASET_PATCH / 'morse_dataset'\n",
    "\n",
    "# Поятоянные значения выявленные в процессе анализа\n",
    "MORSEALP = 'АБВГДЕЁЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯ 1234567890#'\n",
    "MAX_TIME = 48\n",
    "SAMPLE_RATE = 8000\n",
    "N_MELS = 128\n",
    "N_FFT = 400\n",
    "HOP_LENGTH = 180\n",
    "TOP_DB = 80\n",
    "FREQ_MASK = 15\n",
    "TIME_MASK = 20\n",
    "\n",
    "# Гиперпараметы обучения\n",
    "SEED = 42\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 70\n",
    "LEARNING_RATE = 0.001\n",
    "WEIGHT_DECAY = 0.00001\n",
    "\n",
    "#===== Import data =====\n",
    "train_data = pd.read_csv(pt.joinpath(DATASET_PATCH,'train.csv'))\n",
    "test_data = pd.read_csv(pt.joinpath(DATASET_PATCH,'test.csv'))\n",
    "sample_data = pd.read_csv(pt.joinpath(DATASET_PATCH,'sample_submission.csv'))\n",
    "\n",
    "all_chars = Counter(''.join(train_data['message']))\n",
    "BLANK_CHAR = '_'\n",
    "vocab_list = sorted(all_chars.keys()) + [BLANK_CHAR]\n",
    "num_classes = len(vocab_list)\n",
    "char_to_int = {char: i for i, char in enumerate(vocab_list)}\n",
    "int_to_char = {i: char for i, char in enumerate(vocab_list)}\n",
    "BLANK_IDX = char_to_int[BLANK_CHAR]\n",
    "\n",
    "class MosreDataset(Dataset):\n",
    "    '''\n",
    "    Класс для обработки \n",
    "    '''\n",
    "    def __init__(self, df, data_patch,char_to_int, train=True, transforms=None, prev_chars = 1):\n",
    "        self.df = df\n",
    "        self.is_train = train\n",
    "\n",
    "        self.data_path = data_patch\n",
    "        self.audio_paths = self.data_path / 'morse_dataset'\n",
    "\n",
    "        self.transforms = transforms\n",
    "\n",
    "        self.char_to_int = char_to_int\n",
    "        self.prev_chars = prev_chars\n",
    "\n",
    "        if self.is_train:\n",
    "            self.messeges = self.df.message.values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        #Получение аугментрованых спектрограмм\n",
    "        try:\n",
    "            audio_file = self.audio_paths / self.df.id.values[index]\n",
    "            waveform, sample_rate = torchaudio.load(audio_file)\n",
    "            augmented_spectrogram = self.transforms(waveform)\n",
    "\n",
    "            if self.is_train:\n",
    "                message = self.messeges[index]\n",
    "                #Получение списка индексов секта - как требует CTC los\n",
    "                '''\n",
    "                При обработке dataloader labels будут выравниваться по макс длине для выравнивания батча\n",
    "                Т.е. будет padding 0. что в будующем будет пустым значением для ctc loss\n",
    "                '''\n",
    "                target = torch.tensor([self.char_to_int[char] for char in message], dtype=torch.long); \n",
    "                target_len = torch.tensor(len(target), dtype=torch.long)\n",
    "                return augmented_spectrogram, target, target_len, message\n",
    "            else:\n",
    "                return augmented_spectrogram, None, None, None\n",
    "        except Exception as ex:\n",
    "            print(str(ex))\n",
    "        \n",
    "    def change_time(self, audio_file, max_len = 384000):\n",
    "        waveform, sample_rate = torchaudio.load(audio_file)\n",
    "        cahanal, sig_len = waveform.shape\n",
    "\n",
    "        if sig_len < max_len:\n",
    "            pad_len = torch.zeros(max_len - sig_len).unsqueeze(0)\n",
    "            waveform = torch.cat([waveform, pad_len], dim=1)\n",
    "\n",
    "        return waveform\n",
    "    \n",
    "FIRST_FE_COUNT = 16\n",
    "SECOND_FE_COUNT = 32\n",
    "THIRD_FE_COUNT = 32\n",
    "QAD_FE_COUNT = 32\n",
    "PADDING = 1\n",
    "MAXPOOL_KERNEL = 2\n",
    "KERTNEL_SIZE = 3\n",
    "NERON_COUNT = 128\n",
    "GRU_HIDEN = 256\n",
    "\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super().__init__()\n",
    "        self.squeeze = nn.AdaptiveAvgPool2d(1)  # [B, C, 1, 1]\n",
    "        self.excitation = nn.Sequential(\n",
    "            nn.Linear(channels, channels // reduction),  # [B, C/reduction]\n",
    "            nn.GELU(),\n",
    "            nn.Linear(channels // reduction, channels),  # [B, C]\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B, C, _, _ = x.shape\n",
    "        squeezed = self.squeeze(x).view(B, C)  # [B, C]\n",
    "        weights = self.excitation(squeezed).view(B, C, 1, 1)  # [B, C, 1, 1]\n",
    "        return x * weights  # Масштабируем каналы\n",
    "    \n",
    "class MorseNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        # start - [1, 128, 356]\n",
    "        self.net_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, \n",
    "                      out_channels=FIRST_FE_COUNT, \n",
    "                      kernel_size=KERTNEL_SIZE , stride=1, padding=PADDING),\n",
    "            nn.BatchNorm2d(FIRST_FE_COUNT),\n",
    "            nn.GELU(),\n",
    "            SEBlock(FIRST_FE_COUNT),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # [batch, FIRST_FE_COUNT = 16, 64, 178]\n",
    "\n",
    "            nn.Conv2d(in_channels=FIRST_FE_COUNT, \n",
    "                      out_channels=SECOND_FE_COUNT, \n",
    "                      kernel_size=KERTNEL_SIZE , stride=1, padding=PADDING),\n",
    "            nn.BatchNorm2d(SECOND_FE_COUNT),\n",
    "            nn.GELU(),\n",
    "            SEBlock(SECOND_FE_COUNT),\n",
    "            # nn.MaxPool2d(2, 2), #\n",
    "\n",
    "            nn.Conv2d(in_channels=SECOND_FE_COUNT, \n",
    "                      out_channels=THIRD_FE_COUNT, \n",
    "                      kernel_size=KERTNEL_SIZE , stride=1, padding=PADDING),\n",
    "            nn.BatchNorm2d(THIRD_FE_COUNT),\n",
    "            nn.GELU(),\n",
    "            SEBlock(THIRD_FE_COUNT),\n",
    "            # nn.MaxPool2d((2, 2), (2, 2)), \n",
    "\n",
    "            nn.Conv2d(in_channels=THIRD_FE_COUNT, \n",
    "                      out_channels=QAD_FE_COUNT, \n",
    "                      kernel_size=KERTNEL_SIZE , stride=1, padding=PADDING),\n",
    "            nn.BatchNorm2d(QAD_FE_COUNT),\n",
    "            # SEBlock(QAD_FE_COUNT),\n",
    "            nn.GELU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2) # [batch=32, QAD_FE_COUNT = 32, 32, 89]\n",
    "        )\n",
    "        with torch.no_grad(): \n",
    "            dummy_input = torch.randn(1, 1, N_MELS, 356); \n",
    "            cnn_out = self.net_conv(dummy_input); \n",
    "            self.cnn_output_features = cnn_out.shape[1] * cnn_out.shape[2]\n",
    "\n",
    "        print(f'CNN размерность выхода: {cnn_out.shape}'); \n",
    "        print(f'CNN число фичей: {self.cnn_output_features}')\n",
    "\n",
    "        # Добавлен лоейный слой и функция активации. Для чего? расписать потом \n",
    "        self.layer1 = nn.Linear(self.cnn_output_features, N_MELS*2, bias=False); \n",
    "        self.gelu = nn.GELU()\n",
    "        self.rnn = nn.LSTM(\n",
    "                input_size=N_MELS*2,\n",
    "                hidden_size=GRU_HIDEN,\n",
    "                num_layers=2,\n",
    "                bidirectional=True,\n",
    "                dropout=0.3,\n",
    "                batch_first=True \n",
    "            )\n",
    "\n",
    "        \n",
    "        self.embed_dim = GRU_HIDEN * 2\n",
    "        self.layer_norm = nn.LayerNorm(self.embed_dim)      \n",
    "        self.dropout = nn.Dropout(0.5)   \n",
    "        self.layer2 = nn.Linear(self.embed_dim, num_classes)       \n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net_conv(x)\n",
    "\n",
    "        batch, channels, reduced_mels, reduced_time = x.shape\n",
    "        x = x.permute(0, 3, 1, 2)  # [batch, time, channels, mels]\n",
    "\n",
    "        # В частности, каждый вектор признаков в последовательности признаков генерируется \n",
    "        # слева направо на картах признаков. Это означает, что i-й вектор признаков представляет \n",
    "        # собой объединение столбцов всех карт. \n",
    "        # Таким образом, форма тензора может быть изменена, например, на (размер_пакета, 80, 256)\n",
    "        \n",
    "        x = x.reshape(batch, reduced_time, -1)  # to GRU [batch=32, seq_len=89, features/hiden_dim=512]\n",
    "        x = self.layer1(x)\n",
    "        x = self.gelu(x)\n",
    "\n",
    "        self.rnn.flatten_parameters()\n",
    "\n",
    "        x = self.rnn(x) # [batch=32, seq_len=89, features/hiden_dim=256 * 2]\n",
    "        x, _ = x # берем информацию со всез состояний\n",
    "        x = self.layer_norm(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer2(x) # logits - [batch, sequence, num_classes] \n",
    "        x = nn.functional.log_softmax(x.permute(1,0,2), dim=2) # pertime так как CTC loss требует на взод (sequence/T,batch/N,num_classes/C)\n",
    "        '''\n",
    "        по одному прогнозу для каждого из признаков в последовательности, \n",
    "        в итоге получается 89 прогнозов символов для каждой секунды звука.\n",
    "        # '''\n",
    "        return x\n",
    "    \n",
    "\n",
    "train_audio_transforms = nn.Sequential(\n",
    "    transforms.MelSpectrogram(sample_rate=SAMPLE_RATE, n_fft=N_FFT, hop_length=HOP_LENGTH, n_mels=N_MELS),\n",
    "    transforms.AmplitudeToDB(top_db=TOP_DB),\n",
    "    transforms.FrequencyMasking(freq_mask_param=FREQ_MASK),\n",
    "    transforms.TimeMasking(time_mask_param=TIME_MASK),\n",
    "    # v2.RandomCrop((N_MELS, 1920)) # Обрезает последний кадр спектрограммы, в идеале надобы считать а не прописывать число\n",
    "    ) # заметка - Данные трансформации не создают довых обучаемых параметров. Но есть и те что создают. В будущем это стоит учитывать\n",
    "\n",
    "valid_audio_transforms = nn.Sequential(\n",
    "    transforms.MelSpectrogram(sample_rate=SAMPLE_RATE, n_fft=N_FFT, hop_length=HOP_LENGTH, n_mels=N_MELS),\n",
    "    transforms.AmplitudeToDB(top_db=TOP_DB),\n",
    "    # v2.CenterCrop((N_MELS, 1920)) \n",
    "    )\n",
    "\n",
    "train_dataframe, val_dataframe = train_test_split(train_data, test_size=0.15, random_state=SEED)\n",
    "\n",
    "train_ds = MosreDataset(df=train_dataframe,\n",
    "                        data_patch=DATASET_PATCH,\n",
    "                        char_to_int=char_to_int,\n",
    "                        train=True,\n",
    "                        transforms=train_audio_transforms)\n",
    "\n",
    "val_ds = MosreDataset(df=val_dataframe,\n",
    "                        data_patch=DATASET_PATCH,\n",
    "                        char_to_int=char_to_int,\n",
    "                        train=True,\n",
    "                        transforms=valid_audio_transforms)\n",
    "\n",
    "\n",
    "def my_collate(batch):\n",
    "    spectrograms = [item[0].squeeze(0) for item in batch]\n",
    "    # Падинг спектрограмм по максимальной длине\n",
    "    spectrograms_permuted = [s.permute(1, 0) for s in spectrograms]\n",
    "    spectrograms_padded = nn.utils.rnn.pad_sequence(spectrograms_permuted, batch_first=True, padding_value=0.0)\n",
    "    spectrograms_padded = spectrograms_padded.permute(0, 2, 1).unsqueeze(1)\n",
    "\n",
    "    if batch[0][3] is not None:\n",
    "        target = torch.nn.utils.rnn.pad_sequence(\n",
    "                                                [item[1] for item in batch], \n",
    "                                                batch_first=True, \n",
    "                                                padding_value=BLANK_IDX)# выравнивает последовательность до макс \n",
    "                                                                        # длины в батче заполняя пропуски нулем\n",
    "        label_len = torch.stack([item[2] for item in batch])\n",
    "        msg = [item[3] for item in batch]\n",
    "        \n",
    "        return [spectrograms_padded, target, label_len, msg]\n",
    "    else: \n",
    "        return spectrograms_padded\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=my_collate, drop_last=True)\n",
    "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=my_collate, drop_last=True)\n",
    "\n",
    "test, test_target, _, mess = next(iter(train_dl))\n",
    "test, test_target= test.to(DIVICE), test_target.to(DIVICE)\n",
    "\n",
    "test_val, val_target, __, val_mess = next(iter(val_dl))\n",
    "test_val, val_target = test_val.to(DIVICE), val_target.to(DIVICE)\n",
    "# test.shape \n",
    "\n",
    "#===== начало обучения =====\n",
    "model = MorseNet(num_classes=num_classes).to(DIVICE)\n",
    "# model = DataParallel(model)\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=LEARNING_RATE)  # Было 0.002\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "loss_func = nn.CTCLoss(blank=BLANK_IDX, reduction='mean', zero_infinity=True).to(DIVICE)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'\\nMorseNet - инициалицация модели. Число обучаемых параметров: {total_params:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68c51ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 356])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(test)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa7f726",
   "metadata": {},
   "source": [
    "# Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422ea6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 1/70 =====\n",
      "Mean grad norm: 0.067728\n",
      "Max grad norm: 0.627811\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.001000\n",
      "---- Train Loss: 3.4459\n",
      "---- Val Loss: 1.1578\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 2/70 =====\n",
      "Mean grad norm: 0.057049\n",
      "Max grad norm: 0.671087\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.001000\n",
      "---- Train Loss: 0.7479\n",
      "---- Val Loss: 0.3471\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 3/70 =====\n",
      "Mean grad norm: 0.063624\n",
      "Max grad norm: 0.696028\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.001000\n",
      "---- Train Loss: 0.5143\n",
      "---- Val Loss: 0.2498\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 4/70 =====\n",
      "Mean grad norm: 0.069919\n",
      "Max grad norm: 0.565835\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.001000\n",
      "---- Train Loss: 0.4345\n",
      "---- Val Loss: 0.2217\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 5/70 =====\n",
      "Mean grad norm: 0.066804\n",
      "Max grad norm: 0.688251\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.001000\n",
      "---- Train Loss: 0.3921\n",
      "---- Val Loss: 0.2525\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 6/70 =====\n",
      "Mean grad norm: 0.065438\n",
      "Max grad norm: 0.703019\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.001000\n",
      "---- Train Loss: 0.3618\n",
      "---- Val Loss: 0.1968\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 7/70 =====\n",
      "Mean grad norm: 0.070321\n",
      "Max grad norm: 0.641522\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.001000\n",
      "---- Train Loss: 0.3437\n",
      "---- Val Loss: 0.2088\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 8/70 =====\n",
      "Mean grad norm: 0.073640\n",
      "Max grad norm: 0.547426\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.001000\n",
      "---- Train Loss: 0.3319\n",
      "---- Val Loss: 0.1652\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 9/70 =====\n",
      "Mean grad norm: 0.075331\n",
      "Max grad norm: 0.589363\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.001000\n",
      "---- Train Loss: 0.3134\n",
      "---- Val Loss: 0.1618\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 10/70 =====\n",
      "Mean grad norm: 0.074738\n",
      "Max grad norm: 0.552752\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.001000\n",
      "---- Train Loss: 0.3009\n",
      "---- Val Loss: 0.1675\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 11/70 =====\n",
      "Mean grad norm: 0.062511\n",
      "Max grad norm: 0.360322\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.001000\n",
      "---- Train Loss: 0.2884\n",
      "---- Val Loss: 0.1505\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 12/70 =====\n",
      "Mean grad norm: 0.052764\n",
      "Max grad norm: 0.361552\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.001000\n",
      "---- Train Loss: 0.2809\n",
      "---- Val Loss: 0.1615\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 13/70 =====\n",
      "Mean grad norm: 0.059757\n",
      "Max grad norm: 0.804557\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.001000\n",
      "---- Train Loss: 0.2770\n",
      "---- Val Loss: 0.1513\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 14/70 =====\n",
      "Mean grad norm: 0.063033\n",
      "Max grad norm: 0.400451\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.001000\n",
      "---- Train Loss: 0.2729\n",
      "---- Val Loss: 0.1494\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 15/70 =====\n",
      "Mean grad norm: 0.080952\n",
      "Max grad norm: 0.603744\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.001000\n",
      "---- Train Loss: 0.2654\n",
      "---- Val Loss: 0.1576\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 16/70 =====\n",
      "Mean grad norm: 0.076044\n",
      "Max grad norm: 0.532180\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.001000\n",
      "---- Train Loss: 0.2567\n",
      "---- Val Loss: 0.1477\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 17/70 =====\n",
      "Mean grad norm: 0.071414\n",
      "Max grad norm: 0.704624\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.001000\n",
      "---- Train Loss: 0.2517\n",
      "---- Val Loss: 0.1517\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 18/70 =====\n",
      "Mean grad norm: 0.070031\n",
      "Max grad norm: 0.488423\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.001000\n",
      "---- Train Loss: 0.2522\n",
      "---- Val Loss: 0.1394\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 19/70 =====\n",
      "Mean grad norm: 0.061508\n",
      "Max grad norm: 0.369924\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.001000\n",
      "---- Train Loss: 0.2434\n",
      "---- Val Loss: 0.1362\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 20/70 =====\n",
      "Mean grad norm: 0.066800\n",
      "Max grad norm: 0.649132\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.001000\n",
      "---- Train Loss: 0.2409\n",
      "---- Val Loss: 0.1386\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 21/70 =====\n",
      "Mean grad norm: 0.072841\n",
      "Max grad norm: 0.728541\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.001000\n",
      "---- Train Loss: 0.2350\n",
      "---- Val Loss: 0.1458\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 22/70 =====\n",
      "Mean grad norm: 0.049989\n",
      "Max grad norm: 0.287582\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.001000\n",
      "---- Train Loss: 0.2327\n",
      "---- Val Loss: 0.1454\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 23/70 =====\n",
      "Mean grad norm: 0.075500\n",
      "Max grad norm: 0.609054\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.000500\n",
      "---- Train Loss: 0.2297\n",
      "---- Val Loss: 0.1397\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 24/70 =====\n",
      "Mean grad norm: 0.075838\n",
      "Max grad norm: 0.613378\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.000500\n",
      "---- Train Loss: 0.2062\n",
      "---- Val Loss: 0.1422\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 25/70 =====\n",
      "Mean grad norm: 0.040971\n",
      "Max grad norm: 0.261296\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.000500\n",
      "---- Train Loss: 0.1968\n",
      "---- Val Loss: 0.1317\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 26/70 =====\n",
      "Mean grad norm: 0.055147\n",
      "Max grad norm: 0.539284\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.000500\n",
      "---- Train Loss: 0.1955\n",
      "---- Val Loss: 0.1394\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 27/70 =====\n",
      "Mean grad norm: 0.049105\n",
      "Max grad norm: 0.375488\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.000500\n",
      "---- Train Loss: 0.1916\n",
      "---- Val Loss: 0.1367\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 28/70 =====\n",
      "Mean grad norm: 0.063528\n",
      "Max grad norm: 0.653781\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.000500\n",
      "---- Train Loss: 0.1880\n",
      "---- Val Loss: 0.1411\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 29/70 =====\n",
      "Mean grad norm: 0.051385\n",
      "Max grad norm: 0.362836\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.000250\n",
      "---- Train Loss: 0.1880\n",
      "---- Val Loss: 0.1417\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 30/70 =====\n",
      "Mean grad norm: 0.038507\n",
      "Max grad norm: 0.342610\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.000250\n",
      "---- Train Loss: 0.1760\n",
      "---- Val Loss: 0.1427\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 31/70 =====\n",
      "Mean grad norm: 0.063998\n",
      "Max grad norm: 0.375559\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.000250\n",
      "---- Train Loss: 0.1724\n",
      "---- Val Loss: 0.1459\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 32/70 =====\n",
      "Mean grad norm: 0.073506\n",
      "Max grad norm: 0.698338\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.000250\n",
      "---- Train Loss: 0.1697\n",
      "---- Val Loss: 0.1452\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 33/70 =====\n",
      "Mean grad norm: 0.036305\n",
      "Max grad norm: 0.279655\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.000125\n",
      "---- Train Loss: 0.1656\n",
      "---- Val Loss: 0.1468\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 34/70 =====\n",
      "Mean grad norm: 0.031936\n",
      "Max grad norm: 0.149740\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.000125\n",
      "---- Train Loss: 0.1589\n",
      "---- Val Loss: 0.1463\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 35/70 =====\n",
      "Mean grad norm: 0.084062\n",
      "Max grad norm: 0.519938\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.000125\n",
      "---- Train Loss: 0.1608\n",
      "---- Val Loss: 0.1461\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 36/70 =====\n",
      "Mean grad norm: 0.032296\n",
      "Max grad norm: 0.184899\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.000125\n",
      "---- Train Loss: 0.1562\n",
      "---- Val Loss: 0.1491\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 37/70 =====\n",
      "Mean grad norm: 0.056374\n",
      "Max grad norm: 0.355176\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.000063\n",
      "---- Train Loss: 0.1558\n",
      "---- Val Loss: 0.1503\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 38/70 =====\n",
      "Mean grad norm: 0.041048\n",
      "Max grad norm: 0.298149\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.000063\n",
      "---- Train Loss: 0.1565\n",
      "---- Val Loss: 0.1504\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 39/70 =====\n",
      "Mean grad norm: 0.079500\n",
      "Max grad norm: 0.577579\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.000063\n",
      "---- Train Loss: 0.1556\n",
      "---- Val Loss: 0.1487\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 40/70 =====\n",
      "Mean grad norm: 0.047452\n",
      "Max grad norm: 0.341132\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.000063\n",
      "---- Train Loss: 0.1523\n",
      "---- Val Loss: 0.1501\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 41/70 =====\n",
      "Mean grad norm: 0.050903\n",
      "Max grad norm: 0.286214\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.000031\n",
      "---- Train Loss: 0.1527\n",
      "---- Val Loss: 0.1510\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 42/70 =====\n",
      "Mean grad norm: 0.060630\n",
      "Max grad norm: 0.390849\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.000031\n",
      "---- Train Loss: 0.1483\n",
      "---- Val Loss: 0.1546\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 43/70 =====\n",
      "Mean grad norm: 0.044094\n",
      "Max grad norm: 0.321819\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.000031\n",
      "---- Train Loss: 0.1527\n",
      "---- Val Loss: 0.1529\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m train_predicts = []\n\u001b[32m     10\u001b[39m train_tqdm = tqdm(train_dl, desc=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mЭпоха \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m [Обучение]\u001b[39m\u001b[33m\"\u001b[39m, leave=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_ind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_tqdm\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmel_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets_lens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmel_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets_lens\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmel_spec\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDIVICE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDIVICE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets_lens\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDIVICE\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\homer\\OneDrive\\Desktop\\Morse_Decoder_V2\\Morse_decoder_V2\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\homer\\OneDrive\\Desktop\\Morse_Decoder_V2\\Morse_decoder_V2\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\homer\\OneDrive\\Desktop\\Morse_Decoder_V2\\Morse_decoder_V2\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:789\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    788\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    790\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    791\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\homer\\OneDrive\\Desktop\\Morse_Decoder_V2\\Morse_decoder_V2\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 83\u001b[39m, in \u001b[36mMosreDataset.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     82\u001b[39m     audio_file = \u001b[38;5;28mself\u001b[39m.audio_paths / \u001b[38;5;28mself\u001b[39m.df.id.values[index]\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m     waveform, sample_rate = \u001b[43mtorchaudio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     84\u001b[39m     augmented_spectrogram = \u001b[38;5;28mself\u001b[39m.transforms(waveform)\n\u001b[32m     86\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_train:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\homer\\OneDrive\\Desktop\\Morse_Decoder_V2\\Morse_decoder_V2\\Lib\\site-packages\\torchaudio\\_backend\\utils.py:205\u001b[39m, in \u001b[36mget_load_func.<locals>.load\u001b[39m\u001b[34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size, backend)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Load audio data from source.\u001b[39;00m\n\u001b[32m    129\u001b[39m \n\u001b[32m    130\u001b[39m \u001b[33;03mBy default (``normalize=True``, ``channels_first=True``), this function returns Tensor with\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    202\u001b[39m \u001b[33;03m        `[channel, time]` else `[time, channel]`.\u001b[39;00m\n\u001b[32m    203\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    204\u001b[39m backend = dispatcher(uri, \u001b[38;5;28mformat\u001b[39m, backend)\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\homer\\OneDrive\\Desktop\\Morse_Decoder_V2\\Morse_decoder_V2\\Lib\\site-packages\\torchaudio\\_backend\\soundfile.py:27\u001b[39m, in \u001b[36mSoundfileBackend.load\u001b[39m\u001b[34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\n\u001b[32m     19\u001b[39m     uri: Union[BinaryIO, \u001b[38;5;28mstr\u001b[39m, os.PathLike],\n\u001b[32m   (...)\u001b[39m\u001b[32m     25\u001b[39m     buffer_size: \u001b[38;5;28mint\u001b[39m = \u001b[32m4096\u001b[39m,\n\u001b[32m     26\u001b[39m ) -> Tuple[torch.Tensor, \u001b[38;5;28mint\u001b[39m]:\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msoundfile_backend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\homer\\OneDrive\\Desktop\\Morse_Decoder_V2\\Morse_decoder_V2\\Lib\\site-packages\\torchaudio\\_backend\\soundfile_backend.py:230\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(filepath, frame_offset, num_frames, normalize, channels_first, format)\u001b[39m\n\u001b[32m    227\u001b[39m         dtype = _SUBTYPE2DTYPE[file_.subtype]\n\u001b[32m    229\u001b[39m     frames = file_._prepare_read(frame_offset, \u001b[38;5;28;01mNone\u001b[39;00m, num_frames)\n\u001b[32m--> \u001b[39m\u001b[32m230\u001b[39m     waveform = \u001b[43mfile_\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malways_2d\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    231\u001b[39m     sample_rate = file_.samplerate\n\u001b[32m    233\u001b[39m waveform = torch.from_numpy(waveform)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\homer\\OneDrive\\Desktop\\Morse_Decoder_V2\\Morse_decoder_V2\\Lib\\site-packages\\soundfile.py:942\u001b[39m, in \u001b[36mSoundFile.read\u001b[39m\u001b[34m(self, frames, dtype, always_2d, fill_value, out)\u001b[39m\n\u001b[32m    940\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m frames < \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m frames > \u001b[38;5;28mlen\u001b[39m(out):\n\u001b[32m    941\u001b[39m         frames = \u001b[38;5;28mlen\u001b[39m(out)\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m frames = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_array_io\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mread\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) > frames:\n\u001b[32m    944\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m fill_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\homer\\OneDrive\\Desktop\\Morse_Decoder_V2\\Morse_decoder_V2\\Lib\\site-packages\\soundfile.py:1394\u001b[39m, in \u001b[36mSoundFile._array_io\u001b[39m\u001b[34m(self, action, array, frames)\u001b[39m\n\u001b[32m   1392\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m array.dtype.itemsize == _ffi.sizeof(ctype)\n\u001b[32m   1393\u001b[39m cdata = _ffi.cast(ctype + \u001b[33m'\u001b[39m\u001b[33m*\u001b[39m\u001b[33m'\u001b[39m, array.__array_interface__[\u001b[33m'\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m'\u001b[39m][\u001b[32m0\u001b[39m])\n\u001b[32m-> \u001b[39m\u001b[32m1394\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cdata_io\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\homer\\OneDrive\\Desktop\\Morse_Decoder_V2\\Morse_decoder_V2\\Lib\\site-packages\\soundfile.py:1403\u001b[39m, in \u001b[36mSoundFile._cdata_io\u001b[39m\u001b[34m(self, action, data, ctype, frames)\u001b[39m\n\u001b[32m   1401\u001b[39m     curr = \u001b[38;5;28mself\u001b[39m.tell()\n\u001b[32m   1402\u001b[39m func = \u001b[38;5;28mgetattr\u001b[39m(_snd, \u001b[33m'\u001b[39m\u001b[33msf_\u001b[39m\u001b[33m'\u001b[39m + action + \u001b[33m'\u001b[39m\u001b[33mf_\u001b[39m\u001b[33m'\u001b[39m + ctype)\n\u001b[32m-> \u001b[39m\u001b[32m1403\u001b[39m frames = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1404\u001b[39m _error_check(\u001b[38;5;28mself\u001b[39m._errorcode)\n\u001b[32m   1405\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.seekable():\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "lst_loss_train = []\n",
    "lst_loss_val = []\n",
    "best_val_loss = 0\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "\n",
    "    epoch_train_loss = 0.0\n",
    "    train_predicts = []\n",
    "\n",
    "    train_tqdm = tqdm(train_dl, desc=f'Эпоха {epoch+1}/{EPOCHS} [Обучение]', leave=False)\n",
    "    for batch_ind, batch in enumerate(train_tqdm):\n",
    "        mel_spec, targets, targets_lens, _ = batch\n",
    "        mel_spec, targets, targets_lens = mel_spec.to(DIVICE), targets.to(DIVICE), targets_lens.to(DIVICE)\n",
    "\n",
    "        #===== считатем длинну mel_spec для передачи в CTC loss =====\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predict = model(mel_spec) # (N=batch,T,C)\n",
    "        N = predict.shape[1]\n",
    "        T = predict.shape[0]\n",
    "        predict_lengths = torch.full(size=(N,), fill_value=T, dtype=torch.long)\n",
    "\n",
    "        try:\n",
    "            loss = loss_func(predict, targets, predict_lengths, targets_lens.reshape(BATCH_SIZE))\n",
    "        except RuntimeError:\n",
    "            print(predict.shape, targets.shape, predict_lengths, targets_lens.reshape(BATCH_SIZE))\n",
    "            continue\n",
    "\n",
    "        if torch.isnan(loss) or torch.isinf(loss): \n",
    "            print(f'\\nWarning: In batch-{batch_ind} loss train is NaN/Inf: {loss.item()}'); \n",
    "            optimizer.zero_grad(); \n",
    "            continue\n",
    "\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_train_loss += loss.item()\n",
    "\n",
    "    total_train = epoch_train_loss / len(train_dl)\n",
    "\n",
    "    # ======== Валидация ========\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    total_val = 0\n",
    "    val_predicts = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for val_mel_spec, val_labels, val_label_lensin, _ in tqdm(\n",
    "                                                        val_dl, \n",
    "                                                        desc=f'Эпоха {epoch+1}/{EPOCHS} [Валидация]', \n",
    "                                                        leave=False):\n",
    "            val_mel_spec, val_labels, val_label_lensin = val_mel_spec.to(DIVICE), val_labels.to(DIVICE), val_label_lensin.to(DIVICE)\n",
    "            val_predict = model(val_mel_spec)\n",
    "\n",
    "            val_N = val_predict.shape[1]\n",
    "            val_T = val_predict.shape[0]\n",
    "            predict_val_lengths = torch.full(size=(val_N,), fill_value=val_T, dtype=torch.long)\n",
    "            val_loss += loss_func(val_predict, val_labels, predict_val_lengths, val_label_lensin).item()\n",
    "\n",
    "    total_val = val_loss / len(val_dl)\n",
    "\n",
    "    lst_loss_train.append(total_train)\n",
    "    lst_loss_val.append(total_val)\n",
    "\n",
    "    scheduler.step(total_val)\n",
    "\n",
    "    print(f'\\n===== Эпоха {epoch+1}/{EPOCHS} =====')\\\n",
    "    #===== Инфо про градиенты=====\n",
    "    grad_norms = [param.grad.norm().item() for param in model.parameters() if param.grad is not None]\n",
    "    if grad_norms:\n",
    "        print(f'Mean grad norm: {np.mean(grad_norms):.6f}')\n",
    "        print(f'Max grad norm: {np.max(grad_norms):.6f}')\n",
    "        print(f'Min grad norm: {np.min(grad_norms):.6f}')\n",
    "    else:\n",
    "        print('No gradients computed yet.')\n",
    "    #===== Инфо про шаг обучения и данные по потерям =====\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    print(f'Current LR: {current_lr:.6f}')\n",
    "    print(f'---- Train Loss: {total_train:.4f}')\n",
    "    print(f'---- Val Loss: {total_val:.4f}')\n",
    "    if current_lr <= 1e-6:\n",
    "        print('Learning rate достиг минимума 1e-6, остановка обучения')\n",
    "        break\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca52e14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'MorseNet.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1547a2ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAQj5JREFUeJzt3XuYFOWB7/Ff9X2GuXGRGS6DYEAEFQS8jW4iRi6ij5HNHjdLksUYdc8msI+GnHgOeRKVmASfNUbNxtW4mpC9EI3uAU8SFSYoEAJeuCVAlKASQJgZQJj7THd1V50/qrvnQvcwPfSFpr+f56mnuqurqt/pd6B/875vvWXYtm0LAAAgR1y5LgAAAChshBEAAJBThBEAAJBThBEAAJBThBEAAJBThBEAAJBThBEAAJBThBEAAJBTnlwXoD8sy9KRI0dUWloqwzByXRwAANAPtm2rpaVFI0eOlMuVvP0jL8LIkSNHVF1dnetiAACAATh06JBGjx6d9PW8CCOlpaWSnB+mrKwsbec1TVNr167VnDlz5PV603ZeZAb1lT+oq/xBXeWXfKuv5uZmVVdXx7/Hk8mLMBLrmikrK0t7GCkuLlZZWVleVGqho77yB3WVP6ir/JKv9XW6IRYMYAUAADlFGAEAADlFGAEAADlFGAEAADmVUhh56qmnNGXKlPhA0pqaGr366qtJ91+xYoUMw+ixBAKBMy40AAA4d6R0Nc3o0aP18MMPa8KECbJtWz//+c916623aseOHbr44osTHlNWVqa9e/fGnzNpGQAA6C6lMHLLLbf0eP69731PTz31lN58882kYcQwDFVVVQ28hAAA4Jw24HlGIpGIXnzxRbW1tammpibpfq2trTr//PNlWZamT5+u73//+0mDS0wwGFQwGIw/b25uluRcX22a5kCLfIrYudJ5TmQO9ZU/qKv8QV3ll3yrr/6W07Bt207lxLt27VJNTY06OztVUlKilStX6qabbkq475YtW7Rv3z5NmTJFTU1N+sEPfqCNGzdqz549fU4L++CDD2rZsmWnbF+5cqWKi4tTKS4AAMiR9vZ2ff7zn1dTU1Ofk5amHEZCoZAOHjyopqYmvfTSS3r22We1YcMGTZ48+bTHmqapSZMmacGCBXrooYeS7peoZaS6ulrHjx9P+wystbW1mj17dl7NZFeoqK/8QV3lD+oqv+RbfTU3N2vYsGGnDSMpd9P4fD6NHz9ekjRjxgy98847euKJJ/STn/zktMd6vV5NmzZN77//fp/7+f1++f3+hMdn4sPP1HmRGdRX/qCu8gd1lV/ypb76W8YznmfEsqwerRh9iUQi2rVrl0aMGHGmbwsAAM4RKbWMLF26VPPmzdOYMWPU0tKilStXav369VqzZo0kaeHChRo1apSWL18uSfrOd76jq6++WuPHj1djY6MeeeQRHThwQHfddVf6f5IB+NnmA/rdhy6Nb2jRxaOH5Lo4AAAUpJTCyNGjR7Vw4ULV1dWpvLxcU6ZM0Zo1azR79mxJ0sGDB+VydTW2nDx5Unfffbfq6+s1ePBgzZgxQ5s3b+7X+JJseHV3vXY0uLTg4w5dnHw8LQAAyKCUwshzzz3X5+vr16/v8fyxxx7TY489lnKhsqXI65YkdZiRHJcEAIDCVdD3pglEw0gnYQQAgJwp6DBCywgAALlX0GEk4HN+/E7TynFJAAAoXAUdRmgZAQAg9wo6jDBmBACA3CvoMFLkdX58WkYAAMidgg4jgXg3DWNGAADIlYIOI7ExI50hWkYAAMiVgg4jAQawAgCQcwUdRmJjRhjACgBA7hR4GGHMCAAAuVbQYSTg49JeAAByraDDCJOeAQCQewUdRgJepoMHACDXCjqM0DICAEDuFXYYYcwIAAA5V9hhJNoyYkZsmRG6agAAyIWCDiOxSc8kWkcAAMiVgg4jPrchQ7YkqYMp4QEAyImCDiOGYcgX/QQYxAoAQG4UdBiRpFhPDWEEAIDcKPgwEm8ZoZsGAICcIIzQTQMAQE4VfBiJTsLK1TQAAORIwYeRrm4a5hkBACAXCCPu6KW9tIwAAJATBR9GvIwZAQAgpwo+jMS6aTq5mgYAgJwgjNAyAgBAThV8GGHSMwAAcqvgwwiTngEAkFuEEZdzNQ3zjAAAkBsFH0a4mgYAgNwq+DDii40ZoZsGAICcIIzQMgIAQE4VfBjh3jQAAORWwYcRWkYAAMgtwkj0ahrGjAAAkBuEkegA1k6Tu/YCAJALhBG6aQAAyKmUwshTTz2lKVOmqKysTGVlZaqpqdGrr77a5zEvvviiLrroIgUCAV166aV65ZVXzqjA6RYbwNoeCue2IAAAFKiUwsjo0aP18MMPa9u2bdq6das+/elP69Zbb9WePXsS7r9582YtWLBAd955p3bs2KH58+dr/vz52r17d1oKnw7du2ksy85tYQAAKEAphZFbbrlFN910kyZMmKALL7xQ3/ve91RSUqI333wz4f5PPPGEbrzxRn3jG9/QpEmT9NBDD2n69On68Y9/nJbCp4Ov2ycQDDNuBACAbPMM9MBIJKIXX3xRbW1tqqmpSbjPli1btGTJkh7b5s6dq9WrV/d57mAwqGAwGH/e3NwsSTJNU6ZpDrTIpzBNM95NI0nN7Z3yGL60nR/pFav7dP4OIDOoq/xBXeWXfKuv/pYz5TCya9cu1dTUqLOzUyUlJVq1apUmT56ccN/6+npVVlb22FZZWan6+vo+32P58uVatmzZKdvXrl2r4uLiVIvcJ5cheQxbYdvQK2t/qyH+tJ4eGVBbW5vrIqCfqKv8QV3ll3ypr/b29n7tl3IYmThxonbu3Kmmpia99NJLuv3227Vhw4akgWQgli5d2qNFpbm5WdXV1ZozZ47KysrS9j6maaq2tlbFfq+aO8Oq+avr9InzBqXt/EivWH3Nnj1bXq8318VBH6ir/EFd5Zd8q69Yz8bppBxGfD6fxo8fL0maMWOG3nnnHT3xxBP6yU9+csq+VVVVamho6LGtoaFBVVVVfb6H3++X339qE4XX683Ih1/kc6u5M6ywbeRF5Ra6TP0eIP2oq/xBXeWXfKmv/pbxjOcZsSyrx/iO7mpqarRu3boe22pra5OOMcmVIq9zSQ1zjQAAkH0ptYwsXbpU8+bN05gxY9TS0qKVK1dq/fr1WrNmjSRp4cKFGjVqlJYvXy5Juueee3Tdddfp0Ucf1c0336znn39eW7du1TPPPJP+n+QMBGJhhCnhAQDIupTCyNGjR7Vw4ULV1dWpvLxcU6ZM0Zo1azR79mxJ0sGDB+VydTW2XHPNNVq5cqW+9a1v6Zvf/KYmTJig1atX65JLLknvT3GGiqKX1NAyAgBA9qUURp577rk+X1+/fv0p22677TbddtttKRUq22LdNJ2EEQAAsq7g700j0U0DAEAuEUbEAFYAAHKJMCIp4GPMCAAAuUIYUbcxI3TTAACQdYQRdRszQssIAABZRxgRl/YCAJBLhBF1v5rGynFJAAAoPIQRMc8IAAC5RBgRY0YAAMglwoikYh+TngEAkCuEEUkBBrACAJAzhBExZgQAgFwijKgrjLTTTQMAQNYRRsQAVgAAcokwIqkoem8apoMHACD7CCOiZQQAgFwijKhrzEjYsmVGmIUVAIBsIoyoq2VEonUEAIBsI4xI8rkNuQznMeNGAADILsKIJMMw4l01tIwAAJBdhJGoIh9hBACAXCCMRMWvqKGbBgCArCKMRNFNAwBAbhBGomLdNNyfBgCA7CKMRHV10zDPCAAA2UQYiaKbBgCA3CCMRBFGAADIDcJIVHzMCFfTAACQVYSRKG6WBwBAbhBGouimAQAgNwgjUUU+56Ng0jMAALKLMBJV7PNIYp4RAACyjTASxZgRAABygzASVcS9aQAAyAnCSFR8zAgtIwAAZBVhJIqWEQAAcoMwEsWYEQAAcoMwEsU8IwAA5AZhJIrp4AEAyI2Uwsjy5ct1xRVXqLS0VMOHD9f8+fO1d+/ePo9ZsWKFDMPosQQCgTMqdCbQMgIAQG6kFEY2bNigRYsW6c0331Rtba1M09ScOXPU1tbW53FlZWWqq6uLLwcOHDijQmcCY0YAAMgNTyo7v/baaz2er1ixQsOHD9e2bdv0qU99KulxhmGoqqpqYCXMkng3jWnJsmy5XEaOSwQAQGFIKYz01tTUJEkaMmRIn/u1trbq/PPPl2VZmj59ur7//e/r4osvTrp/MBhUMBiMP29ubpYkmaYp0zTPpMg9xM5lmqY86gofrR3BeDjB2aN7feHsRl3lD+oqv+RbffW3nIZt2/ZA3sCyLH3mM59RY2OjNm3alHS/LVu2aN++fZoyZYqampr0gx/8QBs3btSePXs0evTohMc8+OCDWrZs2SnbV65cqeLi4oEU97QsW/ram042+97lYZV4M/I2AAAUjPb2dn3+859XU1OTysrKku434DDyla98Ra+++qo2bdqUNFQkYpqmJk2apAULFuihhx5KuE+ilpHq6modP368zx8mVaZpqra2VrNnz5bX69XFy36rUNjShq9/UiMritL2PkiP3vWFsxd1lT+oq/ySb/XV3NysYcOGnTaMDKibZvHixfr1r3+tjRs3phREJMnr9WratGl6//33k+7j9/vl9/sTHpuJDz923iKvW6GwJdN25UUlF6pM/R4g/air/EFd5Zd8qa/+ljGlq2ls29bixYu1atUqvf766xo3blzKBYtEItq1a5dGjBiR8rGZFru8t5MragAAyJqUWkYWLVqklStX6uWXX1Zpaanq6+slSeXl5Soqcro1Fi5cqFGjRmn58uWSpO985zu6+uqrNX78eDU2NuqRRx7RgQMHdNddd6X5RzlzsUGrXN4LAED2pBRGnnrqKUnSzJkze2z/2c9+pi996UuSpIMHD8rl6mpwOXnypO6++27V19dr8ODBmjFjhjZv3qzJkyefWckzIMDN8gAAyLqUwkh/xrquX7++x/PHHntMjz32WEqFypUirxOiaBkBACB7uDdNN10TnxFGAADIFsJIN0V00wAAkHWEkW64Pw0AANlHGOmGO/cCAJB9hJFuimNjRuimAQAgawgj3QSYZwQAgKwjjHQT66Zpp2UEAICsIYx0w5gRAACyjzDSDfOMAACQfYSRbpgOHgCA7COMdEM3DQAA2UcY6aYrjFg5LgkAAIWDMNJNEfOMAACQdYSRbpgOHgCA7COMdMOYEQAAso8w0g3dNAAAZB9hpBtaRgAAyD7CSDexMBK2bJkRrqgBACAbCCPdBHxdHwetIwAAZAdhpBuf2yWX4Txm3AgAANlBGOnGMAzGjQAAkGWEkV5iV9QQRgAAyA7CSC/cLA8AgOwijPRCNw0AANlFGOklPvEZYQQAgKwgjPTS1U3DPCMAAGQDYaSXYgawAgCQVYSRXhgzAgBAdhFGeomFESY9AwAgOwgjvQSi3TTthBEAALKCMNIL3TQAAGQXYaSXeDcNYQQAgKwgjPQSnw6ebhoAALKCMNJLgG4aAACyijDSC2NGAADILsJIL0U+5yNhzAgAANlBGOmliLv2AgCQVYSRXhgzAgBAdhFGemHMCAAA2UUY6SV2aS/TwQMAkB0phZHly5friiuuUGlpqYYPH6758+dr7969pz3uxRdf1EUXXaRAIKBLL71Ur7zyyoALnGm0jAAAkF0phZENGzZo0aJFevPNN1VbWyvTNDVnzhy1tbUlPWbz5s1asGCB7rzzTu3YsUPz58/X/PnztXv37jMufCYwZgQAgOzypLLza6+91uP5ihUrNHz4cG3btk2f+tSnEh7zxBNP6MYbb9Q3vvENSdJDDz2k2tpa/fjHP9bTTz89wGJnTrybxrRkWbZcLiPHJQIA4NyWUhjprampSZI0ZMiQpPts2bJFS5Ys6bFt7ty5Wr16ddJjgsGggsFg/Hlzc7MkyTRNmaZ5BiXuKXau7uf0yIo/bu0IxsMJci9RfeHsRF3lD+oqv+RbffW3nAMOI5Zl6d5779W1116rSy65JOl+9fX1qqys7LGtsrJS9fX1SY9Zvny5li1bdsr2tWvXqri4eKBFTqq2tjb+2LKl2Mfyq1fXqMSb9rfDGepeXzi7UVf5g7rKL/lSX+3t7f3ab8BhZNGiRdq9e7c2bdo00FMktXTp0h6tKc3NzaqurtacOXNUVlaWtvcxTVO1tbWaPXu2vN6u1PG/t/5WobClv7rueo2sKErb++HMJKsvnH2oq/xBXeWXfKuvWM/G6QwojCxevFi//vWvtXHjRo0ePbrPfauqqtTQ0NBjW0NDg6qqqpIe4/f75ff7T9nu9Xoz8uH3Pm+R161Q2JJpu/KisgtNpn4PkH7UVf6grvJLvtRXf8uY0tU0tm1r8eLFWrVqlV5//XWNGzfutMfU1NRo3bp1PbbV1taqpqYmlbfOqtjlvdyfBgCAzEupZWTRokVauXKlXn75ZZWWlsbHfZSXl6uoyOnOWLhwoUaNGqXly5dLku655x5dd911evTRR3XzzTfr+eef19atW/XMM8+k+UdJn9igVS7vBQAg81JqGXnqqafU1NSkmTNnasSIEfHlhRdeiO9z8OBB1dXVxZ9fc801WrlypZ555hlNnTpVL730klavXt3noNdc42Z5AABkT0otI7Ztn3af9evXn7Lttttu02233ZbKW+UULSMAAGQP96ZJgJYRAACyhzCSAFPCAwCQPYSRBOLdNLSMAACQcYSRBIq8zsdCywgAAJlHGEmAeUYAAMgewkgCAbppAADIGsJIAkUMYAUAIGsIIwkQRgAAyB7CSAKxq2kYMwIAQOYRRhIIMOkZAABZQxhJgG4aAACyhzCSQFcYsXJcEgAAzn2EkQTiY0bopgEAIOMIIwlwbxoAALKHMJIAY0YAAMgewkgCdNMAAJA9hJEEaBkBACB7CCMJxMJI2LJlRriiBgCATCKMJBDwdX0stI4AAJBZhJEEfG6XXIbzmHEjAABkFmEkAcMwVOzzSKJlBACATCOMJMFcIwAAZAdhJImi6LiRdrppAADIKMJIErErahgzAgBAZhFGkmCuEQAAsoMwkgRjRgAAyA7CSBKxKeE76KYBACCjCCNJxMeM0DICAEBGEUaSYMwIAADZQRhJIhDvpuHeNAAAZBJhJAlaRgAAyA7CSBKMGQEAIDsII0lwNQ0AANlBGEmCeUYAAMgOwkgSjBkBACA7CCNJxG6Ux5gRAAAyizCSRLxlhDEjAABkFGEkCcaMAACQHYSRJBgzAgBAdhBGkohd2ttJNw0AABmVchjZuHGjbrnlFo0cOVKGYWj16tV97r9+/XoZhnHKUl9fP9AyZwUtIwAAZEfKYaStrU1Tp07Vk08+mdJxe/fuVV1dXXwZPnx4qm+dVYwZAQAgOzypHjBv3jzNmzcv5TcaPny4KioqUj4uV4pj3TSmJcuy5XIZOS4RAADnppTDyEBddtllCgaDuuSSS/Tggw/q2muvTbpvMBhUMBiMP29ubpYkmaYp0zTTVqbYuRKd02N03a23tSMYH0OC3OmrvnB2oa7yB3WVX/KtvvpbzoyHkREjRujpp5/W5ZdfrmAwqGeffVYzZ87UW2+9penTpyc8Zvny5Vq2bNkp29euXavi4uK0l7G2tvaUbZYtxT6eX726RiXetL8tBihRfeHsRF3lD+oqv+RLfbW3t/drP8O2bXugb2IYhlatWqX58+endNx1112nMWPG6D/+4z8Svp6oZaS6ulrHjx9XWVnZQIt7CtM0VVtbq9mzZ8vrPTVtXLLstwqGLa3/+ic1qqIobe+LgTldfeHsQV3lD+oqv+RbfTU3N2vYsGFqamrq8/s7a9003V155ZXatGlT0tf9fr/8fv8p271eb0Y+/GTnLfK5FQxbCttGXlR6ocjU7wHSj7rKH9RVfsmX+upvGXMyz8jOnTs1YsSIXLx1SrqmhLdOsycAABiolFtGWltb9f7778ef79+/Xzt37tSQIUM0ZswYLV26VIcPH9a///u/S5Ief/xxjRs3ThdffLE6Ozv17LPP6vXXX9fatWvT91NkCHONAACQeSmHka1bt+r666+PP1+yZIkk6fbbb9eKFStUV1engwcPxl8PhUL6+te/rsOHD6u4uFhTpkzRb3/72x7nOFsx1wgAAJmXchiZOXOm+hrzumLFih7P77vvPt13330pF+xsELuclzv3AgCQOdybpg+xbppOWkYAAMgYwkgf6KYBACDzCCN9oJsGAIDMI4z0ocjrfDy0jAAAkDmEkT4wZgQAgMwjjPQhQDcNAAAZRxjpA5OeAQCQeYSRPhBGAADIPMJIH2JX0zBmBACAzCGM9CE+zwhjRgAAyBjCSB/opgEAIPMII33oCiNWjksCAMC5izDSh/iYEbppAADIGMJIH7g3DQAAmUcY6UOxjzACAECmEUb6EJ8Onm4aAAAyhjDSh9iYkXYzItu2c1waAADOTYSRPsTGjEQsW2aEMAIAQCYQRvoQ66aRGDcCAECmEEb64HUbcrsMSUwJDwBAphBG+mAYRtfEZwxiBQAgIwgjp8FcIwAAZBZh5DSKfM5HRBgBACAzCCOnwVwjAABkFmHkNLhzLwAAmUUYOQ3GjAAAkFkFHUZcbz2laQd+In38ftJ9YrOwcjUNAACZUdBhxHj3ZY058XsZx95Luk98zAgtIwAAZERBhxFVjJEkGY1/SboLY0YAAMisgg4jdsVY50HjwaT7BOLdNFYWSgQAQOEp8DASbRk5eSDpPrSMAACQWQUdRuLdNE2nDyOMGQEAIDMKOoz06KaxEnfDcDUNAACZVdBhRGUjZcklIxKSWusT7sI8IwAAZFZhhxGXRx2+Yc7jJONGGDMCAEBmFXYYkdQeDyN/Sfh67EZ5jBkBACAzCj6MtPmHOw8ak7WMeCQxZgQAgEwp+DDS7jvPeZC0ZYRuGgAAMqngw0ibPxZGTjNmhJYRAAAyIuUwsnHjRt1yyy0aOXKkDMPQ6tWrT3vM+vXrNX36dPn9fo0fP14rVqwYQFEz47QtIwxgBQAgo1IOI21tbZo6daqefPLJfu2/f/9+3Xzzzbr++uu1c+dO3Xvvvbrrrru0Zs2alAubCfEw0lInmZ2nvB4bwEoYAQAgMzypHjBv3jzNmzev3/s//fTTGjdunB599FFJ0qRJk7Rp0yY99thjmjt3bqpvn3YhT6ls3yAZoTap6ZA0bEKP1wN00wAAkFEph5FUbdmyRbNmzeqxbe7cubr33nuTHhMMBhUMBuPPm5ubJUmmaco0zbSVzTRNyTBkl4+RcexdhY9/ILt8bI99PIbtlClsKRgMyeUy0vb+SE2s7tP5O4DMoK7yB3WVX/KtvvpbzoyHkfr6elVWVvbYVllZqebmZnV0dKioqOiUY5YvX65ly5adsn3t2rUqLi5OexkbQkUaIWnPplf0l73BHq8FI1LsY3r5N6/K70772yNFtbW1uS4C+om6yh/UVX7Jl/pqb2/v134ZDyMDsXTpUi1ZsiT+vLm5WdXV1ZozZ47KysrS9j6maaq2tlbDxs+Qtm3XJaNLNPmGm3rsY1m27nvbqfRPfXqWhg7ype39kZpYfc2ePVterzfXxUEfqKv8QV3ll3yrr1jPxulkPIxUVVWpoaGhx7aGhgaVlZUlbBWRJL/fL7/ff8p2r9ebkQ/fNfQCSZK76ZDcCc7v97gUDFsK20ZeVP65LlO/B0g/6ip/UFf5JV/qq79lzPg8IzU1NVq3bl2PbbW1taqpqcn0W/ebXTHGeXCaic+YEh4AgPRLOYy0trZq586d2rlzpyTn0t2dO3fq4MGDkpwuloULF8b3/8d//Ed9+OGHuu+++/Tee+/pX//1X/XLX/5SX/va19LzE6SBXTHWeZB0SvjYFTVWlkoEAEDhSDmMbN26VdOmTdO0adMkSUuWLNG0adN0//33S5Lq6uriwUSSxo0bp9/85jeqra3V1KlT9eijj+rZZ589Ky7rjauodtadTVLHyVNeZuIzAAAyJ+UxIzNnzpRt20lfTzS76syZM7Vjx45U3yp7vMXSoOFS21FnWviiwT1eDhBGAADImIK/N03c4LHOOsG4kfjN8pj4DACAtCOMxAw+31knGDcS66ZhACsAAOlHGImJt4ycGkbopgEAIHMIIzEV0ZYRumkAAMgqwkhMrGUkYTcNd+4FACBTCCMx8TEjByWr53wijBkBACBzCCMxZaMkl0eKhKSWuh4vBeimAQAgYwgjMS63VB6d/KzXuBEmPQMAIHMII90lubyXMAIAQOYQRrpLMvFZMTfKAwAgYwgj3cUv7+3ZMhKfZ4QxIwAApB1hpLskl/fG5hlpJ4wAAJB2hJHuBiee+IxLewEAyBzCSHeDxznrljrJ7IxvZgArAACZQxjprmiw5Ct1HjcejG+OzzNCGAEAIO0II90ZRsLLe+MtIyEr0VEAAOAMEEZ6S3B5L2NGAADIHMJIbwnu3lvUrZvGtu0cFAoAgHMXYaS3BC0jsXlGIpatTpOuGgAA0okw0luCMSOlfo8qy/ySpFd21SU6CgAADBBhpLd4y8gBKdol43IZuv0aZ/u//e5DumoAAEgjwkhvFWOcdbBZ6jgZ3/yFK89Xsc+t9+pb9Lt9x3NUOAAAzj2Ekd68RVJJlfO4W1dNebFXn7uiWpLTOgIAANKDMJJIkmnhv3ztOLkM6Xf7jutPR5qzXy4AAM5BhJFEkty9t3pIsW66dIQk6VlaRwAASAvCSCIJLu+N+YdPXSBJ+n9/OKK6po7slQkAgHMUYSSRBJf3xkwZXaGrxg1R2LK14vd/yW65AAA4BxFGEumjZUSS/ud1TuvIyrcOqqXTzE6ZAAA4RxFGEomNGWk8JFmn3o9m5oXDNX54iVqCYb3wzqEsFw4AgHMLYSSRspGSyytZptR85JSXXS5Dd39ynCTpp5v2y4wwRTwAAANFGEnE5ZYqnDlFEo0bkaRbLxulYSV+HWnqZIp4AADOAGEkmSSX98YEvG596Rpnn2c2MkU8AAADRRhJ5jSDWCXpC1edryKvW3uONGvLBx9npVgAAJxrCCPJ9HF5b3yXQT797eWjJUnPMAkaAAADQhhJph8tI5L05b9ypohfv/eY9ta3ZLxYAACcawgjyZxmzEjM+UMH6cZLnBvrMUU8AACpI4wkE2sZaa2XzL6nfb/7k84kaKt3HlZDc2eGCwYAwLmFMJJM0WDJX+Y8bjzY567TxgzWFWMHy4zYWrH5L5kvGwAA5xDCSDKG0TWI9TTjRqSu1pH/evOAWoPhDBYMAIBzC2GkL/0cNyJJsyZVatywQWruDOuXTBEPAEC/DSiMPPnkkxo7dqwCgYCuuuoqvf3220n3XbFihQzD6LEEAoEBFzirYuNG+ri8N8blMnRXdIr45zbtV5gp4gEA6JeUw8gLL7ygJUuW6IEHHtD27ds1depUzZ07V0ePHk16TFlZmerq6uLLgQOn/3I/K/Tz8t6Yv5k+WkMG+XS4sUOv7q7PWLEAADiXpBxGfvjDH+ruu+/WHXfcocmTJ+vpp59WcXGxfvrTnyY9xjAMVVVVxZfKysozKnTWpNBNIzlTxC+scY759su79cZ7yQMaAABweFLZORQKadu2bVq6dGl8m8vl0qxZs7Rly5akx7W2tur888+XZVmaPn26vv/97+viiy9Oun8wGFQwGIw/b25uliSZpinTNFMpcp9i50p6ztLR8kqyT+5XOBRyBrWexsKrRmvduw3adbhZd6x4R//wybH62g3j5XEzPOdMnba+cNagrvIHdZVf8q2++ltOw07hDm9HjhzRqFGjtHnzZtXU1MS333fffdqwYYPeeuutU47ZsmWL9u3bpylTpqipqUk/+MEPtHHjRu3Zs0ejR49O+D4PPvigli1bdsr2lStXqri4uL/FPWMuK6Rb/nCXJOmVS5+U6Snt13FhS1p9wKXf1TsB5IJSW7dPiKjCn7GiAgBw1mlvb9fnP/95NTU1qaysLOl+GQ8jvZmmqUmTJmnBggV66KGHEu6TqGWkurpax48f7/OHSZVpmqqtrdXs2bPl9XoT7uN54hIZrfUK37FW9sjpKZ3/1d31+ubqP6k1GNbgYq8e/R+X6pMThqWj6AWpP/WFswN1lT+oq/ySb/XV3NysYcOGnTaMpNRNM2zYMLndbjU0NPTY3tDQoKqqqn6dw+v1atq0aXr//feT7uP3++X3n9qM4PV6M/Lh93newWOl1np5Wg5L3qtSOu9nplVrSvUQLVq5XXuONOvL/75di67/hL4260K6bc5Apn4PkH7UVf6grvJLvtRXf8uY0jeiz+fTjBkztG7duvg2y7K0bt26Hi0lfYlEItq1a5dGjBiRylvnTopX1PQ2dtgg/fdXrtEXrx4jSXryjQ/0hWffYtp4AACiUv7zfMmSJfq3f/s3/fznP9e7776rr3zlK2pra9Mdd9whSVq4cGGPAa7f+c53tHbtWn344Yfavn27vvjFL+rAgQO666670vdTZFJsFtZ+zDWSTMDr1nfnX6p/WTBNg3xuvbX/hG564nf63b5jaSokAAD5K6VuGkn63Oc+p2PHjun+++9XfX29LrvsMr322mvxy3UPHjwol6sr45w8eVJ333236uvrNXjwYM2YMUObN2/W5MmT0/dTZFKKl/f25ZapI3XxyDJ99b+26736Fi386dv6p+vHa/GnJ8jnodsGAFCYUg4jkrR48WItXrw44Wvr16/v8fyxxx7TY489NpC3OTucYTdNbxecV6LVi67Vsl/9Sb94+6B+9Pr7Wvn2Qf2PGdVacGW1zh86KC3vAwBAvuDP8dOJddM0HZKsSFpOGfC6tfyzl+qJv7tMw0v9Ot4a0tMbPtB1j6zXF599S7/5Y51CYaaTBwAUhgG1jBSU0hGS2ydFQlLzYaliTNpOfetlo3TTpSO07t2j+sXbB7Vx3zFtev+4Nr1/XMNKfLrt8mr93RW0lgAAzm2EkdNxuaXyaunEB864kTSGEUnyul268ZIq3XhJlQ6daNcL7xzSC1sP6VhLUE+t/0BPrf9AfzV+mD5/1RjNmlTJ2BIAwDmHMNIfg8dGw8hfpHGfzNjbVA8p1v+aO1H3zJqQsLVkcLFXMycO18yJ5+mTE87TkEG+jJUFAIBsIYz0Rxou701FX60lq3Yc1qodh2UY0tTRFZo58TzNnDhcU0aVy+U6/b1zAAA42xBG+iN+ee9fsv7W3VtLth04qfV7j2n93qN6r75FOw81auehRj3+230aMsinT00YppkTh+tTF9JqAgDIH4SR/ohf3pudlpFEvG6Xrr5gqK6+YKj+z7yLVNfUoQ17j2n9Xqcb50RbSKt3HtHqnUdkGNLEylJdWFmqiVXRdWWpRg8uovUEAHDWIYz0R5a7afpjRHmR/u7KMfq7K8fIjFintJrEFv2h65gir1sTKkvi4WRCZYkmVpWqsjRASAEA5AxhpD9iLSOtDdLWn0mX35HT4vTWu9WkoblTuw83aW9Di/5c36K9Da364GirOsyI/vhRk/74UVOP431ulyrL/RpRXqSR5QFVlRdpZEVAI8qLNKI8oBHlAQ0Z5JNhEFgAAOlHGOmPosHS1V+V3vxX6df3Su0fS5/8unSWfjlXlgVUWRbQDZMq49vCEUsHTrRHw0mL/tzQoj83tGr/8TaFIpYOnejQoRMdSc/p87g0qqJI44eX6KJo189FVaUaN2wQdyAGAJwRwkh/zf2+5C2WfvcD6fWHpPYT0pzvSq78+CL2uF36xHkl+sR5JZp3adcdk0NhS0dbOlXX1KkjjR2qa+pUfbfHdU2dOt4aVChsaf/xNu0/3qbaPzXEj/e5XfrE8BJNrCzRxKoyJ6hUlWpkeYCWFABAvxBG+sswpBu+LRUPldYsld580mkhufXHktub69INmM/j0ujBxRo9uDjpPsFwRA1NQR062a699U6rynvRdXsoonfrmvVuXbOkI/Fjin1ujawo0qiKoug6oJHxx0WqKg/IS4sKAECEkdTVfFUqHiKt/qr0x+eljpPSbSskX/Iv83zn97g1Zmixxgwt1rXjh8W3W5atw40d8WDyXn2L9tY368NjbWoPRfT+0Va9f7Q14TkNQ6osDWhkNKSMqijSqMFFGlneFVjKijy0rgBAASCMDMTUv3PGkfxyobRvjfSfn5UWPC8VVeS6ZFnlchmqHlKs6iHFmj25a3xKKGzpo5PtOtLodPccbuzQkcYOHWnq0JHGTh1u7FAobKm+uVP1zZ3afrAx4flL/J54WBlZUaSqUp8ONxhy72nQ0NIiVRR7VVHs1eBinwJed5Z+agBAuhFGBurCudLfr5Z+8Tnp4BZpxc3SF/9bKq3Kdclyzudx6YLzSnTBeSUJX7dtWx+3hZygcjIWVjp1uLE9HlZOtIXUGgzrzw2t+nND99YVt1748A+nnNPvcTnhpMinimKvyoq8Kva5FfC4VeRzy+91qcjrVsDrjq5dCnR7XhTf13XKNi57BoDMIoycifNrpC+94rSMNOyWfjpX+vtV0pALcl2ys5phGBpW4tewEr+mjK5IuE9HKKIjTU5YORJtWTl0sl1//stH8pcOUWOHqaZ2U40dpiKWrWDYUkNzUA3NwbSX1+dxgkyR162SgEcVRV5VFPui4cdpnSkv9sUfxwLR4EE+DfK56WoCgNMgjJypqkukL6+R/uOvpZP7pefmOi0kI6bkumR5rcjnjl/9E2Oapl555aBuuulKeb3OoGHbttUaDKux3XSWjpAa2001dZjqNCMKhi11hCLqNCPqMCPqNC11hiPqDEXUGY6oIxRRh2kpGH+9a7+YUNhSKGypqcOUmlP7OXwel4YN8mlIiU9DBvk1dJBPQ6PPncd+DR7k1SC/R4N8HhX73Cr2eRTwuggxAAoGYSQdhoxzAsl//o3UsMvpspn7PWn8LKls5Jmdu+1j6f3fSvvWSqE26ap/kC64/qyd4yTbDMNQacCr0oBX1UPSd14r2toSCycdphNcmju7WmRi4aepVxBqbDd1sj2kYDTEHGnq1JGmzhR/LsXDySB/dO3zyOsxZFmSLVu2LdmSZPd8btu2bDljboYOioagEp+GRIPQ0GgwGjLIp7IAg4QB5B5hJF1KK6U7fiP9YoF04PfS//snZ/uwidIFM51l7LVSoLzv89i2VPcHaV+tMzj2o62KfuU4/vyqNPaT0g0PSNVXZOiHgctlqMjnjBsZPMBztIfC+rg1pI/bQjrRFtTHrSGdaHOeO4+DOtEW0sl2U+2hsNpDEbWHIpKcX4PWYFitwbDUkv6upxiv21BFsU8Br0tet0s+t7P2ug3nuafbNo9Lfo9LJX6PSgOe6NqrkoBHpbFt0e1FbilsOcEIAE6HMJJOgXKni+b3P5L+/Jp0ZId0fK+zvP0TyXBLo2ZIF1znhJPRV0gevxRskT54wwkf+34rtdb3PG/lpdKFc6RQu7T1Oekvv5OemyVNvEn69Lelysk5+XHRt2KfR8VDPKoe0v/Lvi3LVocZUVsorPZgdB2KqC0YVkcoolDEkmEYMuS0nhgyouvo8+hrktTSGdaJtpCOtwV1onsQij5vC0VkRmwdy1jY8ejrb9XK43KCjcdtxINN7LEnGnq8bifo+Dxda5879tztPPe4NMjn1uSRZbqsejB3pgbOIYSRdPMWSTP/t7N0nJT2/076cL2znPhA+uhtZ9n4iDOj67ALpYY9kmV2O8cgJ6xcOEcaP1sqH9X1Ws0iacPD0s6V0t5XpL2vSlP+Vpq51OkuQl5zuQxn/IjfI5Vm9r06zYhOtDkhJRSxZIYtmRFbZsRynseWsB1/3mE6wailM6zWzrBagmG1dJpOK06ns70lGFYo3DXmJmzZClsRyeyjMAMwbtggTRtToeljBmv6mMGaWFUqN1c+AXmJMJJJRYOlyZ9xFklqPCh9uEHav8EJJ23HpLqdzmtDPiFNmOMEkPOvdVpMEqmolm59UrrmHumN70p/eln64wvS7v+WZnxJ+tQ3Tn95sdkpNR+Wmj5yyjBqOlcAFaCA1x2fwyXdWjuC+tUrr+n6G2ZJhrsr2ETDjhmxFLZsmWEn+IS6r7s9DkaX2PbG9pB2ftSoD4+1xW9P8H+3H5YkDfK5NbXaCSfTxlToklHlGjrIx72TgDxAGMmmijHS9L93FtuWjv5JaviTEwaGfiK1c513ofS3/+50Ba17SPpgnfTOs9KO/5Ku+p/OPCjNR5zA0XxYajosNX/krNuPn3q+T9wgXXGnNGGu5ObXAmfG73Gp2CMNHeSLX/mUTo3tIe041KgdB05q+8FG7TzUqNZgWJs/+FibP/g4vp9hSEOKnUG7w0r8Glri17Do42HdtpX43XIZhtyubothyOUy5HE5a3f0dZ/bxdwzQJrxrZMrhiFVXuwsZ2LkNOnv/6/0l03Sb5c5XUC/f9xZ+uItlspGSf5SJ9B8sM5ZykY7LSzTFzqDcoGzUEWxT9dPHK7rJw6XJEUsW/uOtmj7gUbtOHhS2w+e1IfH22Tbio6TCfWaPO/M+D2ubhPluU95HptUz+9xHsfWzrae64DXJY/L1e8L5EoDXo0sD2hYiZ9QhHMGYeRcMfavpDvXSn9e49xZuPWoVD7aCRzlo6Lr0V3bigZ3XR58Yr+07WfSjv90Wk/e+K4zLmXSLdIVdzndRlz+ibOY22XooqoyXVRVps9fNUaSE1BORAfsHm9x1sdagjreGtLHrUEdb3UeH28NqsOMKGLZsixbYcuWZdvO8yQXA8W6j9I+ECYFXrehyrKARpYXaURFQCPKizSy13qQ3y2fmzlrcPYjjJxLDEOaeKOzpGLIOGn2d6SZ33TGoGx9Tjr0lrRnlbOcd5F0+Zede/Kc7tLk/rAizhVEsSVQ5gQk/sNEGrldhs4r9eu8Ur80wLs02NFQErFtWZYUtqz4/DOd0cnx4pPlhSLqDFs9JtTr2tdSMHzqOhhdhyL9uwTatm01tps62tIpM2Lro5Md+uhkR5/HGIa6WmE8zq0Ruq99HkONH7v0WvMf5Pd2Xbnkc7vl9RjyR69q8na7uqnI58xK7I/dOqHb7RMCvq4Zixmvg/4ijKCLNyBN/Zyz1O+S3nlO+uMvpWPvSa/eJ635ptOt4wk4A2w9RdF1wDnW022RpFCrFGzuGTyCLZLZfup7+0qlYROk8yY6VxidN9GZo2Xw2L7HsFiW1P6x1FLXtTTXOe9bPFQqqXQG9JZUOsugYZIrgzfVMzuc8nQ2SYEKqWS45E7/mAlkh2EY8riNbv9RujN9kVO/hCOWGlqCqmvs0JGmTtU1dqiuybkxZV1Tp+qaOnS8NSTJGZ7WaVrRWYWTteS4tPtkQ9rLGfC6VBZw7hVVFvCovCj22Kuyoujz6Fw1tu20ZpkRy1lbtiLRgc5hy1Y4+ti2nRmai31O4CmOTg4Y2+Y89qg4Gqy6XwIv9bwk3tXtMnnblqzohIGWbcefW7YTAmNr244e53LWrth5omt39DGtUakhjCCxqkulWx53Wkz++IITTI6961yunC5uv+Qb5Hxxh1qkI9udpcc+PudKo/MmylUxTpd8tEfu/35Ram2Iho/6npdFn47hkgad1xVOSiud0OD2Si5vdO1xllMee52A1X7CGQTc/nG35YSzThS0ioZE3294r3X0cVGFFA46x5qd0XWHs4Sj69g2t6+ru618tFRe7YQu/uMrKB63S6MqijSqjyuhQuHorQ/MrhYYJ5T0bKFp6wxp284/6MJJF8uyDYUiTuuPGb2iyex1lVPXsdGZiYNhmWZYphmSGTYVMkNy2ZY8smSYtiKmoRMthj6WZMnlzBIcXxuyZMiOLr113xZ77JIln8LyyZRfpnyGKZ/CzmOZ8hlh+RWSX2F5FJFbllyynLXhrGPbXLLjjw31f4I+Sy6F5Vak+9p2KyK3wnIpIrcihkuGXPK7bQU8UsBly++W/G5bPpctv8uOP/a5JJdhybAtGbYtw444n4xtS4ptj35Sdlhqa9Lbf/lvFRum/IYpvx2SXyF57ZC8dlBeKyi3FZTbMmUZzk8cMVyKyNOj3Kbtlmm7FLZdCtkunffZRzTqwsv6/TmkE2EEfQuUSVfe7YwdaT7sTLwW7uy2BKNfmsGe223baUVJtPhKJX9J1+XL4ZB04kNncrhjf46u90rH9zlfxsfelY69K7ekT0jSsd6FNJyAUVrlTL9fWuV0J7V97ISW1nqppcG5jNm2otvS/1dgnMsj+cuc1hkrLHWccJZj72bm/TyBUwNK2SjnM/AEJI+vqzXL7Y+2Zvm7bfM55YyEpIgZXUJda6vbNrNT6mx0QmlHdN3Z2OvxSXk6GvWZcKe005BkRMNSH2tfcfR3o8T57Hr8zpRE12XOwGsr3K2MoeSPXW6ppMoJnLF16Qhp0PD+XTFm204IbD8R/XlPOMFZRvRz8zqfp9vnfMbubovH70xyGA+Wbc6/HTO6hNq7beuQIkHnd9O2nbXs6OPuz7u9bkectWVFn3ff5qx9tiVfOKiySDD67zO69HpuR4L620hI9hFDhuGKNh24ovXjii7dtklOHcQWO9L1mbkkJZmVoKBZ0SWcxnOm8e/CmHebP9ao0++WEYQR9I9hOF90meDxScMvcpbuLEtqOhgPKJHjH+iDw8f0ianXyl0x2vliKRvhtDD0pyskEnZaNFrqnQG+sZASbHJes8LRL95uj61w9Hn0C9k3yGmJSLgMcRZ/mfN5WZbzJRYLP61HEzw+6nzBeQPOF623KNrtFX0cX0cXs8O5XDu2tNY74e/j953lLBH/ezY2Hfzp/ug025ywmBWG011XUuUE19JKZ1vHSWeJh4+Tzhf3Oc6Ir+1ooEn32TN4SwC3r1fA7grcttsny+WNhim3bJdbMlyyDbcTVA23bMMlOx64XM5n0W0WY6PH49ib2pIVkW1FpIgp2wo7ATD6f4XdLajZtiVbbkWMrrYY57GhiB1roXApYrsUMVySupfHkC139LkRL7tlS3UfN6lk6EgF5VO77VW77VVHxKNWy6tWy6u2sFvNEY86Im4FPFKRRyr22Cr2SEVuS0VuW0Xx1hpbAbelgMvSuOpe/wdnEWEEZy+XyxkzMnisdOEcWaapd195ReOuuEnugcxd4fZEv3wGOJoxVS6XNGios2Rqyv5wsGs+mfhyyGnFCrZ2+yu4s+dfx+HO5N1bLm/0P/nua2/XX/yBCudqrKLoOlDR6/Fgmd4Srdvwe93w6U/L6/Eo/pd+wrXlhKxgi1PmROOMYtvM9q7utHhLRO/yRh9HzK7AGV83OF+4bcecpWHX6T9jl9cJmbGfT3I+14gZbWkIdS3h2ONoiHH7ooGy2Gn98RY7gTYWMmOPPf6uVgjp1NaI2HMZ0S9SV88lvi26dkW3u0/9ku7RWub2yZRH697YoBtuiNbVKS00Vrdt0WDh9nR1Ybo8zvu7PM77x7d1G7xq96rvU1qAYjP22l37dx3cc5thdLVIdX+PXgxJGRwdljOmaerPr7yiT950U0bm8MkVwgiQzzx+52qogdwKwLK6wkrsi9zlSc/4E9NU0LvHCX5n03+YViQ64Lk+Ou6o3lkMOWN7igZ3BY/Yc9+g1D+T2BdsJgdLp4tpKugtd1oYM1VXhtHtM8yDzwRZRxgBCpXLJbmi3T+FwuWODiAentn3MQynlQBAv3AROAAAyCnCCAAAyCnCCAAAyCnCCAAAyCnCCAAAyCnCCAAAyCnCCAAAyKkBhZEnn3xSY8eOVSAQ0FVXXaW33367z/1ffPFFXXTRRQoEArr00kv1yiuvDKiwAADg3JNyGHnhhRe0ZMkSPfDAA9q+fbumTp2quXPn6ujRown337x5sxYsWKA777xTO3bs0Pz58zV//nzt3r37jAsPAADyX8ph5Ic//KHuvvtu3XHHHZo8ebKefvppFRcX66c//WnC/Z944gndeOON+sY3vqFJkybpoYce0vTp0/XjH//4jAsPAADyX0rTwYdCIW3btk1Lly6Nb3O5XJo1a5a2bNmS8JgtW7ZoyZIlPbbNnTtXq1evTvo+wWBQwWDX3TKbm5slOTcIMs0kN/cagNi50nlOZA71lT+oq/xBXeWXfKuv/pYzpTBy/PhxRSIRVVZW9theWVmp9957L+Ex9fX1Cfevr69P+j7Lly/XsmXLTtm+du1aFRcXp1LkfqmtrU37OZE51Ff+oK7yB3WVX/Klvtrb2/u131l5o7ylS5f2aE1pbm5WdXW15syZo7KysrS9j2maqq2t1ezZs8+pWzGfq6iv/EFd5Q/qKr/kW33FejZOJ6UwMmzYMLndbjU0NPTY3tDQoKqqqoTHVFVVpbS/JPn9fvn9/vhz27YlSR0dHWn98E3TVHt7uzo6OhQOh9N2XmQG9ZU/qKv8QV3ll3yrr46ODkld3+PJpBRGfD6fZsyYoXXr1mn+/PmSJMuytG7dOi1evDjhMTU1NVq3bp3uvffe+Lba2lrV1NT0+31bWlokSdXV1akUFwAAnAVaWlpUXl6e9PWUu2mWLFmi22+/XZdffrmuvPJKPf7442pra9Mdd9whSVq4cKFGjRql5cuXS5LuueceXXfddXr00Ud188036/nnn9fWrVv1zDPP9Ps9R44cqUOHDqm0tFSGYaRa5KRi3T+HDh1Ka/cPMoP6yh/UVf6grvJLvtWXbdtqaWnRyJEj+9wv5TDyuc99TseOHdP999+v+vp6XXbZZXrttdfig1QPHjwol6vriuFrrrlGK1eu1Le+9S1985vf1IQJE7R69Wpdcskl/X5Pl8ul0aNHp1rUfisrK8uLSoWD+sof1FX+oK7ySz7VV18tIjGGfbqOnHNYc3OzysvL1dTUlDeVWsior/xBXeUP6iq/nKv1xb1pAABAThV0GPH7/XrggQd6XLmDsxf1lT+oq/xBXeWXc7W+CrqbBgAA5F5Bt4wAAIDcI4wAAICcIowAAICcIowAAICcKugw8uSTT2rs2LEKBAK66qqr9Pbbb+e6SAVv48aNuuWWWzRy5EgZhqHVq1f3eN22bd1///0aMWKEioqKNGvWLO3bty83hS1wy5cv1xVXXKHS0lINHz5c8+fP1969e3vs09nZqUWLFmno0KEqKSnR3/zN35xyrypkx1NPPaUpU6bEJ8uqqanRq6++Gn+dujp7PfzwwzIMo8dtVc61+irYMPLCCy9oyZIleuCBB7R9+3ZNnTpVc+fO1dGjR3NdtILW1tamqVOn6sknn0z4+j//8z/rRz/6kZ5++mm99dZbGjRokObOnavOzs4slxQbNmzQokWL9Oabb6q2tlamaWrOnDlqa2uL7/O1r31Nv/rVr/Tiiy9qw4YNOnLkiD772c/msNSFa/To0Xr44Ye1bds2bd26VZ/+9Kd16623as+ePZKoq7PVO++8o5/85CeaMmVKj+3nXH3ZBerKK6+0Fy1aFH8eiUTskSNH2suXL89hqdCdJHvVqlXx55Zl2VVVVfYjjzwS39bY2Gj7/X77F7/4RQ5KiO6OHj1qS7I3bNhg27ZTN16v137xxRfj+7z77ru2JHvLli25Kia6GTx4sP3ss89SV2eplpYWe8KECXZtba193XXX2ffcc49t2+fmv62CbBkJhULatm2bZs2aFd/mcrk0a9YsbdmyJYclQ1/279+v+vr6HvVWXl6uq666ino7CzQ1NUmShgwZIknatm2bTNPsUV8XXXSRxowZQ33lWCQS0fPPP6+2tjbV1NRQV2epRYsW6eabb+5RL9K5+W8r5RvlnQuOHz+uSCQSv7lfTGVlpd57770clQqnU19fL0kJ6y32GnLDsizde++9uvbaa+M3wayvr5fP51NFRUWPfamv3Nm1a5dqamrU2dmpkpISrVq1SpMnT9bOnTupq7PM888/r+3bt+udd9455bVz8d9WQYYRAOm1aNEi7d69W5s2bcp1UdCHiRMnaufOnWpqatJLL72k22+/XRs2bMh1sdDLoUOHdM8996i2tlaBQCDXxcmKguymGTZsmNxu9ykjjxsaGlRVVZWjUuF0YnVDvZ1dFi9erF//+td64403NHr06Pj2qqoqhUIhNTY29tif+sodn8+n8ePHa8aMGVq+fLmmTp2qJ554gro6y2zbtk1Hjx7V9OnT5fF45PF4tGHDBv3oRz+Sx+NRZWXlOVdfBRlGfD6fZsyYoXXr1sW3WZaldevWqaamJoclQ1/GjRunqqqqHvXW3Nyst956i3rLAdu2tXjxYq1atUqvv/66xo0b1+P1GTNmyOv19qivvXv36uDBg9TXWcKyLAWDQerqLHPDDTdo165d2rlzZ3y5/PLL9YUvfCH++Fyrr4LtplmyZIluv/12XX755bryyiv1+OOPq62tTXfccUeui1bQWltb9f7778ef79+/Xzt37tSQIUM0ZswY3Xvvvfrud7+rCRMmaNy4cfr2t7+tkSNHav78+bkrdIFatGiRVq5cqZdfflmlpaXxvury8nIVFRWpvLxcd955p5YsWaIhQ4aorKxM//RP/6SamhpdffXVOS594Vm6dKnmzZunMWPGqKWlRStXrtT69eu1Zs0a6uosU1paGh97FTNo0CANHTo0vv2cq69cX86TS//yL/9ijxkzxvb5fPaVV15pv/nmm7kuUsF74403bEmnLLfffrtt287lvd/+9rftyspK2+/32zfccIO9d+/e3Ba6QCWqJ0n2z372s/g+HR0d9le/+lV78ODBdnFxsf3Xf/3Xdl1dXe4KXcC+/OUv2+eff77t8/ns8847z77hhhvstWvXxl+nrs5u3S/tte1zr74M27btHOUgAACAwhwzAgAAzh6EEQAAkFOEEQAAkFOEEQAAkFOEEQAAkFOEEQAAkFOEEQAAkFOEEQAAkFOEEQAAkFOEEQAAkFOEEQAAkFOEEQAAkFP/H99dOpC7q+S2AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lst_loss_train)\n",
    "plt.plot(lst_loss_val)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f65295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN размерность выхода: torch.Size([1, 32, 32, 89])\n",
      "CNN число фичей: 1024\n",
      "Mean accurasu by The Levenshtein in train is : 0.9560291829189195\n",
      "Mean accurasu by The Levenshtein in validate is : 0.9710400257135271\n",
      "Kagle accurasy: -0.9270692086324466\n"
     ]
    }
   ],
   "source": [
    "def ctc_decoder(logits, int_char_map, blank_label_idx):\n",
    "    preds = []\n",
    "    logits_cpu = logits.cpu()\n",
    "    max_inds = torch.argmax(logits_cpu.detach(), dim=2).t().numpy()\n",
    "\n",
    "    for ind in max_inds:\n",
    "        merged_inds = []\n",
    "        prev_idx = None\n",
    "        for idx in ind:\n",
    "            if idx != blank_label_idx and idx != prev_idx:\n",
    "                merged_inds.append(idx)\n",
    "            prev_idx = idx\n",
    "        text = ''.join([int_char_map.get(i, '') for i in merged_inds])\n",
    "        preds.append(text)\n",
    "\n",
    "    return preds\n",
    "\n",
    "model_load = MorseNet(num_classes=num_classes)\n",
    "model_load.load_state_dict(torch.load('MorseNet.pth'))\n",
    "model_load.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_mess = []\n",
    "    train_predicts = []\n",
    "    for loader in train_dl:\n",
    "        seq, test_target, _, mess = loader\n",
    "        train_mess.extend(mess)\n",
    "\n",
    "        logits = model_load(seq)\n",
    "        predicted_values = ctc_decoder(logits, int_to_char, BLANK_IDX)\n",
    "        train_predicts.extend(predicted_values)\n",
    "\n",
    "    val_mess = []\n",
    "    val_predicts = []\n",
    "    for loader in val_dl:\n",
    "        seq, test_target, _, mess = loader\n",
    "        val_mess.extend(mess)\n",
    "\n",
    "        logits= model_load(seq)\n",
    "        predicted_values = ctc_decoder(logits, int_to_char, BLANK_IDX)\n",
    "        val_predicts.extend(predicted_values)\n",
    "\n",
    "import Levenshtein\n",
    "\n",
    "mean_acc_test = np.mean([Levenshtein.ratio(test_pred, train_mess[ind]) for ind, test_pred in enumerate(train_predicts)])\n",
    "mean_acc_val = np.mean([Levenshtein.ratio(val_pred, val_mess[ind]) for ind, val_pred in enumerate(val_predicts)])\n",
    "\n",
    "\n",
    "print(f'Mean accurasu by The Levenshtein in train is : {mean_acc_test}')\n",
    "print(f'Mean accurasu by The Levenshtein in validate is : {mean_acc_val}')\n",
    "print(f'Kagle accurasy: {1 - np.mean(mean_acc_val+mean_acc_test)}')\n",
    "\n",
    "\n",
    "test_ds = MosreDataset(df=sample_data,\n",
    "                        data_patch=DATASET_PATCH,\n",
    "                        char_to_int=char_to_int,\n",
    "                        train=False,\n",
    "                        transforms=valid_audio_transforms)\n",
    "\n",
    "\n",
    "test_dl = torch.utils.data.DataLoader(test_ds, batch_size=20, shuffle=False, collate_fn=my_collate)\n",
    "model_load.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_predicts = []\n",
    "    for loader in test_dl:\n",
    "        seq = loader\n",
    "        logits = model_load(seq)\n",
    "        predicted_values = ctc_decoder(logits, int_to_char, BLANK_IDX)\n",
    "        test_predicts.extend(predicted_values)\n",
    "\n",
    "sample_data.message = test_predicts\n",
    "sample_data.to_csv('sample_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Morse_decoder_V2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d761d8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN размерность выхода: torch.Size([1, 32, 16, 89])\n",
      "CNN число фичей: 512\n",
      "Проекция из 512 в 256\n",
      "\n",
      "MorseNet - инициалицация модели. Число обучаемых параметров: 759,821\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path as pt\n",
    "import torch\n",
    "import torchaudio\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchaudio import transforms\n",
    "from torchvision.transforms import v2\n",
    "# from Moduls.MosreDataset import MosreDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch.nn.parallel import DataParallel\n",
    "from collections import Counter\n",
    "\n",
    "DEVICE = torch.device(\"cuda\")\n",
    "\n",
    "MAIN = pt(os.getcwd())\n",
    "DATASET_PATCH = MAIN / 'morse_dataset'\n",
    "AUDIO_FILES = DATASET_PATCH / 'morse_dataset'\n",
    "\n",
    "# Поятоянные значения выявленные в процессе анализа\n",
    "MORSEALP = \"АБВГДЕЁЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯ 1234567890#\"\n",
    "MAX_TIME = 48\n",
    "SAMPLE_RATE = 8000\n",
    "N_MELS = 128\n",
    "N_FFT = 400\n",
    "HOP_LENGTH = 180\n",
    "TOP_DB = 80\n",
    "FREQ_MASK = 40\n",
    "TIME_MASK = 50\n",
    "\n",
    "# Гиперпараметы обучения\n",
    "SEED = 42\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 2e-4 \n",
    "WEIGHT_DECAY = 1e-4\n",
    "\n",
    "#===== Import data =====\n",
    "train_data = pd.read_csv(pt.joinpath(DATASET_PATCH,'train.csv'))\n",
    "test_data = pd.read_csv(pt.joinpath(DATASET_PATCH,'test.csv'))\n",
    "sample_data = pd.read_csv(pt.joinpath(DATASET_PATCH,'sample_submission.csv'))\n",
    "\n",
    "all_chars = Counter(\"\".join(train_data['message']))\n",
    "BLANK_CHAR = \"_\"\n",
    "vocab_list = sorted(all_chars.keys()) + [BLANK_CHAR]\n",
    "num_classes = len(vocab_list)\n",
    "char_to_int = {char: i for i, char in enumerate(vocab_list)}\n",
    "int_to_char = {i: char for i, char in enumerate(vocab_list)}\n",
    "BLANK_IDX = char_to_int[BLANK_CHAR]\n",
    "\n",
    "class MosreDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Класс для обработки \n",
    "    \"\"\"\n",
    "    def __init__(self, df, data_patch,char_to_int, train=True, transforms=None, prev_chars = 1):\n",
    "        self.df = df\n",
    "        self.is_train = train\n",
    "\n",
    "        self.data_path = data_patch\n",
    "        self.audio_paths = self.data_path / 'morse_dataset'\n",
    "\n",
    "        self.transforms = transforms\n",
    "\n",
    "        self.char_to_int = char_to_int\n",
    "        self.prev_chars = prev_chars\n",
    "\n",
    "        if self.is_train:\n",
    "            self.messeges = self.df.message.values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        #Получение аугментрованых спектрограмм\n",
    "        try:\n",
    "            audio_file = self.audio_paths / self.df.id.values[index]\n",
    "            waveform, sample_rate = torchaudio.load(audio_file)\n",
    "            augmented_spectrogram = self.transforms(waveform)\n",
    "\n",
    "            if self.is_train:\n",
    "                message = self.messeges[index]\n",
    "                #Получение списка индексов секта - как требует CTC los\n",
    "                '''\n",
    "                При обработке dataloader labels будут выравниваться по макс длине для выравнивания батча\n",
    "                Т.е. будет padding 0. что в будующем будет пустым значением для ctc loss\n",
    "                '''\n",
    "                target = torch.tensor([self.char_to_int[char] for char in message], dtype=torch.long); \n",
    "                target_len = torch.tensor(len(target), dtype=torch.long)\n",
    "                return augmented_spectrogram, target, target_len, message\n",
    "            else:\n",
    "                return augmented_spectrogram, None, None, None\n",
    "        except Exception as ex:\n",
    "            print(str(ex))\n",
    "        \n",
    "    def change_time(self, audio_file, max_len = 384000):\n",
    "        waveform, sample_rate = torchaudio.load(audio_file)\n",
    "        cahanal, sig_len = waveform.shape\n",
    "\n",
    "        if sig_len < max_len:\n",
    "            pad_len = torch.zeros(max_len - sig_len).unsqueeze(0)\n",
    "            waveform = torch.cat([waveform, pad_len], dim=1)\n",
    "\n",
    "        return waveform\n",
    "    \n",
    "FIRST_FE_COUNT = 16\n",
    "SECOND_FE_COUNT = 32\n",
    "THIRD_FE_COUNT = 32\n",
    "QAD_FE_COUNT = 32\n",
    "PADDING = 'same'\n",
    "MAXPOOL_KERNEL = 2\n",
    "KERTNEL_SIZE = 3\n",
    "NERON_COUNT = 128\n",
    "GRU_HIDEN = 128\n",
    "# Start with 4 transforms\n",
    "class MorseNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.net_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, \n",
    "                      out_channels=FIRST_FE_COUNT, \n",
    "                      kernel_size=KERTNEL_SIZE , stride=1, padding=PADDING),\n",
    "            nn.BatchNorm2d(FIRST_FE_COUNT),\n",
    "            nn.GELU(),\n",
    "            nn.MaxPool2d((1, 2), (1, 2)), # [batch, FIRST_FE_COUNT = 16, 64, 960]\n",
    "\n",
    "            nn.Conv2d(in_channels=FIRST_FE_COUNT, \n",
    "                      out_channels=SECOND_FE_COUNT, \n",
    "                      kernel_size=KERTNEL_SIZE , stride=1, padding=PADDING),\n",
    "            nn.BatchNorm2d(SECOND_FE_COUNT),\n",
    "            nn.GELU(),\n",
    "            nn.MaxPool2d((2, 1), (2, 1)), # [batch, SECOND_FE_COUNT = 32, 32, 480]\n",
    "\n",
    "            nn.Conv2d(in_channels=SECOND_FE_COUNT, \n",
    "                      out_channels=THIRD_FE_COUNT, \n",
    "                      kernel_size=KERTNEL_SIZE , stride=1, padding=PADDING),\n",
    "            nn.BatchNorm2d(THIRD_FE_COUNT),\n",
    "            nn.GELU(),\n",
    "            nn.MaxPool2d((2, 2), (2, 2)), # [batch, THIRD_FE_COUNT = 32, 16, 240]\n",
    "\n",
    "            nn.Conv2d(in_channels=THIRD_FE_COUNT, \n",
    "                      out_channels=QAD_FE_COUNT, \n",
    "                      kernel_size=KERTNEL_SIZE , stride=1, padding=PADDING),\n",
    "            nn.BatchNorm2d(QAD_FE_COUNT),\n",
    "            nn.GELU(),\n",
    "            nn.MaxPool2d((2, 1), (2, 1)) # [batch=32, QAD_FE_COUNT = 32, 8, 80](что юы сохраниить большще признаков по горизонтали)\n",
    "        )\n",
    "        with torch.no_grad(): \n",
    "            dummy_input = torch.randn(1, 1, N_MELS, 356); \n",
    "            cnn_out = self.net_conv(dummy_input); \n",
    "            self.cnn_output_features = cnn_out.shape[1] * cnn_out.shape[2]\n",
    "\n",
    "        print(f\"CNN размерность выхода: {cnn_out.shape}\"); \n",
    "        print(f\"CNN число фичей: {self.cnn_output_features}\")\n",
    "\n",
    "        # Добавлен лоейный слой и функция активации. Для чего? расписать потом \n",
    "        self.layer1 = nn.Linear(self.cnn_output_features, N_MELS*2); \n",
    "        self.gelu = nn.GELU()\n",
    "        print(f\"Проекция из {self.cnn_output_features} в {GRU_HIDEN*2}\")\n",
    "        self.rnn = nn.GRU(\n",
    "                input_size=N_MELS*2,\n",
    "                hidden_size=GRU_HIDEN,\n",
    "                num_layers=2,\n",
    "                bidirectional=True,\n",
    "                batch_first=True,\n",
    "                dropout= 0.2\n",
    "            )\n",
    "\n",
    "        \n",
    "        self.embed_dim = GRU_HIDEN * 2\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm(self.embed_dim)   \n",
    "        self.dropout = nn.Dropout(0.3)   \n",
    "        self.layer2 = nn.Linear(self.embed_dim, num_classes)       \n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net_conv(x)\n",
    "\n",
    "        batch, channels, reduced_mels, reduced_time = x.shape\n",
    "        x = x.permute(0, 3, 1, 2)  # [batch, time, channels, mels]\n",
    "\n",
    "        # В частности, каждый вектор признаков в последовательности признаков генерируется \n",
    "        # слева направо на картах признаков. Это означает, что i-й вектор признаков представляет \n",
    "        # собой объединение столбцов всех карт. \n",
    "        # Таким образом, форма тензора может быть изменена, например, на (размер_пакета, 80, 256)\n",
    "        \n",
    "        x = x.reshape(batch, reduced_time, -1)  # to GRU [batch=32, seq_len=89, features/hiden_dim=512]\n",
    "        x = self.layer1(x)\n",
    "        x = self.gelu(x)\n",
    "\n",
    "        self.rnn.flatten_parameters()\n",
    "\n",
    "        x = self.rnn(x) # [batch=32, seq_len=89, features/hiden_dim=256 * 2]\n",
    "        x, _ = x # берем информацию со всез состояний\n",
    "        x = self.layer_norm(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer2(x) # logits - [batch, sequence, num_classes] \n",
    "        x = nn.functional.log_softmax(x.permute(1,0,2), dim=2) # pertime так как CTC loss требует на взод (sequence/T,batch/N,num_classes/C)\n",
    "        '''\n",
    "        по одному прогнозу для каждого из признаков в последовательности, \n",
    "        в итоге получается 89 прогнозов символов для каждой секунды звука.\n",
    "        '''\n",
    "        return x\n",
    "    \n",
    "\n",
    "train_audio_transforms = nn.Sequential(\n",
    "    transforms.MelSpectrogram(sample_rate=SAMPLE_RATE, n_fft=N_FFT, hop_length=HOP_LENGTH, n_mels=N_MELS),\n",
    "    transforms.AmplitudeToDB(top_db=TOP_DB),\n",
    "    transforms.FrequencyMasking(freq_mask_param=FREQ_MASK, iid_masks=True),\n",
    "    transforms.TimeMasking(time_mask_param=TIME_MASK, iid_masks=True),\n",
    "    ) \n",
    "# заметка - Данные трансформации не создают довых обучаемых параметров. Но есть и те что создают. В будущем это стоит учитывать\n",
    "\n",
    "valid_audio_transforms = nn.Sequential(\n",
    "    transforms.MelSpectrogram(sample_rate=SAMPLE_RATE, n_fft=N_FFT, hop_length=HOP_LENGTH, n_mels=N_MELS),\n",
    "    transforms.AmplitudeToDB(top_db=TOP_DB),\n",
    "    # v2.CenterCrop((N_MELS, 1920)) \n",
    "    )\n",
    "\n",
    "train_dataframe, val_dataframe = train_test_split(train_data, test_size=0.15, random_state=SEED)\n",
    "\n",
    "train_ds = MosreDataset(df=train_dataframe,\n",
    "                        data_patch=DATASET_PATCH,\n",
    "                        char_to_int=char_to_int,\n",
    "                        train=True,\n",
    "                        transforms=train_audio_transforms)\n",
    "\n",
    "val_ds = MosreDataset(df=val_dataframe,\n",
    "                        data_patch=DATASET_PATCH,\n",
    "                        char_to_int=char_to_int,\n",
    "                        train=True,\n",
    "                        transforms=valid_audio_transforms)\n",
    "\n",
    "def my_collate(batch):\n",
    "    spectrograms = [item[0].squeeze(0) for item in batch]\n",
    "    # Падинг спектрограмм по максимальной длине\n",
    "    spectrograms_permuted = [s.permute(1, 0) for s in spectrograms]\n",
    "    spectrograms_padded = nn.utils.rnn.pad_sequence(spectrograms_permuted, batch_first=True, padding_value=0.0)\n",
    "    spectrograms_padded = spectrograms_padded.permute(0, 2, 1).unsqueeze(1)\n",
    "\n",
    "    if batch[0][3] is not None:\n",
    "        target = torch.nn.utils.rnn.pad_sequence(\n",
    "                                                [item[1] for item in batch], \n",
    "                                                batch_first=True, \n",
    "                                                padding_value=BLANK_IDX)# выравнивает последовательность до макс \n",
    "                                                                        # длины в батче заполняя пропуски нулем\n",
    "        label_len = torch.stack([item[2] for item in batch])\n",
    "        msg = [item[3] for item in batch]\n",
    "        \n",
    "        return [spectrograms_padded, target, label_len, msg]\n",
    "    else: \n",
    "        return spectrograms_padded\n",
    "\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=my_collate, drop_last=True)\n",
    "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=my_collate, drop_last=True)\n",
    "\n",
    "\n",
    "\n",
    "#===== начало обучения =====\n",
    "model = MorseNet(num_classes=num_classes).to(DEVICE)\n",
    "model = DataParallel(model)\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.2, patience=6)\n",
    "loss_func = nn.CTCLoss(blank=BLANK_IDX, reduction='mean', zero_infinity=True).to(DEVICE)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nMorseNet - инициалицация модели. Число обучаемых параметров: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be51c697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a= model(test)\n",
    "# a.shape, a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa77922d",
   "metadata": {},
   "source": [
    "Подсказка по ctc loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "222c0bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\homer\\AppData\\Local\\Temp\\ipykernel_20744\\2733710114.py:15: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\build\\aten\\src\\ATen/core/TensorBody.h:494.)\n",
      "  loss.grad\n"
     ]
    }
   ],
   "source": [
    "# Target are to be un-padded\n",
    "T = 50      # Input sequence length\n",
    "C = 20      # Number of classes (including blank)\n",
    "N = 16      # Batch size\n",
    "# Initialize random batch of input vectors, for *size = (T,N,C)\n",
    "input = torch.randn(T, N, C).log_softmax(2).detach().requires_grad_()\n",
    "input_lengths = torch.full(size=(N,), fill_value=T, dtype=torch.long)\n",
    "# Initialize random batch of targets (0 = blank, 1:C = classes)\n",
    "target_lengths = torch.randint(low=1, high=T, size=(N,), dtype=torch.long)\n",
    "target = torch.randint(low=1, high=C, size=(sum(target_lengths),), dtype=torch.long)\n",
    "ctc_loss = nn.CTCLoss()\n",
    "loss = ctc_loss(input, target, input_lengths, target_lengths)\n",
    "loss.backward()\n",
    "# input.detach().numpy().shape\n",
    "loss.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89dc4bd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50, 16, 20]), torch.Size([334]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape, target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbaf999d",
   "metadata": {},
   "source": [
    "# Декодировщик предсказаний"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad235125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = model(test)\n",
    "# a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50953d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_loss_train = []\n",
    "lst_loss_val = []\n",
    "pr = []\n",
    "p_Val = []\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    epoch_train_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    pr = []\n",
    "\n",
    "    train_tqdm = tqdm(train_dl, desc=f\"Эпоха {epoch+1}/{EPOCHS} [Обучение]\", leave=False)\n",
    "    for batch_ind, batch in enumerate(train_tqdm):\n",
    "        mel_spec, targets, targets_lens, _ = batch\n",
    "        mel_spec, targets, targets_lens = mel_spec.to(DIVICE), targets.to(DIVICE), targets_lens.to(DIVICE)\n",
    "\n",
    "        #===== считатем длинну mel_spec для передачи в CTC loss =====\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predict = model(mel_spec) # (N=batch,T,C)\n",
    "        pr.append(predict)\n",
    "\n",
    "        N = predict.shape[1]\n",
    "        T = predict.shape[0]\n",
    "        predict_lengths = torch.full(size=(N,), fill_value=T, dtype=torch.long)\n",
    "\n",
    "    #     print(\"Predict shape:\", predict.shape) # [T, N, C]\n",
    "    #     print(\"Labels shape:\", targets.shape)   # [N, max_label_len]\n",
    "    #     print(\"Predict lengths:\", predict_lengths) # [N]\n",
    "    #     print(\"Target lengths:\", targets_lens.reshape(BATCH_SIZE))   # [N]\n",
    "    #     break\n",
    "    # break\n",
    "        try:\n",
    "            loss = loss_func(predict, targets, predict_lengths, targets_lens.reshape(BATCH_SIZE))\n",
    "        except RuntimeError:\n",
    "            print(predict.shape, targets.shape, predict_lengths, targets_lens.reshape(BATCH_SIZE))\n",
    "            continue\n",
    "        # print(loss)\n",
    "        if torch.isnan(loss) or torch.isinf(loss): \n",
    "            print(f\"\\nWarning: In batch-{batch_ind} loss train is NaN/Inf: {loss.item()}\"); \n",
    "            optimizer.zero_grad(); \n",
    "            continue\n",
    "\n",
    "        loss.backward()\n",
    "        # nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_train_loss += loss.item()\n",
    "        train_loss = epoch_train_loss / len(train_dl)\n",
    "\n",
    "    # ======== Валидация ========\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    all_targets = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for val_mel_spec, val_labels, val_label_lensin, _ in tqdm(\n",
    "                                                        val_dl, \n",
    "                                                        desc=f\"Эпоха {epoch+1}/{EPOCHS} [Валидация]\", \n",
    "                                                        leave=False):\n",
    "            val_mel_spec, val_labels, val_label_lensin = val_mel_spec.to(DIVICE), val_labels.to(DIVICE), val_label_lensin.to(DIVICE)\n",
    "            val_predict = model(val_mel_spec)\n",
    "\n",
    "            p_Val.append(val_predict)\n",
    "            val_N = val_predict.shape[1]\n",
    "            val_T = val_predict.shape[0]\n",
    "            predict_val_lengths = torch.full(size=(val_N,), fill_value=val_T, dtype=torch.long)\n",
    "            epoch_val_loss += loss_func(val_predict, val_labels, predict_val_lengths, val_label_lensin).item()\n",
    "            val_loss = epoch_val_loss / len(val_dl)\n",
    "\n",
    "    lst_loss_train.append(train_loss)\n",
    "    lst_loss_val.append(val_loss)\n",
    "\n",
    "    # scheduler.step(val_loss)\n",
    "\n",
    "\n",
    "            \n",
    "    print(f\"===== Эпоха {epoch+1}/{EPOCHS} =====\")\n",
    "    # print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "    grad_norms = [param.grad.norm().item() for param in model.parameters() if param.grad is not None]\n",
    "    if grad_norms:\n",
    "        print(f\"Mean grad norm: {np.mean(grad_norms):.6f}\")\n",
    "        print(f\"Max grad norm: {np.max(grad_norms):.6f}\")\n",
    "        print(f\"Min grad norm: {np.min(grad_norms):.6f}\")\n",
    "    else:\n",
    "        print(\"No gradients computed yet.\")\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}\")\n",
    "    print(f\"LR: {optimizer.param_groups[0][\"lr\"]:.2e}\")\n",
    "    print(\"\\n\"+\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa7f726",
   "metadata": {},
   "source": [
    "# Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "422ea6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 1/20 =====\n",
      "Mean grad norm: 0.085850\n",
      "Max grad norm: 1.005806\n",
      "Min grad norm: 0.000000\n",
      "Train Loss: 4.1436\n",
      "Val Loss: 4.0235\n",
      "Current LR: 2.00e-04\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 2/20 =====\n",
      "Mean grad norm: 0.326711\n",
      "Max grad norm: 1.668219\n",
      "Min grad norm: 0.000000\n",
      "Train Loss: 3.9235\n",
      "Val Loss: 3.3938\n",
      "Current LR: 2.00e-04\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 3/20 =====\n",
      "Mean grad norm: 0.335563\n",
      "Max grad norm: 2.200292\n",
      "Min grad norm: 0.000000\n",
      "Train Loss: 1.8223\n",
      "Val Loss: 0.6184\n",
      "Current LR: 2.00e-04\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 4/20 =====\n",
      "Mean grad norm: 0.274909\n",
      "Max grad norm: 1.997544\n",
      "Min grad norm: 0.000000\n",
      "Train Loss: 1.0663\n",
      "Val Loss: 0.4010\n",
      "Current LR: 2.00e-04\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 5/20 =====\n",
      "Mean grad norm: 0.302335\n",
      "Max grad norm: 1.920506\n",
      "Min grad norm: 0.000000\n",
      "Train Loss: 0.9022\n",
      "Val Loss: 0.3365\n",
      "Current LR: 2.00e-04\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 6/20 =====\n",
      "Mean grad norm: 0.306850\n",
      "Max grad norm: 1.801928\n",
      "Min grad norm: 0.000000\n",
      "Train Loss: 0.8270\n",
      "Val Loss: 0.2881\n",
      "Current LR: 2.00e-04\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 7/20 =====\n",
      "Mean grad norm: 0.245806\n",
      "Max grad norm: 1.633025\n",
      "Min grad norm: 0.000000\n",
      "Train Loss: 0.7833\n",
      "Val Loss: 0.2646\n",
      "Current LR: 2.00e-04\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 8/20 =====\n",
      "Mean grad norm: 0.316028\n",
      "Max grad norm: 2.324334\n",
      "Min grad norm: 0.000000\n",
      "Train Loss: 0.7458\n",
      "Val Loss: 0.2376\n",
      "Current LR: 2.00e-04\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 9/20 =====\n",
      "Mean grad norm: 0.223619\n",
      "Max grad norm: 1.391899\n",
      "Min grad norm: 0.000000\n",
      "Train Loss: 0.7242\n",
      "Val Loss: 0.2319\n",
      "Current LR: 2.00e-04\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 10/20 =====\n",
      "Mean grad norm: 0.235263\n",
      "Max grad norm: 1.556732\n",
      "Min grad norm: 0.000000\n",
      "Train Loss: 0.6953\n",
      "Val Loss: 0.2115\n",
      "Current LR: 2.00e-04\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 11/20 =====\n",
      "Mean grad norm: 0.233918\n",
      "Max grad norm: 1.357821\n",
      "Min grad norm: 0.000000\n",
      "Train Loss: 0.6751\n",
      "Val Loss: 0.2079\n",
      "Current LR: 2.00e-04\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 12/20 =====\n",
      "Mean grad norm: 0.229712\n",
      "Max grad norm: 1.517110\n",
      "Min grad norm: 0.000000\n",
      "Train Loss: 0.6590\n",
      "Val Loss: 0.1976\n",
      "Current LR: 2.00e-04\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 13/20 =====\n",
      "Mean grad norm: 0.273000\n",
      "Max grad norm: 2.150087\n",
      "Min grad norm: 0.000000\n",
      "Train Loss: 0.6479\n",
      "Val Loss: 0.2050\n",
      "Current LR: 2.00e-04\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 14/20 =====\n",
      "Mean grad norm: 0.255824\n",
      "Max grad norm: 1.911178\n",
      "Min grad norm: 0.000000\n",
      "Train Loss: 0.6372\n",
      "Val Loss: 0.1858\n",
      "Current LR: 2.00e-04\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 15/20 =====\n",
      "Mean grad norm: 0.221895\n",
      "Max grad norm: 1.576340\n",
      "Min grad norm: 0.000000\n",
      "Train Loss: 0.6318\n",
      "Val Loss: 0.1944\n",
      "Current LR: 2.00e-04\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 16/20 =====\n",
      "Mean grad norm: 0.313765\n",
      "Max grad norm: 2.377007\n",
      "Min grad norm: 0.000000\n",
      "Train Loss: 0.6201\n",
      "Val Loss: 0.1775\n",
      "Current LR: 2.00e-04\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 17/20 =====\n",
      "Mean grad norm: 0.247832\n",
      "Max grad norm: 1.595030\n",
      "Min grad norm: 0.000000\n",
      "Train Loss: 0.6082\n",
      "Val Loss: 0.1714\n",
      "Current LR: 2.00e-04\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 18/20 =====\n",
      "Mean grad norm: 0.270576\n",
      "Max grad norm: 2.080219\n",
      "Min grad norm: 0.000000\n",
      "Train Loss: 0.6043\n",
      "Val Loss: 0.1669\n",
      "Current LR: 2.00e-04\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 19/20 =====\n",
      "Mean grad norm: 0.276422\n",
      "Max grad norm: 2.250238\n",
      "Min grad norm: 0.000000\n",
      "Train Loss: 0.5967\n",
      "Val Loss: 0.1659\n",
      "Current LR: 2.00e-04\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 20/20 =====\n",
      "Mean grad norm: 0.469851\n",
      "Max grad norm: 6.043739\n",
      "Min grad norm: 0.000000\n",
      "Train Loss: 0.5899\n",
      "Val Loss: 0.1675\n",
      "Current LR: 2.00e-04\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "lst_loss_train = []\n",
    "lst_loss_val = []\n",
    "pr = []\n",
    "p_Val = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # ======== Обучение ========\n",
    "    model.train()\n",
    "    epoch_train_loss = 0.0\n",
    "    \n",
    "    train_tqdm = tqdm(train_dl, desc=f\"Эпоха {epoch+1}/{EPOCHS} [Обучение]\", leave=False)\n",
    "    for batch_ind, batch in enumerate(train_tqdm):\n",
    "        mel_spec, targets, targets_lens, _ = batch\n",
    "        mel_spec = mel_spec.to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "        targets_lens = targets_lens.to(DEVICE)\n",
    "\n",
    "        #===== считатем длинну mel_spec для передачи в CTC loss =====\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        predict = model(mel_spec)  # (N=batch,T,C)\n",
    "        pr.append(predict)\n",
    "        \n",
    "        N = predict.shape[1]\n",
    "        T = predict.shape[0]\n",
    "        predict_lengths = torch.full(size=(N,), fill_value=T, dtype=torch.long)\n",
    "\n",
    "        try:\n",
    "            loss = loss_func(predict, targets, predict_lengths, targets_lens.reshape(BATCH_SIZE))\n",
    "        except RuntimeError:\n",
    "            print(predict.shape, targets.shape, predict_lengths, targets_lens.reshape(BATCH_SIZE))\n",
    "            continue\n",
    "\n",
    "        if torch.isnan(loss) or torch.isinf(loss): \n",
    "            print(f\"\\nWarning: In batch-{batch_ind} loss train is NaN/Inf: {loss.item()}\")\n",
    "            optimizer.zero_grad()\n",
    "            continue\n",
    "\n",
    "        loss.backward()\n",
    "        # nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_train_loss += loss.item()\n",
    "        train_tqdm.set_postfix({'train_loss': loss.item()})\n",
    "\n",
    "    # Правильное усреднение после эпохи\n",
    "    train_loss = epoch_train_loss / len(train_dl)\n",
    "    lst_loss_train.append(train_loss)\n",
    "\n",
    "    # ======== Валидация ========\n",
    "    model.eval()\n",
    "    epoch_val_loss = 0.0  # Исправлено: инициализация перед циклом\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        val_tqdm = tqdm(val_dl, desc=f\"Эпоха {epoch+1}/{EPOCHS} [Валидация]\", leave=False)\n",
    "        for val_mel_spec, val_labels, val_label_lens, _ in val_tqdm:\n",
    "            val_mel_spec = val_mel_spec.to(DEVICE)\n",
    "            val_labels = val_labels.to(DEVICE)\n",
    "            val_label_lens = val_label_lens.to(DEVICE)\n",
    "            \n",
    "            val_predict = model(val_mel_spec)\n",
    "            p_Val.append(val_predict)\n",
    "            \n",
    "            val_N = val_predict.shape[1]\n",
    "            val_T = val_predict.shape[0]\n",
    "            predict_val_lengths = torch.full(size=(val_N,), fill_value=val_T, dtype=torch.long)\n",
    "            \n",
    "            loss = loss_func(val_predict, val_labels, predict_val_lengths, val_label_lens)\n",
    "            epoch_val_loss += loss.item()\n",
    "            # val_tqdm.set_postfix({'val_loss': loss.item()})\n",
    "\n",
    "    # Правильное усреднение после эпохи\n",
    "    val_loss = epoch_val_loss / len(val_dl)\n",
    "    lst_loss_val.append(val_loss)\n",
    "\n",
    "    # scheduler.step(val_loss)  \n",
    "\n",
    "    # ======== Вывод информации ========\n",
    "    print(f\"\\n===== Эпоха {epoch+1}/{EPOCHS} =====\")\n",
    "    grad_norms = [param.grad.norm().item() for param in model.parameters() if param.grad is not None]\n",
    "    if grad_norms:\n",
    "        print(f\"Mean grad norm: {np.mean(grad_norms):.6f}\")\n",
    "        print(f\"Max grad norm: {np.max(grad_norms):.6f}\")\n",
    "        print(f\"Min grad norm: {np.min(grad_norms):.6f}\")\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.4f}\")  # Средний лосс за эпоху\n",
    "    print(f\"Val Loss: {val_loss:.4f}\")     # Средний лосс за эпоху\n",
    "    print(f\"Current LR: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "    print(\"-\" * 50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca52e14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'MorseNet.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1547a2ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lst_loss_train)\n",
    "plt.plot(lst_loss_val)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58358780",
   "metadata": {},
   "source": [
    "# Проверка качества модели "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b4b4b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN размерность выхода: torch.Size([1, 32, 16, 89])\n",
      "CNN число фичей: 512\n",
      "Проекция из 512 в 256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): MorseNet(\n",
       "    (net_conv): Sequential(\n",
       "      (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "      (4): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): GELU(approximate='none')\n",
       "      (7): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "      (8): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (9): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (10): GELU(approximate='none')\n",
       "      (11): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "      (12): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (13): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (14): GELU(approximate='none')\n",
       "      (15): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (layer1): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (gelu): GELU(approximate='none')\n",
       "    (rnn): GRU(256, 128, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "    (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "    (layer2): Linear(in_features=256, out_features=45, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ctc_decoder(logits, int_char_map, blank_label_idx):\n",
    "    preds = []\n",
    "    logits_cpu = logits.cpu() \n",
    "    max_inds = torch.argmax(logits_cpu.detach(), dim=2).t().numpy() # арзмакс по лагитам и преобразование к словарю\n",
    "    \n",
    "    for ind in max_inds:\n",
    "        merged_inds = []\n",
    "        for idx in ind:\n",
    "            if idx != blank_label_idx: \n",
    "                merged_inds.append(idx)\n",
    "        text = \"\".join([int_char_map.get(i, '?') for i in merged_inds])\n",
    "        preds.append(text)\n",
    "\n",
    "    return preds\n",
    "\n",
    "model_load = nn.DataParallel(MorseNet(num_classes=num_classes))\n",
    "model_load.load_state_dict(torch.load('MorseNet.pth'))\n",
    "model_load.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f65295",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    train_mess = []\n",
    "    train_predicts = []\n",
    "    for loader in train_dl:\n",
    "        seq, test_target, _, mess = loader\n",
    "        train_mess.extend(mess)\n",
    "\n",
    "        logits = model_load(seq)\n",
    "        predicted_values = ctc_decoder(logits, int_to_char, BLANK_IDX)\n",
    "        train_predicts.extend(predicted_values)\n",
    "\n",
    "    val_mess = []\n",
    "    val_predicts = []\n",
    "    for loader in val_dl:\n",
    "        seq, test_target, _, mess = loader\n",
    "        val_mess.extend(mess)\n",
    "\n",
    "        logits= model_load(seq)\n",
    "        predicted_values = ctc_decoder(logits, int_to_char, BLANK_IDX)\n",
    "        val_predicts.extend(predicted_values)\n",
    "\n",
    "import Levenshtein\n",
    "\n",
    "mean_acc_test = np.mean([Levenshtein.ratio(test_pred, train_mess[ind]) for ind, test_pred in enumerate(train_predicts)])\n",
    "mean_acc_val = np.mean([Levenshtein.ratio(val_pred, val_mess[ind]) for ind, val_pred in enumerate(val_predicts)])\n",
    "\n",
    "\n",
    "print(f\"Mean accurasu by The Levenshtein in train is : {mean_acc_test}\")\n",
    "print(f\"Mean accurasu by The Levenshtein in validate is : {mean_acc_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f45a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = MosreDataset(df=sample_data,\n",
    "                        data_patch=DATASET_PATCH,\n",
    "                        char_to_int=char_to_int,\n",
    "                        train=False,\n",
    "                        transforms=valid_audio_transforms)\n",
    "     \n",
    "test_dl = torch.utils.data.DataLoader(test_ds, batch_size=20, shuffle=False, collate_fn=my_collate)\n",
    "model_load.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_predicts = []\n",
    "    for loader in test_dl:\n",
    "        seq = loader\n",
    "        logits = model_load(seq)\n",
    "        predicted_values = ctc_decoder(logits, int_to_char, BLANK_IDX)\n",
    "        test_predicts.extend(predicted_values)\n",
    "\n",
    "sample_data.message = test_predicts\n",
    "sample_data.to_csv('sample_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Morse_decoder_V2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

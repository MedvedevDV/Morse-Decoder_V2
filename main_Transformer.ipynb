{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d761d8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path as pt\n",
    "import torch\n",
    "import torchaudio\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchaudio import transforms\n",
    "from torchvision.transforms import v2\n",
    "# from Moduls.MosreDataset import MosreDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch.nn.parallel import DataParallel\n",
    "from collections import Counter\n",
    "import math\n",
    "DIVICE = torch.device(\"cuda\")\n",
    "\n",
    "MAIN = pt(os.getcwd())\n",
    "DATASET_PATCH = MAIN / 'morse_dataset'\n",
    "AUDIO_FILES = DATASET_PATCH / 'morse_dataset'\n",
    "\n",
    "# Поятоянные значения выявленные в процессе анализа\n",
    "MORSEALP = \"АБВГДЕЁЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯ 1234567890#\"\n",
    "MAX_TIME = 48\n",
    "SAMPLE_RATE = 8000\n",
    "N_MELS = 128\n",
    "N_FFT = 400\n",
    "HOP_LENGTH = 180\n",
    "TOP_DB = 80\n",
    "FREQ_MASK = 15\n",
    "TIME_MASK = 20\n",
    "\n",
    "# Гиперпараметы обучения\n",
    "SEED = 42\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 0.0002 #2e-4\n",
    "WEIGHT_DECAY = 0.00001\n",
    "# int_to_alph = dict(enumerate(MORSEALP))\n",
    "# alph_to_int = {char:enum for enum, char in int_to_alph.items()}\n",
    "\n",
    "#===== Import data =====\n",
    "train_data = pd.read_csv(pt.joinpath(DATASET_PATCH,'train.csv'))\n",
    "test_data = pd.read_csv(pt.joinpath(DATASET_PATCH,'test.csv'))\n",
    "sample_data = pd.read_csv(pt.joinpath(DATASET_PATCH,'sample_submission.csv'))\n",
    "\n",
    "all_chars = Counter(\"\".join(train_data['message']))\n",
    "BLANK_CHAR = \"_\"\n",
    "vocab_list = sorted(all_chars.keys()) + [BLANK_CHAR]\n",
    "num_classes = len(vocab_list)\n",
    "char_to_int = {char: i for i, char in enumerate(vocab_list)}\n",
    "int_to_char = {i: char for i, char in enumerate(vocab_list)}\n",
    "BLANK_IDX = char_to_int[BLANK_CHAR]\n",
    "\n",
    "class MosreDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Класс для обработки \n",
    "    \"\"\"\n",
    "    def __init__(self, df, data_patch,char_to_int, train=True, transforms=None, prev_chars = 1):\n",
    "        self.df = df\n",
    "        self.is_train = train\n",
    "\n",
    "        self.data_path = data_patch\n",
    "        self.audio_paths = self.data_path / 'morse_dataset'\n",
    "\n",
    "        self.transforms = transforms\n",
    "\n",
    "        self.char_to_int = char_to_int\n",
    "        self.prev_chars = prev_chars\n",
    "\n",
    "        if self.is_train:\n",
    "            self.messeges = self.df.message.values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        #Получение аугментрованых спектрограмм\n",
    "        try:\n",
    "            audio_file = self.audio_paths / self.df.id.values[index]\n",
    "            waveform, sample_rate = torchaudio.load(audio_file)\n",
    "            augmented_spectrogram = self.transforms(waveform)\n",
    "            spec_lens = augmented_spectrogram.shape[-1]\n",
    "            if self.is_train:\n",
    "                message = self.messeges[index]\n",
    "                #Получение списка индексов секта - как требует CTC los\n",
    "                '''\n",
    "                При обработке dataloader labels будут выравниваться по макс длине для выравнивания батча\n",
    "                Т.е. будет padding 0. что в будующем будет пустым значением для ctc loss\n",
    "                '''\n",
    "                target = torch.tensor([self.char_to_int[char] for char in message], dtype=torch.long); \n",
    "                target_len = torch.tensor(len(target), dtype=torch.long)\n",
    "                return augmented_spectrogram, spec_lens, target ,target_len, message\n",
    "            else:\n",
    "                return augmented_spectrogram,spec_lens, None, None, None\n",
    "        except Exception as ex:\n",
    "            print(str(ex))\n",
    "        \n",
    "    def change_time(self, audio_file, max_len = 384000):\n",
    "        waveform, sample_rate = torchaudio.load(audio_file)\n",
    "        cahanal, sig_len = waveform.shape\n",
    "\n",
    "        if sig_len < max_len:\n",
    "            pad_len = torch.zeros(max_len - sig_len).unsqueeze(0)\n",
    "            waveform = torch.cat([waveform, pad_len], dim=1)\n",
    "\n",
    "        return waveform\n",
    "    \n",
    "FIRST_FE_COUNT = 16\n",
    "SECOND_FE_COUNT = 32\n",
    "THIRD_FE_COUNT = 32\n",
    "QAD_FE_COUNT = 32\n",
    "PADDING = 'same'\n",
    "MAXPOOL_KERNEL = 2\n",
    "KERTNEL_SIZE = 3\n",
    "NERON_COUNT = 128\n",
    "GRU_HIDEN = 256\n",
    "\n",
    "# Start with 4 transforms\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super().__init__()\n",
    "        self.squeeze = nn.AdaptiveAvgPool2d(1)  # [B, C, 1, 1]\n",
    "        self.excitation = nn.Sequential(\n",
    "            nn.Linear(channels, channels // reduction),  # [B, C/reduction]\n",
    "            nn.GELU(),\n",
    "            nn.Linear(channels // reduction, channels),  # [B, C]\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B, C, _, _ = x.shape\n",
    "        squeezed = self.squeeze(x).view(B, C)  # [B, C]\n",
    "        weights = self.excitation(squeezed).view(B, C, 1, 1)  # [B, C, 1, 1]\n",
    "        return x * weights  # Масштабируем каналы\n",
    "    \n",
    "class Embedding(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, \n",
    "                      out_channels=FIRST_FE_COUNT, \n",
    "                      kernel_size=KERTNEL_SIZE , stride=1, padding=PADDING),\n",
    "            nn.BatchNorm2d(FIRST_FE_COUNT),\n",
    "            SEBlock(FIRST_FE_COUNT, 4),\n",
    "            nn.GELU(),\n",
    "            nn.MaxPool2d((1, 2), (1, 2)), # [batch, FIRST_FE_COUNT = 16, 64, 960]\n",
    "\n",
    "            nn.Conv2d(in_channels=FIRST_FE_COUNT, \n",
    "                      out_channels=SECOND_FE_COUNT, \n",
    "                      kernel_size=KERTNEL_SIZE , stride=1, padding=PADDING),\n",
    "            nn.BatchNorm2d(SECOND_FE_COUNT),\n",
    "            nn.GELU(),\n",
    "            SEBlock(SECOND_FE_COUNT, 8),\n",
    "            nn.MaxPool2d((2, 1), (2, 1)), # [batch, SECOND_FE_COUNT = 32, 32, 480]\n",
    "\n",
    "            nn.Conv2d(in_channels=SECOND_FE_COUNT, \n",
    "                      out_channels=THIRD_FE_COUNT, \n",
    "                      kernel_size=KERTNEL_SIZE , stride=1, padding=PADDING),\n",
    "            nn.BatchNorm2d(THIRD_FE_COUNT),\n",
    "            nn.GELU(),\n",
    "            SEBlock(THIRD_FE_COUNT, 16),\n",
    "            nn.MaxPool2d((2, 2), (2, 2)), # [batch, THIRD_FE_COUNT = 32, 16, 240]\n",
    "\n",
    "            nn.Conv2d(in_channels=THIRD_FE_COUNT, \n",
    "                      out_channels=QAD_FE_COUNT, \n",
    "                      kernel_size=KERTNEL_SIZE , stride=1, padding=PADDING),\n",
    "            nn.BatchNorm2d(QAD_FE_COUNT, 16),\n",
    "            nn.GELU(),\n",
    "            SEBlock(QAD_FE_COUNT),\n",
    "            nn.MaxPool2d((2, 1), (2, 1)) # [batch=32, QAD_FE_COUNT = 32, 16, 89](что юы сохраниить большще признаков по горизонтали)\n",
    "        )\n",
    "        self.cnn_output_features = 0\n",
    "        self.layer1 = nn.Linear(self.cnn_output_features, N_MELS*2); \n",
    "        self.gelu = nn.GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net_conv(x)\n",
    "        return x\n",
    "\n",
    "class PositionalEncoding(nn.Module): # класический\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return x\n",
    "    \n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(self).__init__()\n",
    "        self.self_attn = nn.MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = nn.PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        attn_output = self.self_attn(x, x, x, mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        return x\n",
    "\n",
    "    def _get_output_lengths(self, input_lengths):\n",
    "        output_lengths = torch.floor(input_lengths.float() / 4); \n",
    "        return torch.clamp(output_lengths.long(), min=1)\n",
    "    \n",
    "\n",
    "train_audio_transforms = nn.Sequential(\n",
    "    transforms.MelSpectrogram(sample_rate=SAMPLE_RATE, n_fft=N_FFT, hop_length=HOP_LENGTH, n_mels=N_MELS),\n",
    "    transforms.AmplitudeToDB(top_db=TOP_DB),\n",
    "    transforms.FrequencyMasking(freq_mask_param=FREQ_MASK),\n",
    "    transforms.TimeMasking(time_mask_param=TIME_MASK),\n",
    "    # v2.RandomCrop((N_MELS, 1920)) # Обрезает последний кадр спектрограммы, в идеале надобы считать а не прописывать число\n",
    "    ) # заметка - Данные трансформации не создают довых обучаемых параметров. Но есть и те что создают. В будущем это стоит учитывать\n",
    "\n",
    "valid_audio_transforms = nn.Sequential(\n",
    "    transforms.MelSpectrogram(sample_rate=SAMPLE_RATE, n_fft=N_FFT, hop_length=HOP_LENGTH, n_mels=N_MELS),\n",
    "    transforms.AmplitudeToDB(top_db=TOP_DB),\n",
    "    # v2.CenterCrop((N_MELS, 1920)) \n",
    "    )\n",
    "\n",
    "train_dataframe, val_dataframe = train_test_split(train_data, test_size=0.15, random_state=SEED)\n",
    "\n",
    "train_ds = MosreDataset(df=train_dataframe,\n",
    "                        data_patch=DATASET_PATCH,\n",
    "                        char_to_int=char_to_int,\n",
    "                        train=True,\n",
    "                        transforms=train_audio_transforms)\n",
    "\n",
    "val_ds = MosreDataset(df=val_dataframe,\n",
    "                        data_patch=DATASET_PATCH,\n",
    "                        char_to_int=char_to_int,\n",
    "                        train=True,\n",
    "                        transforms=valid_audio_transforms)\n",
    "\n",
    "\n",
    "def my_collate(batch):\n",
    "    spectrograms = [item[0].squeeze(0) for item in batch]\n",
    "    # Падинг спектрограмм по максимальной длине\n",
    "    spectrograms_permuted = [s.permute(1, 0) for s in spectrograms]\n",
    "    spectrograms_padded = nn.utils.rnn.pad_sequence(spectrograms_permuted, batch_first=True, padding_value=0.0)\n",
    "    spectrograms_padded = spectrograms_padded.permute(0, 2, 1).unsqueeze(1)\n",
    "    # spec_lens = torch.stack([item[0] for item in batch])\n",
    "    spec_lens = torch.tensor([item[1] for item in batch]).reshape(BATCH_SIZE)\n",
    "    if batch[0][3] is not None:\n",
    "        target = torch.nn.utils.rnn.pad_sequence(\n",
    "                                                [item[2] for item in batch], \n",
    "                                                batch_first=True, \n",
    "                                                padding_value=BLANK_IDX)# выравнивает последовательность до макс \n",
    "                                                                        # длины в батче заполняя пропуски нулем\n",
    "        label_len = torch.stack([item[3] for item in batch])\n",
    "        msg = [item[4] for item in batch]\n",
    "        \n",
    "        return [spectrograms_padded, spec_lens, target, label_len, msg]\n",
    "    else: \n",
    "        return spectrograms_padded\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=my_collate, drop_last=True)\n",
    "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=my_collate, drop_last=True)\n",
    "\n",
    "# test, test_lens, test_target, _, mess = next(iter(train_dl))\n",
    "# test, test_target= test.to(DIVICE), test_target.to(DIVICE)\n",
    "\n",
    "# test_val, val_lens, val_target, __, val_mess = next(iter(val_dl))\n",
    "# test_val, val_target = test_val.to(DIVICE), val_target.to(DIVICE)\n",
    "# test.shape \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "87b1a2a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False, False,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False,  True,  True,  True,  True,  True]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_padding_mask = torch.zeros(32, 10, dtype=torch.bool)  # (batch_size, sequence_length)\n",
    "key_padding_mask[:, 5:] = 1\n",
    "key_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef76d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_output_lengths(x, input_lengths):\n",
    "    output_lengths = torch.floor(input_lengths.float() / 4); \n",
    "    return torch.clamp(output_lengths.long(), min=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "62ada272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 25,  25,  25,  81,  25, 125])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dl))[1]\n",
    "\n",
    "_get_output_lengths(torch.tensor([100,100,100,324,100,500]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2957fb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===== начало обучения =====\n",
    "model = MorseNet(num_classes=num_classes).to(DIVICE)\n",
    "# model = DataParallel(model)\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=0.002)  # Было 0.002\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "loss_func = nn.CTCLoss(blank=BLANK_IDX, reduction='mean', zero_infinity=True).to(DIVICE)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nMorseNet - инициалицация модели. Число обучаемых параметров: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d2fbb29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\homer\\OneDrive\\Desktop\\Morse_Decoder_V2\\Morse_decoder_V2\\Lib\\site-packages\\torch\\nn\\init.py:511: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Module [Embedding] is missing the required \"forward\" function",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m model = Embedding(num_classes=num_classes).to(DIVICE)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m emb_out = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m emb_out\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\homer\\OneDrive\\Desktop\\Morse_Decoder_V2\\Morse_decoder_V2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\homer\\OneDrive\\Desktop\\Morse_Decoder_V2\\Morse_decoder_V2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\homer\\OneDrive\\Desktop\\Morse_Decoder_V2\\Morse_decoder_V2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:387\u001b[39m, in \u001b[36m_forward_unimplemented\u001b[39m\u001b[34m(self, *input)\u001b[39m\n\u001b[32m    376\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_forward_unimplemented\u001b[39m(\u001b[38;5;28mself\u001b[39m, *\u001b[38;5;28minput\u001b[39m: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    377\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Define the computation performed at every call.\u001b[39;00m\n\u001b[32m    378\u001b[39m \n\u001b[32m    379\u001b[39m \u001b[33;03m    Should be overridden by all subclasses.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    385\u001b[39m \u001b[33;03m        registered hooks while the latter silently ignores them.\u001b[39;00m\n\u001b[32m    386\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m387\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[32m    388\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mModule [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] is missing the required \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mforward\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m function\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    389\u001b[39m     )\n",
      "\u001b[31mNotImplementedError\u001b[39m: Module [Embedding] is missing the required \"forward\" function"
     ]
    }
   ],
   "source": [
    "model = Embedding(num_classes=num_classes).to(DIVICE)\n",
    "emb_out = model(test)\n",
    "emb_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa7f726",
   "metadata": {},
   "source": [
    "# Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c23dee31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Levenshtein\n",
    "def ctc_decoder(logits, int_char_map, blank_label_idx):\n",
    "    preds = []\n",
    "    logits_cpu = logits.cpu() \n",
    "    max_inds = torch.argmax(logits_cpu.detach(), dim=2).t().numpy() # арзмакс по лагитам и преобразование к словарю\n",
    "    \n",
    "    for ind in max_inds:\n",
    "        merged_inds = []\n",
    "        for idx in ind:\n",
    "            if idx != blank_label_idx: \n",
    "                merged_inds.append(idx)\n",
    "        text = \"\".join([int_char_map.get(i, '?') for i in merged_inds])\n",
    "        preds.append(text)\n",
    "\n",
    "    return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "422ea6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 1/50 =====\n",
      "Mean grad norm: 0.022087\n",
      "Max grad norm: 0.972216\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.002000\n",
      "---- Train Loss: 4.1686\n",
      "---- Val Loss: 4.0351\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 2/50 =====\n",
      "Mean grad norm: 0.070542\n",
      "Max grad norm: 0.553876\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.002000\n",
      "---- Train Loss: 2.5585\n",
      "---- Val Loss: 0.5602\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 3/50 =====\n",
      "Mean grad norm: 0.062897\n",
      "Max grad norm: 0.666260\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.002000\n",
      "---- Train Loss: 0.5613\n",
      "---- Val Loss: 0.2444\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 4/50 =====\n",
      "Mean grad norm: 0.064604\n",
      "Max grad norm: 0.507543\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.002000\n",
      "---- Train Loss: 0.4149\n",
      "---- Val Loss: 0.2004\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 5/50 =====\n",
      "Mean grad norm: 0.036125\n",
      "Max grad norm: 0.298841\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.002000\n",
      "---- Train Loss: 0.3610\n",
      "---- Val Loss: 0.1687\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 6/50 =====\n",
      "Mean grad norm: 0.053615\n",
      "Max grad norm: 0.396670\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.002000\n",
      "---- Train Loss: 0.3298\n",
      "---- Val Loss: 0.1658\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 7/50 =====\n",
      "Mean grad norm: 0.062139\n",
      "Max grad norm: 0.654993\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.002000\n",
      "---- Train Loss: 0.3147\n",
      "---- Val Loss: 0.1561\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 8/50 =====\n",
      "Mean grad norm: 0.062966\n",
      "Max grad norm: 0.541432\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.002000\n",
      "---- Train Loss: 0.2982\n",
      "---- Val Loss: 0.1773\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 9/50 =====\n",
      "Mean grad norm: 0.063755\n",
      "Max grad norm: 0.800694\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.002000\n",
      "---- Train Loss: 0.2886\n",
      "---- Val Loss: 0.1504\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 10/50 =====\n",
      "Mean grad norm: 0.055470\n",
      "Max grad norm: 0.503541\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.002000\n",
      "---- Train Loss: 0.2750\n",
      "---- Val Loss: 0.1482\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 11/50 =====\n",
      "Mean grad norm: 0.038079\n",
      "Max grad norm: 0.273240\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.002000\n",
      "---- Train Loss: 0.2717\n",
      "---- Val Loss: 0.1417\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 12/50 =====\n",
      "Mean grad norm: 0.063230\n",
      "Max grad norm: 0.423697\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.002000\n",
      "---- Train Loss: 0.2613\n",
      "---- Val Loss: 0.1511\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 13/50 =====\n",
      "Mean grad norm: 0.049591\n",
      "Max grad norm: 0.304322\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.002000\n",
      "---- Train Loss: 0.2553\n",
      "---- Val Loss: 0.1456\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 14/50 =====\n",
      "Mean grad norm: 0.037707\n",
      "Max grad norm: 0.230941\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.002000\n",
      "---- Train Loss: 0.2473\n",
      "---- Val Loss: 0.1391\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 15/50 =====\n",
      "Mean grad norm: 0.046601\n",
      "Max grad norm: 0.380733\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.002000\n",
      "---- Train Loss: 0.2470\n",
      "---- Val Loss: 0.1453\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 16/50 =====\n",
      "Mean grad norm: 0.046754\n",
      "Max grad norm: 0.395047\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.002000\n",
      "---- Train Loss: 0.2385\n",
      "---- Val Loss: 0.1394\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 17/50 =====\n",
      "Mean grad norm: 0.045973\n",
      "Max grad norm: 0.354849\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.002000\n",
      "---- Train Loss: 0.2389\n",
      "---- Val Loss: 0.1392\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 18/50 =====\n",
      "Mean grad norm: 0.056559\n",
      "Max grad norm: 0.748435\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.002000\n",
      "---- Train Loss: 0.2334\n",
      "---- Val Loss: 0.1388\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 19/50 =====\n",
      "Mean grad norm: 0.035549\n",
      "Max grad norm: 0.303391\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.002000\n",
      "---- Train Loss: 0.2316\n",
      "---- Val Loss: 0.1338\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 20/50 =====\n",
      "Mean grad norm: 0.045660\n",
      "Max grad norm: 0.368888\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.002000\n",
      "---- Train Loss: 0.2304\n",
      "---- Val Loss: 0.1380\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 21/50 =====\n",
      "Mean grad norm: 0.036161\n",
      "Max grad norm: 0.413403\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.002000\n",
      "---- Train Loss: 0.2285\n",
      "---- Val Loss: 0.1329\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 22/50 =====\n",
      "Mean grad norm: 0.045496\n",
      "Max grad norm: 0.435238\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.002000\n",
      "---- Train Loss: 0.2245\n",
      "---- Val Loss: 0.1338\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 23/50 =====\n",
      "Mean grad norm: 0.040601\n",
      "Max grad norm: 0.476108\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.002000\n",
      "---- Train Loss: 0.2211\n",
      "---- Val Loss: 0.1350\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 24/50 =====\n",
      "Mean grad norm: 0.067148\n",
      "Max grad norm: 0.753639\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.002000\n",
      "---- Train Loss: 0.2182\n",
      "---- Val Loss: 0.1432\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 25/50 =====\n",
      "Mean grad norm: 0.061821\n",
      "Max grad norm: 0.840548\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.001000\n",
      "---- Train Loss: 0.2165\n",
      "---- Val Loss: 0.1451\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 26/50 =====\n",
      "Mean grad norm: 0.038779\n",
      "Max grad norm: 0.370544\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.001000\n",
      "---- Train Loss: 0.1959\n",
      "---- Val Loss: 0.1310\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 27/50 =====\n",
      "Mean grad norm: 0.041363\n",
      "Max grad norm: 0.483809\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.001000\n",
      "---- Train Loss: 0.1923\n",
      "---- Val Loss: 0.1356\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 28/50 =====\n",
      "Mean grad norm: 0.023501\n",
      "Max grad norm: 0.198048\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.001000\n",
      "---- Train Loss: 0.1812\n",
      "---- Val Loss: 0.1430\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 29/50 =====\n",
      "Mean grad norm: 0.020703\n",
      "Max grad norm: 0.137880\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.001000\n",
      "---- Train Loss: 0.1793\n",
      "---- Val Loss: 0.1383\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 30/50 =====\n",
      "Mean grad norm: 0.042217\n",
      "Max grad norm: 0.247247\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.000500\n",
      "---- Train Loss: 0.1768\n",
      "---- Val Loss: 0.1442\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 31/50 =====\n",
      "Mean grad norm: 0.070645\n",
      "Max grad norm: 0.735852\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.000500\n",
      "---- Train Loss: 0.1683\n",
      "---- Val Loss: 0.1365\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 32/50 =====\n",
      "Mean grad norm: 0.027807\n",
      "Max grad norm: 0.214193\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.000500\n",
      "---- Train Loss: 0.1632\n",
      "---- Val Loss: 0.1379\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 33/50 =====\n",
      "Mean grad norm: 0.029956\n",
      "Max grad norm: 0.205058\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.000500\n",
      "---- Train Loss: 0.1593\n",
      "---- Val Loss: 0.1399\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 34/50 =====\n",
      "Mean grad norm: 0.071418\n",
      "Max grad norm: 0.719050\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.000250\n",
      "---- Train Loss: 0.1600\n",
      "---- Val Loss: 0.1401\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 35/50 =====\n",
      "Mean grad norm: 0.056433\n",
      "Max grad norm: 0.434097\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.000250\n",
      "---- Train Loss: 0.1591\n",
      "---- Val Loss: 0.1389\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 36/50 =====\n",
      "Mean grad norm: 0.032238\n",
      "Max grad norm: 0.184965\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.000250\n",
      "---- Train Loss: 0.1563\n",
      "---- Val Loss: 0.1381\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 37/50 =====\n",
      "Mean grad norm: 0.026891\n",
      "Max grad norm: 0.156677\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.000250\n",
      "---- Train Loss: 0.1539\n",
      "---- Val Loss: 0.1422\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 38/50 =====\n",
      "Mean grad norm: 0.023550\n",
      "Max grad norm: 0.138763\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.000125\n",
      "---- Train Loss: 0.1510\n",
      "---- Val Loss: 0.1417\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 39/50 =====\n",
      "Mean grad norm: 0.040658\n",
      "Max grad norm: 0.245864\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.000125\n",
      "---- Train Loss: 0.1488\n",
      "---- Val Loss: 0.1417\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Эпоха 40/50 =====\n",
      "Mean grad norm: 0.041323\n",
      "Max grad norm: 0.399770\n",
      "Min grad norm: 0.000000\n",
      "Current LR: 0.000125\n",
      "---- Train Loss: 0.1492\n",
      "---- Val Loss: 0.1457\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m train_predicts = []\n\u001b[32m     10\u001b[39m train_tqdm = tqdm(train_dl, desc=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mЭпоха \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m [Обучение]\u001b[39m\u001b[33m\"\u001b[39m, leave=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_ind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_tqdm\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmel_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets_lens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmel_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets_lens\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmel_spec\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDIVICE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDIVICE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets_lens\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDIVICE\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\homer\\OneDrive\\Desktop\\Morse_Decoder_V2\\Morse_decoder_V2\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\homer\\OneDrive\\Desktop\\Morse_Decoder_V2\\Morse_decoder_V2\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\homer\\OneDrive\\Desktop\\Morse_Decoder_V2\\Morse_decoder_V2\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:789\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    788\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    790\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    791\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\homer\\OneDrive\\Desktop\\Morse_Decoder_V2\\Morse_decoder_V2\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 85\u001b[39m, in \u001b[36mMosreDataset.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     84\u001b[39m     audio_file = \u001b[38;5;28mself\u001b[39m.audio_paths / \u001b[38;5;28mself\u001b[39m.df.id.values[index]\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m     waveform, sample_rate = \u001b[43mtorchaudio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     86\u001b[39m     augmented_spectrogram = \u001b[38;5;28mself\u001b[39m.transforms(waveform)\n\u001b[32m     88\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_train:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\homer\\OneDrive\\Desktop\\Morse_Decoder_V2\\Morse_decoder_V2\\Lib\\site-packages\\torchaudio\\_backend\\utils.py:205\u001b[39m, in \u001b[36mget_load_func.<locals>.load\u001b[39m\u001b[34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size, backend)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Load audio data from source.\u001b[39;00m\n\u001b[32m    129\u001b[39m \n\u001b[32m    130\u001b[39m \u001b[33;03mBy default (``normalize=True``, ``channels_first=True``), this function returns Tensor with\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    202\u001b[39m \u001b[33;03m        `[channel, time]` else `[time, channel]`.\u001b[39;00m\n\u001b[32m    203\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    204\u001b[39m backend = dispatcher(uri, \u001b[38;5;28mformat\u001b[39m, backend)\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\homer\\OneDrive\\Desktop\\Morse_Decoder_V2\\Morse_decoder_V2\\Lib\\site-packages\\torchaudio\\_backend\\soundfile.py:27\u001b[39m, in \u001b[36mSoundfileBackend.load\u001b[39m\u001b[34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\n\u001b[32m     19\u001b[39m     uri: Union[BinaryIO, \u001b[38;5;28mstr\u001b[39m, os.PathLike],\n\u001b[32m   (...)\u001b[39m\u001b[32m     25\u001b[39m     buffer_size: \u001b[38;5;28mint\u001b[39m = \u001b[32m4096\u001b[39m,\n\u001b[32m     26\u001b[39m ) -> Tuple[torch.Tensor, \u001b[38;5;28mint\u001b[39m]:\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msoundfile_backend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\homer\\OneDrive\\Desktop\\Morse_Decoder_V2\\Morse_decoder_V2\\Lib\\site-packages\\torchaudio\\_backend\\soundfile_backend.py:230\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(filepath, frame_offset, num_frames, normalize, channels_first, format)\u001b[39m\n\u001b[32m    227\u001b[39m         dtype = _SUBTYPE2DTYPE[file_.subtype]\n\u001b[32m    229\u001b[39m     frames = file_._prepare_read(frame_offset, \u001b[38;5;28;01mNone\u001b[39;00m, num_frames)\n\u001b[32m--> \u001b[39m\u001b[32m230\u001b[39m     waveform = \u001b[43mfile_\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malways_2d\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    231\u001b[39m     sample_rate = file_.samplerate\n\u001b[32m    233\u001b[39m waveform = torch.from_numpy(waveform)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\homer\\OneDrive\\Desktop\\Morse_Decoder_V2\\Morse_decoder_V2\\Lib\\site-packages\\soundfile.py:942\u001b[39m, in \u001b[36mSoundFile.read\u001b[39m\u001b[34m(self, frames, dtype, always_2d, fill_value, out)\u001b[39m\n\u001b[32m    940\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m frames < \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m frames > \u001b[38;5;28mlen\u001b[39m(out):\n\u001b[32m    941\u001b[39m         frames = \u001b[38;5;28mlen\u001b[39m(out)\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m frames = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_array_io\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mread\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) > frames:\n\u001b[32m    944\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m fill_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\homer\\OneDrive\\Desktop\\Morse_Decoder_V2\\Morse_decoder_V2\\Lib\\site-packages\\soundfile.py:1394\u001b[39m, in \u001b[36mSoundFile._array_io\u001b[39m\u001b[34m(self, action, array, frames)\u001b[39m\n\u001b[32m   1392\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m array.dtype.itemsize == _ffi.sizeof(ctype)\n\u001b[32m   1393\u001b[39m cdata = _ffi.cast(ctype + \u001b[33m'\u001b[39m\u001b[33m*\u001b[39m\u001b[33m'\u001b[39m, array.__array_interface__[\u001b[33m'\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m'\u001b[39m][\u001b[32m0\u001b[39m])\n\u001b[32m-> \u001b[39m\u001b[32m1394\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cdata_io\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\homer\\OneDrive\\Desktop\\Morse_Decoder_V2\\Morse_decoder_V2\\Lib\\site-packages\\soundfile.py:1403\u001b[39m, in \u001b[36mSoundFile._cdata_io\u001b[39m\u001b[34m(self, action, data, ctype, frames)\u001b[39m\n\u001b[32m   1401\u001b[39m     curr = \u001b[38;5;28mself\u001b[39m.tell()\n\u001b[32m   1402\u001b[39m func = \u001b[38;5;28mgetattr\u001b[39m(_snd, \u001b[33m'\u001b[39m\u001b[33msf_\u001b[39m\u001b[33m'\u001b[39m + action + \u001b[33m'\u001b[39m\u001b[33mf_\u001b[39m\u001b[33m'\u001b[39m + ctype)\n\u001b[32m-> \u001b[39m\u001b[32m1403\u001b[39m frames = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1404\u001b[39m _error_check(\u001b[38;5;28mself\u001b[39m._errorcode)\n\u001b[32m   1405\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.seekable():\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "lst_loss_train = []\n",
    "lst_loss_val = []\n",
    "best_val_loss = 0\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "\n",
    "    epoch_train_loss = 0.0\n",
    "    train_predicts = []\n",
    "\n",
    "    train_tqdm = tqdm(train_dl, desc=f\"Эпоха {epoch+1}/{EPOCHS} [Обучение]\", leave=False)\n",
    "    for batch_ind, batch in enumerate(train_tqdm):\n",
    "        mel_spec, targets, targets_lens, _ = batch\n",
    "        mel_spec, targets, targets_lens = mel_spec.to(DIVICE), targets.to(DIVICE), targets_lens.to(DIVICE)\n",
    "\n",
    "        #===== считатем длинну mel_spec для передачи в CTC loss =====\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predict = model(mel_spec) # (N=batch,T,C)\n",
    "        N = predict.shape[1]\n",
    "        T = predict.shape[0]\n",
    "        predict_lengths = torch.full(size=(N,), fill_value=T, dtype=torch.long)\n",
    "\n",
    "        try:\n",
    "            loss = loss_func(predict, targets, predict_lengths, targets_lens.reshape(BATCH_SIZE))\n",
    "        except RuntimeError:\n",
    "            print(predict.shape, targets.shape, predict_lengths, targets_lens.reshape(BATCH_SIZE))\n",
    "            continue\n",
    "\n",
    "        if torch.isnan(loss) or torch.isinf(loss): \n",
    "            print(f\"\\nWarning: In batch-{batch_ind} loss train is NaN/Inf: {loss.item()}\"); \n",
    "            optimizer.zero_grad(); \n",
    "            continue\n",
    "\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_train_loss += loss.item()\n",
    "\n",
    "    total_train = epoch_train_loss / len(train_dl)\n",
    "\n",
    "    # ======== Валидация ========\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    total_val = 0\n",
    "    val_predicts = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for val_mel_spec, val_labels, val_label_lensin, _ in tqdm(\n",
    "                                                        val_dl, \n",
    "                                                        desc=f\"Эпоха {epoch+1}/{EPOCHS} [Валидация]\", \n",
    "                                                        leave=False):\n",
    "            val_mel_spec, val_labels, val_label_lensin = val_mel_spec.to(DIVICE), val_labels.to(DIVICE), val_label_lensin.to(DIVICE)\n",
    "            val_predict = model(val_mel_spec)\n",
    "\n",
    "            val_N = val_predict.shape[1]\n",
    "            val_T = val_predict.shape[0]\n",
    "            predict_val_lengths = torch.full(size=(val_N,), fill_value=val_T, dtype=torch.long)\n",
    "            val_loss += loss_func(val_predict, val_labels, predict_val_lengths, val_label_lensin).item()\n",
    "\n",
    "    total_val = val_loss / len(val_dl)\n",
    "\n",
    "    lst_loss_train.append(total_train)\n",
    "    lst_loss_val.append(total_val)\n",
    "\n",
    "    scheduler.step(total_val)\n",
    "\n",
    "    print(f\"\\n===== Эпоха {epoch+1}/{EPOCHS} =====\")\\\n",
    "    #===== Инфо про градиенты=====\n",
    "    grad_norms = [param.grad.norm().item() for param in model.parameters() if param.grad is not None]\n",
    "    if grad_norms:\n",
    "        print(f\"Mean grad norm: {np.mean(grad_norms):.6f}\")\n",
    "        print(f\"Max grad norm: {np.max(grad_norms):.6f}\")\n",
    "        print(f\"Min grad norm: {np.min(grad_norms):.6f}\")\n",
    "    else:\n",
    "        print(\"No gradients computed yet.\")\n",
    "    #===== Инфо про шаг обучения и данные по потерям =====\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    print(f\"Current LR: {current_lr:.6f}\")\n",
    "    print(f\"---- Train Loss: {total_train:.4f}\")\n",
    "    print(f\"---- Val Loss: {total_val:.4f}\")\n",
    "    if current_lr <= 1e-6:\n",
    "        print(\"Learning rate достиг минимума 1e-6, остановка обучения\")\n",
    "        break\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca52e14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'MorseNet.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1547a2ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lst_loss_train)\n",
    "plt.plot(lst_loss_val)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45f65295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN размерность выхода: torch.Size([1, 32, 16, 89])\n",
      "CNN число фичей: 512\n",
      "Проекция из 512 в 512\n",
      "Mean accurasu by The Levenshtein in train is : 0.9306204623520523\n",
      "Mean accurasu by The Levenshtein in validate is : 0.9449027945915751\n"
     ]
    }
   ],
   "source": [
    "def ctc_decoder(logits, int_char_map, blank_label_idx):\n",
    "    preds = []\n",
    "    logits_cpu = logits.cpu() \n",
    "    max_inds = torch.argmax(logits_cpu.detach(), dim=2).t().numpy() # арзмакс по лагитам и преобразование к словарю\n",
    "    \n",
    "    for ind in max_inds:\n",
    "        merged_inds = []\n",
    "        for idx in ind:\n",
    "            if idx != blank_label_idx: \n",
    "                merged_inds.append(idx)\n",
    "        text = \"\".join([int_char_map.get(i, '?') for i in merged_inds])\n",
    "        preds.append(text)\n",
    "\n",
    "    return preds\n",
    "\n",
    "model_load = MorseNet(num_classes=num_classes)\n",
    "model_load.load_state_dict(torch.load('MorseNet.pth'))\n",
    "model_load.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_mess = []\n",
    "    train_predicts = []\n",
    "    for loader in train_dl:\n",
    "        seq, test_target, _, mess = loader\n",
    "        train_mess.extend(mess)\n",
    "\n",
    "        logits = model_load(seq)\n",
    "        predicted_values = ctc_decoder(logits, int_to_char, BLANK_IDX)\n",
    "        train_predicts.extend(predicted_values)\n",
    "\n",
    "    val_mess = []\n",
    "    val_predicts = []\n",
    "    for loader in val_dl:\n",
    "        seq, test_target, _, mess = loader\n",
    "        val_mess.extend(mess)\n",
    "\n",
    "        logits= model_load(seq)\n",
    "        predicted_values = ctc_decoder(logits, int_to_char, BLANK_IDX)\n",
    "        val_predicts.extend(predicted_values)\n",
    "\n",
    "import Levenshtein\n",
    "\n",
    "mean_acc_test = np.mean([Levenshtein.ratio(test_pred, train_mess[ind]) for ind, test_pred in enumerate(train_predicts)])\n",
    "mean_acc_val = np.mean([Levenshtein.ratio(val_pred, val_mess[ind]) for ind, val_pred in enumerate(val_predicts)])\n",
    "\n",
    "\n",
    "print(f\"Mean accurasu by The Levenshtein in train is : {mean_acc_test}\")\n",
    "print(f\"Mean accurasu by The Levenshtein in validate is : {mean_acc_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49ca828",
   "metadata": {},
   "source": [
    "# Сбор sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c85e44a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN размерность выхода: torch.Size([1, 32, 16, 89])\n",
      "CNN число фичей: 512\n",
      "Проекция из 512 в 512\n"
     ]
    }
   ],
   "source": [
    "def ctc_decoder(logits, int_char_map, blank_label_idx):\n",
    "    preds = []\n",
    "    logits_cpu = logits.cpu() \n",
    "    max_inds = torch.argmax(logits_cpu.detach(), dim=2).t().numpy() # арзмакс по лагитам и преобразование к словарю\n",
    "    \n",
    "    for ind in max_inds:\n",
    "        merged_inds = []\n",
    "        for idx in ind:\n",
    "            if idx != blank_label_idx: \n",
    "                merged_inds.append(idx)\n",
    "        text = \"\".join([int_char_map.get(i, '?') for i in merged_inds])\n",
    "        preds.append(text)\n",
    "\n",
    "    return preds\n",
    "\n",
    "model_load = MorseNet(num_classes=num_classes)\n",
    "model_load.load_state_dict(torch.load('MorseNet.pth'))\n",
    "model_load.eval()\n",
    "\n",
    "test_ds = MosreDataset(df=sample_data,\n",
    "                        data_patch=DATASET_PATCH,\n",
    "                        char_to_int=char_to_int,\n",
    "                        train=False,\n",
    "                        transforms=valid_audio_transforms)\n",
    "\n",
    "\n",
    "test_dl = torch.utils.data.DataLoader(test_ds, batch_size=20, shuffle=False, collate_fn=my_collate)\n",
    "model_load.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_predicts = []\n",
    "    for loader in test_dl:\n",
    "        seq = loader\n",
    "        logits = model_load(seq)\n",
    "        predicted_values = ctc_decoder(logits, int_to_char, BLANK_IDX)\n",
    "        test_predicts.extend(predicted_values)\n",
    "\n",
    "sample_data.message = test_predicts\n",
    "sample_data.to_csv('sample_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Morse_decoder_V2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

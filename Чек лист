0) Сохдать отдельный трансформер на валинацию => Изменить class Dataset 
1) Обучить на 1-м батче
2) изменить LEARNING_RATE и WEIGHT_DECAY 

3) попробовать убрать выравнивание по длинне аудио - появляется много пустого места => 
модет плохо сказываться на обучение - Пошли взрывы градиента + непонятно что делать с ращной длиной
4) Дабавить нормализацию данных + Линейный слой для уменьшения признаков - 
5) добавить инициализацию весов/переписать архитектуру - 

6) Добавлена ифнормация перед запуском обучения + инфо о градиентах(Сейчас происходит затухание так как nan в preicts), 
    Попытна сгладит зибухание путем добалвения LeakyReLU для просчета отрицательных значений    
    Изменена свертка - есть предполодение что очень резкая вертка, делаем ее плавнее и оставляем больше признаков.
    # Уже стало лучше - градиенты не затухают а и ишибки стали алекватнее

7) Возможно подрезка кадра не нужна, так как принудительно ухудшает данные# не понятно есть ли вэлью, но я вно стало медленне обучаться
7.1) Порробую рапарралелить обучение (DataParallel to gpu) и использую flatten_parameters # ну хз

8) попробую порабгоать с моделью без удлинения сигнала по времени.
 До этого я удлинял короткие сигналы в 5 раз))


Подтянул знания в Rnn сетях:
2.1) Думаю что нужно реализовать модель encoder-decoder,
где в encoder будет использоваться CNN сеть для извлечения фич
далее пойдет рекурентный декодер. Кажется что испольщование attention не 
целесообразно так как нет зависимости в последовательности.
Цель по фото декодировать хаотичный набор символов. т.е. Будем плучать одну метку класса 
для КАЖДОГО скрытого состояния полученного на слое encoder
nn.functional.log_softmax(x.permute(1,0,2), dim=2) - добавил .detach().requires_grad_() - градиент не взрывается???


2.2) 
Train Loss: 0.8667
Val Loss: 4546.3094 - может быть предикт не соответствует таргету

2.3) поставил клипинг, но есть nan следоваетльно градиенты затухают резко.

2.4) Возможно косяк был в неправильном падинге последовательности. 
У меня симпол пропуска кодировался нулум так же как и нулевой элемент помледовательности - переделал 
на отдельный симпол и дабавил его в словарь
